{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_17_Yoel_RegenT.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "WAl5WbZRd1PV",
        "4TCyLYuQ6t-K",
        "D6qvlF1Gq9-0",
        "SVSZ5zrGf-kA",
        "xrgDrN-agJLD",
        "x3Rm3rdbgP75",
        "dE9eKPzW7HbG",
        "MPaPMPeTdCTJ",
        "pBH51VPldBHi",
        "V7j2rsHWdJdH",
        "UiEbtlDGdguk",
        "2IK141L9rNLr",
        "-BXhRZgzrYlT",
        "a-hKNlSirYlc",
        "vA-9QU9ArYlg",
        "qAHQCzVy7sT1",
        "dyf48MmwrYly",
        "lcvd-m-UrYl_",
        "YsnGgHEHrYmH",
        "Hc2q5qu4rYmM"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAl5WbZRd1PV"
      },
      "source": [
        "# Import Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXJXtZqeaYIf"
      },
      "source": [
        "# From: https://machinelearningmastery.com/exploratory-configuration-multilayer-perceptron-network-time-series-forecasting/\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "from tensorflow.keras.layers import LSTM"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TCyLYuQ6t-K"
      },
      "source": [
        "# Function Plot hasil"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pzu_OHJEcaQb"
      },
      "source": [
        "def plot_loss(history):\n",
        "  plt.plot(history.history['loss'], label='loss')\n",
        "  plt.plot(history.history['val_loss'], label='val_loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss (MSE)')\n",
        "  plt.legend()\n",
        "  plt.grid(True)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6qvlF1Gq9-0"
      },
      "source": [
        "# Dataset daily-min-temperature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVSZ5zrGf-kA"
      },
      "source": [
        "## Parser dan Read dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FABCDpbkcDHD"
      },
      "source": [
        "def parser(x):\n",
        "\treturn datetime.strptime(x, '%Y-%m-%d')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DddLNKkgcD1p",
        "outputId": "17bc355a-067c-4a30-a7e6-9aa47c6c945d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "dataset = pd.read_csv('/content/drive/My Drive/BCML/daily-min-temperatures.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n",
        "\n",
        "dataset.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Date\n",
              "1981-01-01    20.7\n",
              "1981-01-02    17.9\n",
              "1981-01-03    18.8\n",
              "1981-01-04    14.6\n",
              "1981-01-05    15.8\n",
              "Name: Temp, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrgDrN-agJLD"
      },
      "source": [
        "## Plot dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5VcfffOcDyx",
        "outputId": "e7ecba33-8fd0-4711-ec76-f3b7de182e4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "dataset.plot()\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3Rm3rdbgP75"
      },
      "source": [
        "## Processing Time series"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_p-x75ccF9J"
      },
      "source": [
        "def timeseries_to_supervised(data, lag=1):\n",
        "\tdf = pd.DataFrame(data)\n",
        "\tcolumns = [df.shift(i) for i in range(1, lag+1)]\n",
        "\tcolumns.append(df)\n",
        "\tdf = pd.concat(columns, axis=1)\n",
        "\treturn df\n",
        "\n",
        "def difference(dataset, interval=1):\n",
        "\tdiff = list()\n",
        "\tfor i in range(interval, len(dataset)):\n",
        "\t\tvalue = dataset[i] - dataset[i - interval]\n",
        "\t\tdiff.append(value)\n",
        "\treturn pd.Series(diff)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y51MND_CcF6h",
        "outputId": "816ddfaf-ca8f-4c52-dcd2-907bcf96ca1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "lag = 1\n",
        "\n",
        "raw_values = dataset.values\n",
        "diff_values = difference(raw_values, 1)\n",
        "\n",
        "diff_values"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      -2.8\n",
              "1       0.9\n",
              "2      -4.2\n",
              "3       1.2\n",
              "4       0.0\n",
              "       ... \n",
              "3644   -0.6\n",
              "3645   -0.4\n",
              "3646   -0.1\n",
              "3647    2.2\n",
              "3648   -2.7\n",
              "Length: 3649, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8J-uCP-cF4C",
        "outputId": "129aebeb-59b8-4af8-e50c-5bc6ca813d40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "supervised = timeseries_to_supervised(diff_values, lag)\n",
        "supervised"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>-2.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-2.8</td>\n",
              "      <td>0.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.9</td>\n",
              "      <td>-4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-4.2</td>\n",
              "      <td>1.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3644</th>\n",
              "      <td>1.7</td>\n",
              "      <td>-0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3645</th>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3646</th>\n",
              "      <td>-0.4</td>\n",
              "      <td>-0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3647</th>\n",
              "      <td>-0.1</td>\n",
              "      <td>2.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3648</th>\n",
              "      <td>2.2</td>\n",
              "      <td>-2.7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3649 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0    0\n",
              "0     NaN -2.8\n",
              "1    -2.8  0.9\n",
              "2     0.9 -4.2\n",
              "3    -4.2  1.2\n",
              "4     1.2  0.0\n",
              "...   ...  ...\n",
              "3644  1.7 -0.6\n",
              "3645 -0.6 -0.4\n",
              "3646 -0.4 -0.1\n",
              "3647 -0.1  2.2\n",
              "3648  2.2 -2.7\n",
              "\n",
              "[3649 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OB2BYo4AcF1b",
        "outputId": "cc44489f-c922-4877-a2bb-6eacf2c42e5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "supervised_values = supervised.values[lag:,:]\n",
        "supervised_values"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-2.8,  0.9],\n",
              "       [ 0.9, -4.2],\n",
              "       [-4.2,  1.2],\n",
              "       ...,\n",
              "       [-0.4, -0.1],\n",
              "       [-0.1,  2.2],\n",
              "       [ 2.2, -2.7]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n59t5e03cFyi"
      },
      "source": [
        "split_percentage = 0.75\n",
        "\n",
        "train_size = int(split_percentage * len(supervised_values))\n",
        "\n",
        "train, test = supervised_values[0:train_size], supervised_values[train_size:len(supervised_values)]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mN4sWlrecFvi"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(-1, 1)) # Range hasil scaling menjadi angka diantara -1 hingga 1\n",
        "scaler = scaler.fit(train)\n",
        "\n",
        "train_scaled = scaler.transform(train)\n",
        "test_scaled = scaler.transform(test)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSBFIfGLcFsj",
        "outputId": "a97ac920-3bd4-4876-d067-f21f9e01b438",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "train_scaled"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.11607143,  0.21428571],\n",
              "       [ 0.21428571, -0.24107143],\n",
              "       [-0.24107143,  0.24107143],\n",
              "       ...,\n",
              "       [-0.16071429,  0.375     ],\n",
              "       [ 0.375     ,  0.125     ],\n",
              "       [ 0.125     , -0.16071429]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dE9eKPzW7HbG"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPaPMPeTdCTJ"
      },
      "source": [
        "### Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woZbmtYTcaFy",
        "outputId": "ab560b72-e4d6-4139-9ac3-21759e08f782",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "neurons = 1\n",
        "epoch = 1000\n",
        "batch_size = 32\n",
        "\n",
        "feature_train, label_train = train_scaled[:, 0:-1], train_scaled[:, -1]\n",
        "feature_test, label_test = test_scaled[:, 0:-1], test_scaled[:, -1]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(neurons, activation='relu', input_dim=feature_train.shape[1]))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "history = model.fit(feature_train, label_train, epochs=epoch, batch_size=batch_size, validation_data=(feature_test, label_test))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0664 - val_loss: 0.0561\n",
            "Epoch 2/1000\n",
            "86/86 [==============================] - 0s 839us/step - loss: 0.0599 - val_loss: 0.0545\n",
            "Epoch 3/1000\n",
            "86/86 [==============================] - 0s 847us/step - loss: 0.0594 - val_loss: 0.0544\n",
            "Epoch 4/1000\n",
            "86/86 [==============================] - 0s 981us/step - loss: 0.0592 - val_loss: 0.0543\n",
            "Epoch 5/1000\n",
            "86/86 [==============================] - 0s 937us/step - loss: 0.0591 - val_loss: 0.0542\n",
            "Epoch 6/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0542\n",
            "Epoch 7/1000\n",
            "86/86 [==============================] - 0s 941us/step - loss: 0.0590 - val_loss: 0.0542\n",
            "Epoch 8/1000\n",
            "86/86 [==============================] - 0s 960us/step - loss: 0.0590 - val_loss: 0.0542\n",
            "Epoch 9/1000\n",
            "86/86 [==============================] - 0s 931us/step - loss: 0.0590 - val_loss: 0.0542\n",
            "Epoch 10/1000\n",
            "86/86 [==============================] - 0s 862us/step - loss: 0.0589 - val_loss: 0.0541\n",
            "Epoch 11/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0541\n",
            "Epoch 12/1000\n",
            "86/86 [==============================] - 0s 843us/step - loss: 0.0589 - val_loss: 0.0541\n",
            "Epoch 13/1000\n",
            "86/86 [==============================] - 0s 888us/step - loss: 0.0589 - val_loss: 0.0541\n",
            "Epoch 14/1000\n",
            "86/86 [==============================] - 0s 930us/step - loss: 0.0589 - val_loss: 0.0541\n",
            "Epoch 15/1000\n",
            "86/86 [==============================] - 0s 953us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 16/1000\n",
            "86/86 [==============================] - 0s 931us/step - loss: 0.0589 - val_loss: 0.0541\n",
            "Epoch 17/1000\n",
            "86/86 [==============================] - 0s 843us/step - loss: 0.0589 - val_loss: 0.0541\n",
            "Epoch 18/1000\n",
            "86/86 [==============================] - 0s 962us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 19/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 20/1000\n",
            "86/86 [==============================] - 0s 853us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 21/1000\n",
            "86/86 [==============================] - 0s 872us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 22/1000\n",
            "86/86 [==============================] - 0s 867us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 23/1000\n",
            "86/86 [==============================] - 0s 861us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 24/1000\n",
            "86/86 [==============================] - 0s 917us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 25/1000\n",
            "86/86 [==============================] - 0s 845us/step - loss: 0.0589 - val_loss: 0.0541\n",
            "Epoch 26/1000\n",
            "86/86 [==============================] - 0s 903us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 27/1000\n",
            "86/86 [==============================] - 0s 955us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 28/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 29/1000\n",
            "86/86 [==============================] - 0s 835us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 30/1000\n",
            "86/86 [==============================] - 0s 943us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 31/1000\n",
            "86/86 [==============================] - 0s 859us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 32/1000\n",
            "86/86 [==============================] - 0s 950us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 33/1000\n",
            "86/86 [==============================] - 0s 905us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 34/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 35/1000\n",
            "86/86 [==============================] - 0s 999us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 36/1000\n",
            "86/86 [==============================] - 0s 827us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 37/1000\n",
            "86/86 [==============================] - 0s 835us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 38/1000\n",
            "86/86 [==============================] - 0s 939us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 39/1000\n",
            "86/86 [==============================] - 0s 941us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 40/1000\n",
            "86/86 [==============================] - 0s 936us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 41/1000\n",
            "86/86 [==============================] - 0s 857us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 42/1000\n",
            "86/86 [==============================] - 0s 973us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 43/1000\n",
            "86/86 [==============================] - 0s 934us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 44/1000\n",
            "86/86 [==============================] - 0s 877us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 45/1000\n",
            "86/86 [==============================] - 0s 883us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 46/1000\n",
            "86/86 [==============================] - 0s 905us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 47/1000\n",
            "86/86 [==============================] - 0s 834us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 48/1000\n",
            "86/86 [==============================] - 0s 907us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 49/1000\n",
            "86/86 [==============================] - 0s 907us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 50/1000\n",
            "86/86 [==============================] - 0s 882us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 51/1000\n",
            "86/86 [==============================] - 0s 841us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 52/1000\n",
            "86/86 [==============================] - 0s 912us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 53/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 54/1000\n",
            "86/86 [==============================] - 0s 996us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 55/1000\n",
            "86/86 [==============================] - 0s 925us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 56/1000\n",
            "86/86 [==============================] - 0s 920us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 57/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 58/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 59/1000\n",
            "86/86 [==============================] - 0s 974us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 60/1000\n",
            "86/86 [==============================] - 0s 966us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 61/1000\n",
            "86/86 [==============================] - 0s 935us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 62/1000\n",
            "86/86 [==============================] - 0s 958us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 63/1000\n",
            "86/86 [==============================] - 0s 959us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 64/1000\n",
            "86/86 [==============================] - 0s 939us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 65/1000\n",
            "86/86 [==============================] - 0s 915us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 66/1000\n",
            "86/86 [==============================] - 0s 983us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 67/1000\n",
            "86/86 [==============================] - 0s 929us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 68/1000\n",
            "86/86 [==============================] - 0s 854us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 69/1000\n",
            "86/86 [==============================] - 0s 848us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 70/1000\n",
            "86/86 [==============================] - 0s 952us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 71/1000\n",
            "86/86 [==============================] - 0s 924us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 72/1000\n",
            "86/86 [==============================] - 0s 862us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 73/1000\n",
            "86/86 [==============================] - 0s 895us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 74/1000\n",
            "86/86 [==============================] - 0s 985us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 75/1000\n",
            "86/86 [==============================] - 0s 890us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 76/1000\n",
            "86/86 [==============================] - 0s 902us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 77/1000\n",
            "86/86 [==============================] - 0s 911us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 78/1000\n",
            "86/86 [==============================] - 0s 986us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 79/1000\n",
            "86/86 [==============================] - 0s 987us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 80/1000\n",
            "86/86 [==============================] - 0s 953us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 81/1000\n",
            "86/86 [==============================] - 0s 808us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 82/1000\n",
            "86/86 [==============================] - 0s 943us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 83/1000\n",
            "86/86 [==============================] - 0s 908us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 84/1000\n",
            "86/86 [==============================] - 0s 917us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 85/1000\n",
            "86/86 [==============================] - 0s 938us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 86/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 87/1000\n",
            "86/86 [==============================] - 0s 836us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 88/1000\n",
            "86/86 [==============================] - 0s 995us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 89/1000\n",
            "86/86 [==============================] - 0s 852us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 90/1000\n",
            "86/86 [==============================] - 0s 973us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 91/1000\n",
            "86/86 [==============================] - 0s 987us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 92/1000\n",
            "86/86 [==============================] - 0s 945us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 93/1000\n",
            "86/86 [==============================] - 0s 965us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 94/1000\n",
            "86/86 [==============================] - 0s 921us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 95/1000\n",
            "86/86 [==============================] - 0s 911us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 96/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 97/1000\n",
            "86/86 [==============================] - 0s 936us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 98/1000\n",
            "86/86 [==============================] - 0s 876us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 99/1000\n",
            "86/86 [==============================] - 0s 995us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 100/1000\n",
            "86/86 [==============================] - 0s 963us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 101/1000\n",
            "86/86 [==============================] - 0s 904us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 102/1000\n",
            "86/86 [==============================] - 0s 999us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 103/1000\n",
            "86/86 [==============================] - 0s 972us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 104/1000\n",
            "86/86 [==============================] - 0s 916us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 105/1000\n",
            "86/86 [==============================] - 0s 858us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 106/1000\n",
            "86/86 [==============================] - 0s 890us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 107/1000\n",
            "86/86 [==============================] - 0s 903us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 108/1000\n",
            "86/86 [==============================] - 0s 933us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 109/1000\n",
            "86/86 [==============================] - 0s 957us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 110/1000\n",
            "86/86 [==============================] - 0s 867us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 111/1000\n",
            "86/86 [==============================] - 0s 945us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 112/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 113/1000\n",
            "86/86 [==============================] - 0s 880us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 114/1000\n",
            "86/86 [==============================] - 0s 835us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 115/1000\n",
            "86/86 [==============================] - 0s 944us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 116/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 117/1000\n",
            "86/86 [==============================] - 0s 912us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 118/1000\n",
            "86/86 [==============================] - 0s 942us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 119/1000\n",
            "86/86 [==============================] - 0s 840us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 120/1000\n",
            "86/86 [==============================] - 0s 904us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 121/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 122/1000\n",
            "86/86 [==============================] - 0s 868us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 123/1000\n",
            "86/86 [==============================] - 0s 925us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 124/1000\n",
            "86/86 [==============================] - 0s 933us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 125/1000\n",
            "86/86 [==============================] - 0s 980us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 126/1000\n",
            "86/86 [==============================] - 0s 943us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 127/1000\n",
            "86/86 [==============================] - 0s 940us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 128/1000\n",
            "86/86 [==============================] - 0s 955us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 129/1000\n",
            "86/86 [==============================] - 0s 910us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 130/1000\n",
            "86/86 [==============================] - 0s 956us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 131/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 132/1000\n",
            "86/86 [==============================] - 0s 931us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 133/1000\n",
            "86/86 [==============================] - 0s 948us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 134/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 135/1000\n",
            "86/86 [==============================] - 0s 932us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 136/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 137/1000\n",
            "86/86 [==============================] - 0s 961us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 138/1000\n",
            "86/86 [==============================] - 0s 926us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 139/1000\n",
            "86/86 [==============================] - 0s 954us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 140/1000\n",
            "86/86 [==============================] - 0s 961us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 141/1000\n",
            "86/86 [==============================] - 0s 874us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 142/1000\n",
            "86/86 [==============================] - 0s 898us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 143/1000\n",
            "86/86 [==============================] - 0s 961us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 144/1000\n",
            "86/86 [==============================] - 0s 941us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 145/1000\n",
            "86/86 [==============================] - 0s 819us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 146/1000\n",
            "86/86 [==============================] - 0s 831us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 147/1000\n",
            "86/86 [==============================] - 0s 912us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 148/1000\n",
            "86/86 [==============================] - 0s 842us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 149/1000\n",
            "86/86 [==============================] - 0s 938us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 150/1000\n",
            "86/86 [==============================] - 0s 854us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 151/1000\n",
            "86/86 [==============================] - 0s 890us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 152/1000\n",
            "86/86 [==============================] - 0s 933us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 153/1000\n",
            "86/86 [==============================] - 0s 874us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 154/1000\n",
            "86/86 [==============================] - 0s 939us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 155/1000\n",
            "86/86 [==============================] - 0s 844us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 156/1000\n",
            "86/86 [==============================] - 0s 861us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 157/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 158/1000\n",
            "86/86 [==============================] - 0s 984us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 159/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 160/1000\n",
            "86/86 [==============================] - 0s 914us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 161/1000\n",
            "86/86 [==============================] - 0s 997us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 162/1000\n",
            "86/86 [==============================] - 0s 931us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 163/1000\n",
            "86/86 [==============================] - 0s 939us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 164/1000\n",
            "86/86 [==============================] - 0s 843us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 165/1000\n",
            "86/86 [==============================] - 0s 990us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 166/1000\n",
            "86/86 [==============================] - 0s 946us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 167/1000\n",
            "86/86 [==============================] - 0s 911us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 168/1000\n",
            "86/86 [==============================] - 0s 954us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 169/1000\n",
            "86/86 [==============================] - 0s 936us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 170/1000\n",
            "86/86 [==============================] - 0s 819us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 171/1000\n",
            "86/86 [==============================] - 0s 813us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 172/1000\n",
            "86/86 [==============================] - 0s 922us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 173/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 174/1000\n",
            "86/86 [==============================] - 0s 825us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 175/1000\n",
            "86/86 [==============================] - 0s 851us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 176/1000\n",
            "86/86 [==============================] - 0s 956us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 177/1000\n",
            "86/86 [==============================] - 0s 941us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 178/1000\n",
            "86/86 [==============================] - 0s 883us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 179/1000\n",
            "86/86 [==============================] - 0s 913us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 180/1000\n",
            "86/86 [==============================] - 0s 910us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 181/1000\n",
            "86/86 [==============================] - 0s 895us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 182/1000\n",
            "86/86 [==============================] - 0s 967us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 183/1000\n",
            "86/86 [==============================] - 0s 879us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 184/1000\n",
            "86/86 [==============================] - 0s 920us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 185/1000\n",
            "86/86 [==============================] - 0s 994us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 186/1000\n",
            "86/86 [==============================] - 0s 876us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 187/1000\n",
            "86/86 [==============================] - 0s 911us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 188/1000\n",
            "86/86 [==============================] - 0s 889us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 189/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 190/1000\n",
            "86/86 [==============================] - 0s 839us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 191/1000\n",
            "86/86 [==============================] - 0s 833us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 192/1000\n",
            "86/86 [==============================] - 0s 822us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 193/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 194/1000\n",
            "86/86 [==============================] - 0s 871us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 195/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 196/1000\n",
            "86/86 [==============================] - 0s 966us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 197/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 198/1000\n",
            "86/86 [==============================] - 0s 978us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 199/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 200/1000\n",
            "86/86 [==============================] - 0s 987us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 201/1000\n",
            "86/86 [==============================] - 0s 986us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 202/1000\n",
            "86/86 [==============================] - 0s 934us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 203/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 204/1000\n",
            "86/86 [==============================] - 0s 846us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 205/1000\n",
            "86/86 [==============================] - 0s 844us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 206/1000\n",
            "86/86 [==============================] - 0s 850us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 207/1000\n",
            "86/86 [==============================] - 0s 966us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 208/1000\n",
            "86/86 [==============================] - 0s 922us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 209/1000\n",
            "86/86 [==============================] - 0s 944us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 210/1000\n",
            "86/86 [==============================] - 0s 961us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 211/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 212/1000\n",
            "86/86 [==============================] - 0s 965us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 213/1000\n",
            "86/86 [==============================] - 0s 857us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 214/1000\n",
            "86/86 [==============================] - 0s 932us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 215/1000\n",
            "86/86 [==============================] - 0s 863us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 216/1000\n",
            "86/86 [==============================] - 0s 889us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 217/1000\n",
            "86/86 [==============================] - 0s 915us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 218/1000\n",
            "86/86 [==============================] - 0s 993us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 219/1000\n",
            "86/86 [==============================] - 0s 859us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 220/1000\n",
            "86/86 [==============================] - 0s 846us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 221/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 222/1000\n",
            "86/86 [==============================] - 0s 850us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 223/1000\n",
            "86/86 [==============================] - 0s 837us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 224/1000\n",
            "86/86 [==============================] - 0s 820us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 225/1000\n",
            "86/86 [==============================] - 0s 848us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 226/1000\n",
            "86/86 [==============================] - 0s 862us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 227/1000\n",
            "86/86 [==============================] - 0s 913us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 228/1000\n",
            "86/86 [==============================] - 0s 987us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 229/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 230/1000\n",
            "86/86 [==============================] - 0s 935us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 231/1000\n",
            "86/86 [==============================] - 0s 915us/step - loss: 0.0589 - val_loss: 0.0541\n",
            "Epoch 232/1000\n",
            "86/86 [==============================] - 0s 938us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 233/1000\n",
            "86/86 [==============================] - 0s 974us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 234/1000\n",
            "86/86 [==============================] - 0s 832us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 235/1000\n",
            "86/86 [==============================] - 0s 925us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 236/1000\n",
            "86/86 [==============================] - 0s 934us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 237/1000\n",
            "86/86 [==============================] - 0s 961us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 238/1000\n",
            "86/86 [==============================] - 0s 856us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 239/1000\n",
            "86/86 [==============================] - 0s 931us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 240/1000\n",
            "86/86 [==============================] - 0s 876us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 241/1000\n",
            "86/86 [==============================] - 0s 920us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 242/1000\n",
            "86/86 [==============================] - 0s 956us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 243/1000\n",
            "86/86 [==============================] - 0s 922us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 244/1000\n",
            "86/86 [==============================] - 0s 878us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 245/1000\n",
            "86/86 [==============================] - 0s 882us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 246/1000\n",
            "86/86 [==============================] - 0s 877us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 247/1000\n",
            "86/86 [==============================] - 0s 988us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 248/1000\n",
            "86/86 [==============================] - 0s 901us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 249/1000\n",
            "86/86 [==============================] - 0s 924us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 250/1000\n",
            "86/86 [==============================] - 0s 972us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 251/1000\n",
            "86/86 [==============================] - 0s 835us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 252/1000\n",
            "86/86 [==============================] - 0s 818us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 253/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 254/1000\n",
            "86/86 [==============================] - 0s 949us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 255/1000\n",
            "86/86 [==============================] - 0s 824us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 256/1000\n",
            "86/86 [==============================] - 0s 849us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 257/1000\n",
            "86/86 [==============================] - 0s 952us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 258/1000\n",
            "86/86 [==============================] - 0s 996us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 259/1000\n",
            "86/86 [==============================] - 0s 897us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 260/1000\n",
            "86/86 [==============================] - 0s 873us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 261/1000\n",
            "86/86 [==============================] - 0s 906us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 262/1000\n",
            "86/86 [==============================] - 0s 894us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 263/1000\n",
            "86/86 [==============================] - 0s 982us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 264/1000\n",
            "86/86 [==============================] - 0s 844us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 265/1000\n",
            "86/86 [==============================] - 0s 960us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 266/1000\n",
            "86/86 [==============================] - 0s 871us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 267/1000\n",
            "86/86 [==============================] - 0s 942us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 268/1000\n",
            "86/86 [==============================] - 0s 950us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 269/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 270/1000\n",
            "86/86 [==============================] - 0s 968us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 271/1000\n",
            "86/86 [==============================] - 0s 946us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 272/1000\n",
            "86/86 [==============================] - 0s 922us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 273/1000\n",
            "86/86 [==============================] - 0s 968us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 274/1000\n",
            "86/86 [==============================] - 0s 825us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 275/1000\n",
            "86/86 [==============================] - 0s 852us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 276/1000\n",
            "86/86 [==============================] - 0s 954us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 277/1000\n",
            "86/86 [==============================] - 0s 848us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 278/1000\n",
            "86/86 [==============================] - 0s 842us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 279/1000\n",
            "86/86 [==============================] - 0s 871us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 280/1000\n",
            "86/86 [==============================] - 0s 865us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 281/1000\n",
            "86/86 [==============================] - 0s 957us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 282/1000\n",
            "86/86 [==============================] - 0s 906us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 283/1000\n",
            "86/86 [==============================] - 0s 936us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 284/1000\n",
            "86/86 [==============================] - 0s 959us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 285/1000\n",
            "86/86 [==============================] - 0s 925us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 286/1000\n",
            "86/86 [==============================] - 0s 844us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 287/1000\n",
            "86/86 [==============================] - 0s 924us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 288/1000\n",
            "86/86 [==============================] - 0s 816us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 289/1000\n",
            "86/86 [==============================] - 0s 967us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 290/1000\n",
            "86/86 [==============================] - 0s 842us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 291/1000\n",
            "86/86 [==============================] - 0s 901us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 292/1000\n",
            "86/86 [==============================] - 0s 814us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 293/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 294/1000\n",
            "86/86 [==============================] - 0s 937us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 295/1000\n",
            "86/86 [==============================] - 0s 984us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 296/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 297/1000\n",
            "86/86 [==============================] - 0s 974us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 298/1000\n",
            "86/86 [==============================] - 0s 881us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 299/1000\n",
            "86/86 [==============================] - 0s 873us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 300/1000\n",
            "86/86 [==============================] - 0s 830us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 301/1000\n",
            "86/86 [==============================] - 0s 915us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 302/1000\n",
            "86/86 [==============================] - 0s 858us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 303/1000\n",
            "86/86 [==============================] - 0s 929us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 304/1000\n",
            "86/86 [==============================] - 0s 864us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 305/1000\n",
            "86/86 [==============================] - 0s 845us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 306/1000\n",
            "86/86 [==============================] - 0s 869us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 307/1000\n",
            "86/86 [==============================] - 0s 953us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 308/1000\n",
            "86/86 [==============================] - 0s 983us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 309/1000\n",
            "86/86 [==============================] - 0s 928us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 310/1000\n",
            "86/86 [==============================] - 0s 958us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 311/1000\n",
            "86/86 [==============================] - 0s 819us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 312/1000\n",
            "86/86 [==============================] - 0s 886us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 313/1000\n",
            "86/86 [==============================] - 0s 890us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 314/1000\n",
            "86/86 [==============================] - 0s 928us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 315/1000\n",
            "86/86 [==============================] - 0s 937us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 316/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 317/1000\n",
            "86/86 [==============================] - 0s 909us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 318/1000\n",
            "86/86 [==============================] - 0s 942us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 319/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 320/1000\n",
            "86/86 [==============================] - 0s 852us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 321/1000\n",
            "86/86 [==============================] - 0s 830us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 322/1000\n",
            "86/86 [==============================] - 0s 946us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 323/1000\n",
            "86/86 [==============================] - 0s 823us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 324/1000\n",
            "86/86 [==============================] - 0s 832us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 325/1000\n",
            "86/86 [==============================] - 0s 937us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 326/1000\n",
            "86/86 [==============================] - 0s 841us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 327/1000\n",
            "86/86 [==============================] - 0s 853us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 328/1000\n",
            "86/86 [==============================] - 0s 864us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 329/1000\n",
            "86/86 [==============================] - 0s 858us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 330/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 331/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 332/1000\n",
            "86/86 [==============================] - 0s 879us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 333/1000\n",
            "86/86 [==============================] - 0s 862us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 334/1000\n",
            "86/86 [==============================] - 0s 948us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 335/1000\n",
            "86/86 [==============================] - 0s 902us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 336/1000\n",
            "86/86 [==============================] - 0s 825us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 337/1000\n",
            "86/86 [==============================] - 0s 985us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 338/1000\n",
            "86/86 [==============================] - 0s 891us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 339/1000\n",
            "86/86 [==============================] - 0s 929us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 340/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 341/1000\n",
            "86/86 [==============================] - 0s 909us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 342/1000\n",
            "86/86 [==============================] - 0s 850us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 343/1000\n",
            "86/86 [==============================] - 0s 937us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 344/1000\n",
            "86/86 [==============================] - 0s 930us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 345/1000\n",
            "86/86 [==============================] - 0s 949us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 346/1000\n",
            "86/86 [==============================] - 0s 828us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 347/1000\n",
            "86/86 [==============================] - 0s 847us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 348/1000\n",
            "86/86 [==============================] - 0s 885us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 349/1000\n",
            "86/86 [==============================] - 0s 961us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 350/1000\n",
            "86/86 [==============================] - 0s 943us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 351/1000\n",
            "86/86 [==============================] - 0s 847us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 352/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 353/1000\n",
            "86/86 [==============================] - 0s 954us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 354/1000\n",
            "86/86 [==============================] - 0s 860us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 355/1000\n",
            "86/86 [==============================] - 0s 935us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 356/1000\n",
            "86/86 [==============================] - 0s 939us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 357/1000\n",
            "86/86 [==============================] - 0s 826us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 358/1000\n",
            "86/86 [==============================] - 0s 926us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 359/1000\n",
            "86/86 [==============================] - 0s 942us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 360/1000\n",
            "86/86 [==============================] - 0s 982us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 361/1000\n",
            "86/86 [==============================] - 0s 829us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 362/1000\n",
            "86/86 [==============================] - 0s 941us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 363/1000\n",
            "86/86 [==============================] - 0s 838us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 364/1000\n",
            "86/86 [==============================] - 0s 977us/step - loss: 0.0587 - val_loss: 0.0542\n",
            "Epoch 365/1000\n",
            "86/86 [==============================] - 0s 852us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 366/1000\n",
            "86/86 [==============================] - 0s 1000us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 367/1000\n",
            "86/86 [==============================] - 0s 850us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 368/1000\n",
            "86/86 [==============================] - 0s 917us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 369/1000\n",
            "86/86 [==============================] - 0s 905us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 370/1000\n",
            "86/86 [==============================] - 0s 924us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 371/1000\n",
            "86/86 [==============================] - 0s 857us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 372/1000\n",
            "86/86 [==============================] - 0s 900us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 373/1000\n",
            "86/86 [==============================] - 0s 962us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 374/1000\n",
            "86/86 [==============================] - 0s 838us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 375/1000\n",
            "86/86 [==============================] - 0s 861us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 376/1000\n",
            "86/86 [==============================] - 0s 923us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 377/1000\n",
            "86/86 [==============================] - 0s 866us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 378/1000\n",
            "86/86 [==============================] - 0s 881us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 379/1000\n",
            "86/86 [==============================] - 0s 915us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 380/1000\n",
            "86/86 [==============================] - 0s 838us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 381/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 382/1000\n",
            "86/86 [==============================] - 0s 942us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 383/1000\n",
            "86/86 [==============================] - 0s 854us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 384/1000\n",
            "86/86 [==============================] - 0s 914us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 385/1000\n",
            "86/86 [==============================] - 0s 843us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 386/1000\n",
            "86/86 [==============================] - 0s 924us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 387/1000\n",
            "86/86 [==============================] - 0s 936us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 388/1000\n",
            "86/86 [==============================] - 0s 853us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 389/1000\n",
            "86/86 [==============================] - 0s 955us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 390/1000\n",
            "86/86 [==============================] - 0s 978us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 391/1000\n",
            "86/86 [==============================] - 0s 841us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 392/1000\n",
            "86/86 [==============================] - 0s 807us/step - loss: 0.0588 - val_loss: 0.0542\n",
            "Epoch 393/1000\n",
            "86/86 [==============================] - 0s 979us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 394/1000\n",
            "86/86 [==============================] - 0s 977us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 395/1000\n",
            "86/86 [==============================] - 0s 1000us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 396/1000\n",
            "86/86 [==============================] - 0s 822us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 397/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 398/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 399/1000\n",
            "86/86 [==============================] - 0s 845us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 400/1000\n",
            "86/86 [==============================] - 0s 880us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 401/1000\n",
            "86/86 [==============================] - 0s 948us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 402/1000\n",
            "86/86 [==============================] - 0s 810us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 403/1000\n",
            "86/86 [==============================] - 0s 861us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 404/1000\n",
            "86/86 [==============================] - 0s 914us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 405/1000\n",
            "86/86 [==============================] - 0s 970us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 406/1000\n",
            "86/86 [==============================] - 0s 944us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 407/1000\n",
            "86/86 [==============================] - 0s 934us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 408/1000\n",
            "86/86 [==============================] - 0s 925us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 409/1000\n",
            "86/86 [==============================] - 0s 930us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 410/1000\n",
            "86/86 [==============================] - 0s 823us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 411/1000\n",
            "86/86 [==============================] - 0s 854us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 412/1000\n",
            "86/86 [==============================] - 0s 901us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 413/1000\n",
            "86/86 [==============================] - 0s 924us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 414/1000\n",
            "86/86 [==============================] - 0s 863us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 415/1000\n",
            "86/86 [==============================] - 0s 863us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 416/1000\n",
            "86/86 [==============================] - 0s 844us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 417/1000\n",
            "86/86 [==============================] - 0s 971us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 418/1000\n",
            "86/86 [==============================] - 0s 967us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 419/1000\n",
            "86/86 [==============================] - 0s 863us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 420/1000\n",
            "86/86 [==============================] - 0s 940us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 421/1000\n",
            "86/86 [==============================] - 0s 872us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 422/1000\n",
            "86/86 [==============================] - 0s 865us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 423/1000\n",
            "86/86 [==============================] - 0s 869us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 424/1000\n",
            "86/86 [==============================] - 0s 841us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 425/1000\n",
            "86/86 [==============================] - 0s 959us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 426/1000\n",
            "86/86 [==============================] - 0s 890us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 427/1000\n",
            "86/86 [==============================] - 0s 977us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 428/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 429/1000\n",
            "86/86 [==============================] - 0s 966us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 430/1000\n",
            "86/86 [==============================] - 0s 857us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 431/1000\n",
            "86/86 [==============================] - 0s 924us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 432/1000\n",
            "86/86 [==============================] - 0s 908us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 433/1000\n",
            "86/86 [==============================] - 0s 947us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 434/1000\n",
            "86/86 [==============================] - 0s 941us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 435/1000\n",
            "86/86 [==============================] - 0s 950us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 436/1000\n",
            "86/86 [==============================] - 0s 888us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 437/1000\n",
            "86/86 [==============================] - 0s 903us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 438/1000\n",
            "86/86 [==============================] - 0s 832us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 439/1000\n",
            "86/86 [==============================] - 0s 994us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 440/1000\n",
            "86/86 [==============================] - 0s 853us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 441/1000\n",
            "86/86 [==============================] - 0s 862us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 442/1000\n",
            "86/86 [==============================] - 0s 952us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 443/1000\n",
            "86/86 [==============================] - 0s 948us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 444/1000\n",
            "86/86 [==============================] - 0s 809us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 445/1000\n",
            "86/86 [==============================] - 0s 922us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 446/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 447/1000\n",
            "86/86 [==============================] - 0s 937us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 448/1000\n",
            "86/86 [==============================] - 0s 894us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 449/1000\n",
            "86/86 [==============================] - 0s 902us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 450/1000\n",
            "86/86 [==============================] - 0s 954us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 451/1000\n",
            "86/86 [==============================] - 0s 846us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 452/1000\n",
            "86/86 [==============================] - 0s 961us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 453/1000\n",
            "86/86 [==============================] - 0s 947us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 454/1000\n",
            "86/86 [==============================] - 0s 912us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 455/1000\n",
            "86/86 [==============================] - 0s 865us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 456/1000\n",
            "86/86 [==============================] - 0s 963us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 457/1000\n",
            "86/86 [==============================] - 0s 807us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 458/1000\n",
            "86/86 [==============================] - 0s 911us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 459/1000\n",
            "86/86 [==============================] - 0s 952us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 460/1000\n",
            "86/86 [==============================] - 0s 909us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 461/1000\n",
            "86/86 [==============================] - 0s 870us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 462/1000\n",
            "86/86 [==============================] - 0s 846us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 463/1000\n",
            "86/86 [==============================] - 0s 968us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 464/1000\n",
            "86/86 [==============================] - 0s 920us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 465/1000\n",
            "86/86 [==============================] - 0s 805us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 466/1000\n",
            "86/86 [==============================] - 0s 981us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 467/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 468/1000\n",
            "86/86 [==============================] - 0s 853us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 469/1000\n",
            "86/86 [==============================] - 0s 863us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 470/1000\n",
            "86/86 [==============================] - 0s 840us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 471/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 472/1000\n",
            "86/86 [==============================] - 0s 845us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 473/1000\n",
            "86/86 [==============================] - 0s 928us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 474/1000\n",
            "86/86 [==============================] - 0s 913us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 475/1000\n",
            "86/86 [==============================] - 0s 942us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 476/1000\n",
            "86/86 [==============================] - 0s 857us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 477/1000\n",
            "86/86 [==============================] - 0s 815us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 478/1000\n",
            "86/86 [==============================] - 0s 888us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 479/1000\n",
            "86/86 [==============================] - 0s 906us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 480/1000\n",
            "86/86 [==============================] - 0s 942us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 481/1000\n",
            "86/86 [==============================] - 0s 845us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 482/1000\n",
            "86/86 [==============================] - 0s 960us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 483/1000\n",
            "86/86 [==============================] - 0s 861us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 484/1000\n",
            "86/86 [==============================] - 0s 874us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 485/1000\n",
            "86/86 [==============================] - 0s 894us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 486/1000\n",
            "86/86 [==============================] - 0s 819us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 487/1000\n",
            "86/86 [==============================] - 0s 974us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 488/1000\n",
            "86/86 [==============================] - 0s 824us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 489/1000\n",
            "86/86 [==============================] - 0s 831us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 490/1000\n",
            "86/86 [==============================] - 0s 842us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 491/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 492/1000\n",
            "86/86 [==============================] - 0s 937us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 493/1000\n",
            "86/86 [==============================] - 0s 834us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 494/1000\n",
            "86/86 [==============================] - 0s 875us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 495/1000\n",
            "86/86 [==============================] - 0s 978us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 496/1000\n",
            "86/86 [==============================] - 0s 919us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 497/1000\n",
            "86/86 [==============================] - 0s 802us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 498/1000\n",
            "86/86 [==============================] - 0s 822us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 499/1000\n",
            "86/86 [==============================] - 0s 849us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 500/1000\n",
            "86/86 [==============================] - 0s 817us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 501/1000\n",
            "86/86 [==============================] - 0s 928us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 502/1000\n",
            "86/86 [==============================] - 0s 967us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 503/1000\n",
            "86/86 [==============================] - 0s 860us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 504/1000\n",
            "86/86 [==============================] - 0s 818us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 505/1000\n",
            "86/86 [==============================] - 0s 832us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 506/1000\n",
            "86/86 [==============================] - 0s 919us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 507/1000\n",
            "86/86 [==============================] - 0s 803us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 508/1000\n",
            "86/86 [==============================] - 0s 787us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 509/1000\n",
            "86/86 [==============================] - 0s 827us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 510/1000\n",
            "86/86 [==============================] - 0s 865us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 511/1000\n",
            "86/86 [==============================] - 0s 833us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 512/1000\n",
            "86/86 [==============================] - 0s 875us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 513/1000\n",
            "86/86 [==============================] - 0s 957us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 514/1000\n",
            "86/86 [==============================] - 0s 843us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 515/1000\n",
            "86/86 [==============================] - 0s 814us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 516/1000\n",
            "86/86 [==============================] - 0s 848us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 517/1000\n",
            "86/86 [==============================] - 0s 923us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 518/1000\n",
            "86/86 [==============================] - 0s 813us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 519/1000\n",
            "86/86 [==============================] - 0s 806us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 520/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 521/1000\n",
            "86/86 [==============================] - 0s 836us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 522/1000\n",
            "86/86 [==============================] - 0s 902us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 523/1000\n",
            "86/86 [==============================] - 0s 839us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 524/1000\n",
            "86/86 [==============================] - 0s 811us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 525/1000\n",
            "86/86 [==============================] - 0s 822us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 526/1000\n",
            "86/86 [==============================] - 0s 885us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 527/1000\n",
            "86/86 [==============================] - 0s 898us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 528/1000\n",
            "86/86 [==============================] - 0s 902us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 529/1000\n",
            "86/86 [==============================] - 0s 862us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 530/1000\n",
            "86/86 [==============================] - 0s 978us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 531/1000\n",
            "86/86 [==============================] - 0s 986us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 532/1000\n",
            "86/86 [==============================] - 0s 825us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 533/1000\n",
            "86/86 [==============================] - 0s 913us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 534/1000\n",
            "86/86 [==============================] - 0s 903us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 535/1000\n",
            "86/86 [==============================] - 0s 826us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 536/1000\n",
            "86/86 [==============================] - 0s 886us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 537/1000\n",
            "86/86 [==============================] - 0s 926us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 538/1000\n",
            "86/86 [==============================] - 0s 982us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 539/1000\n",
            "86/86 [==============================] - 0s 846us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 540/1000\n",
            "86/86 [==============================] - 0s 895us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 541/1000\n",
            "86/86 [==============================] - 0s 926us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 542/1000\n",
            "86/86 [==============================] - 0s 976us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 543/1000\n",
            "86/86 [==============================] - 0s 786us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 544/1000\n",
            "86/86 [==============================] - 0s 810us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 545/1000\n",
            "86/86 [==============================] - 0s 839us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 546/1000\n",
            "86/86 [==============================] - 0s 858us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 547/1000\n",
            "86/86 [==============================] - 0s 840us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 548/1000\n",
            "86/86 [==============================] - 0s 847us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 549/1000\n",
            "86/86 [==============================] - 0s 857us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 550/1000\n",
            "86/86 [==============================] - 0s 801us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 551/1000\n",
            "86/86 [==============================] - 0s 829us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 552/1000\n",
            "86/86 [==============================] - 0s 913us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 553/1000\n",
            "86/86 [==============================] - 0s 822us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 554/1000\n",
            "86/86 [==============================] - 0s 825us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 555/1000\n",
            "86/86 [==============================] - 0s 897us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 556/1000\n",
            "86/86 [==============================] - 0s 971us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 557/1000\n",
            "86/86 [==============================] - 0s 827us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 558/1000\n",
            "86/86 [==============================] - 0s 857us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 559/1000\n",
            "86/86 [==============================] - 0s 830us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 560/1000\n",
            "86/86 [==============================] - 0s 976us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 561/1000\n",
            "86/86 [==============================] - 0s 820us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 562/1000\n",
            "86/86 [==============================] - 0s 835us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 563/1000\n",
            "86/86 [==============================] - 0s 826us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 564/1000\n",
            "86/86 [==============================] - 0s 935us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 565/1000\n",
            "86/86 [==============================] - 0s 831us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 566/1000\n",
            "86/86 [==============================] - 0s 808us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 567/1000\n",
            "86/86 [==============================] - 0s 922us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 568/1000\n",
            "86/86 [==============================] - 0s 896us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 569/1000\n",
            "86/86 [==============================] - 0s 822us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 570/1000\n",
            "86/86 [==============================] - 0s 856us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 571/1000\n",
            "86/86 [==============================] - 0s 829us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 572/1000\n",
            "86/86 [==============================] - 0s 831us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 573/1000\n",
            "86/86 [==============================] - 0s 917us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 574/1000\n",
            "86/86 [==============================] - 0s 797us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 575/1000\n",
            "86/86 [==============================] - 0s 878us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 576/1000\n",
            "86/86 [==============================] - 0s 836us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 577/1000\n",
            "86/86 [==============================] - 0s 818us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 578/1000\n",
            "86/86 [==============================] - 0s 828us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 579/1000\n",
            "86/86 [==============================] - 0s 867us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 580/1000\n",
            "86/86 [==============================] - 0s 866us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 581/1000\n",
            "86/86 [==============================] - 0s 895us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 582/1000\n",
            "86/86 [==============================] - 0s 833us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 583/1000\n",
            "86/86 [==============================] - 0s 869us/step - loss: 0.0587 - val_loss: 0.0542\n",
            "Epoch 584/1000\n",
            "86/86 [==============================] - 0s 832us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 585/1000\n",
            "86/86 [==============================] - 0s 798us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 586/1000\n",
            "86/86 [==============================] - 0s 821us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 587/1000\n",
            "86/86 [==============================] - 0s 846us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 588/1000\n",
            "86/86 [==============================] - 0s 847us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 589/1000\n",
            "86/86 [==============================] - 0s 868us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 590/1000\n",
            "86/86 [==============================] - 0s 897us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 591/1000\n",
            "86/86 [==============================] - 0s 948us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 592/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 593/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 594/1000\n",
            "86/86 [==============================] - 0s 805us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 595/1000\n",
            "86/86 [==============================] - 0s 799us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 596/1000\n",
            "86/86 [==============================] - 0s 844us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 597/1000\n",
            "86/86 [==============================] - 0s 786us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 598/1000\n",
            "86/86 [==============================] - 0s 794us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 599/1000\n",
            "86/86 [==============================] - 0s 907us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 600/1000\n",
            "86/86 [==============================] - 0s 805us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 601/1000\n",
            "86/86 [==============================] - 0s 809us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 602/1000\n",
            "86/86 [==============================] - 0s 869us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 603/1000\n",
            "86/86 [==============================] - 0s 929us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 604/1000\n",
            "86/86 [==============================] - 0s 828us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 605/1000\n",
            "86/86 [==============================] - 0s 831us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 606/1000\n",
            "86/86 [==============================] - 0s 831us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 607/1000\n",
            "86/86 [==============================] - 0s 985us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 608/1000\n",
            "86/86 [==============================] - 0s 807us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 609/1000\n",
            "86/86 [==============================] - 0s 816us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 610/1000\n",
            "86/86 [==============================] - 0s 844us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 611/1000\n",
            "86/86 [==============================] - 0s 814us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 612/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 613/1000\n",
            "86/86 [==============================] - 0s 816us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 614/1000\n",
            "86/86 [==============================] - 0s 800us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 615/1000\n",
            "86/86 [==============================] - 0s 851us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 616/1000\n",
            "86/86 [==============================] - 0s 839us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 617/1000\n",
            "86/86 [==============================] - 0s 844us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 618/1000\n",
            "86/86 [==============================] - 0s 838us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 619/1000\n",
            "86/86 [==============================] - 0s 798us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 620/1000\n",
            "86/86 [==============================] - 0s 921us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 621/1000\n",
            "86/86 [==============================] - 0s 843us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 622/1000\n",
            "86/86 [==============================] - 0s 814us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 623/1000\n",
            "86/86 [==============================] - 0s 954us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 624/1000\n",
            "86/86 [==============================] - 0s 803us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 625/1000\n",
            "86/86 [==============================] - 0s 906us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 626/1000\n",
            "86/86 [==============================] - 0s 987us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 627/1000\n",
            "86/86 [==============================] - 0s 852us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 628/1000\n",
            "86/86 [==============================] - 0s 850us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 629/1000\n",
            "86/86 [==============================] - 0s 836us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 630/1000\n",
            "86/86 [==============================] - 0s 846us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 631/1000\n",
            "86/86 [==============================] - 0s 783us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 632/1000\n",
            "86/86 [==============================] - 0s 944us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 633/1000\n",
            "86/86 [==============================] - 0s 839us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 634/1000\n",
            "86/86 [==============================] - 0s 809us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 635/1000\n",
            "86/86 [==============================] - 0s 796us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 636/1000\n",
            "86/86 [==============================] - 0s 790us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 637/1000\n",
            "86/86 [==============================] - 0s 903us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 638/1000\n",
            "86/86 [==============================] - 0s 802us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 639/1000\n",
            "86/86 [==============================] - 0s 842us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 640/1000\n",
            "86/86 [==============================] - 0s 848us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 641/1000\n",
            "86/86 [==============================] - 0s 790us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 642/1000\n",
            "86/86 [==============================] - 0s 813us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 643/1000\n",
            "86/86 [==============================] - 0s 874us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 644/1000\n",
            "86/86 [==============================] - 0s 803us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 645/1000\n",
            "86/86 [==============================] - 0s 785us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 646/1000\n",
            "86/86 [==============================] - 0s 906us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 647/1000\n",
            "86/86 [==============================] - 0s 782us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 648/1000\n",
            "86/86 [==============================] - 0s 874us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 649/1000\n",
            "86/86 [==============================] - 0s 891us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 650/1000\n",
            "86/86 [==============================] - 0s 841us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 651/1000\n",
            "86/86 [==============================] - 0s 804us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 652/1000\n",
            "86/86 [==============================] - 0s 801us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 653/1000\n",
            "86/86 [==============================] - 0s 749us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 654/1000\n",
            "86/86 [==============================] - 0s 778us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 655/1000\n",
            "86/86 [==============================] - 0s 809us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 656/1000\n",
            "86/86 [==============================] - 0s 826us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 657/1000\n",
            "86/86 [==============================] - 0s 813us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 658/1000\n",
            "86/86 [==============================] - 0s 830us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 659/1000\n",
            "86/86 [==============================] - 0s 878us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 660/1000\n",
            "86/86 [==============================] - 0s 800us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 661/1000\n",
            "86/86 [==============================] - 0s 794us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 662/1000\n",
            "86/86 [==============================] - 0s 770us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 663/1000\n",
            "86/86 [==============================] - 0s 787us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 664/1000\n",
            "86/86 [==============================] - 0s 782us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 665/1000\n",
            "86/86 [==============================] - 0s 866us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 666/1000\n",
            "86/86 [==============================] - 0s 816us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 667/1000\n",
            "86/86 [==============================] - 0s 956us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 668/1000\n",
            "86/86 [==============================] - 0s 829us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 669/1000\n",
            "86/86 [==============================] - 0s 948us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 670/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 671/1000\n",
            "86/86 [==============================] - 0s 830us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 672/1000\n",
            "86/86 [==============================] - 0s 948us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 673/1000\n",
            "86/86 [==============================] - 0s 913us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 674/1000\n",
            "86/86 [==============================] - 0s 936us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 675/1000\n",
            "86/86 [==============================] - 0s 859us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 676/1000\n",
            "86/86 [==============================] - 0s 828us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 677/1000\n",
            "86/86 [==============================] - 0s 856us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 678/1000\n",
            "86/86 [==============================] - 0s 853us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 679/1000\n",
            "86/86 [==============================] - 0s 800us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 680/1000\n",
            "86/86 [==============================] - 0s 800us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 681/1000\n",
            "86/86 [==============================] - 0s 796us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 682/1000\n",
            "86/86 [==============================] - 0s 840us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 683/1000\n",
            "86/86 [==============================] - 0s 839us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 684/1000\n",
            "86/86 [==============================] - 0s 827us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 685/1000\n",
            "86/86 [==============================] - 0s 857us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 686/1000\n",
            "86/86 [==============================] - 0s 852us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 687/1000\n",
            "86/86 [==============================] - 0s 789us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 688/1000\n",
            "86/86 [==============================] - 0s 758us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 689/1000\n",
            "86/86 [==============================] - 0s 781us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 690/1000\n",
            "86/86 [==============================] - 0s 923us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 691/1000\n",
            "86/86 [==============================] - 0s 888us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 692/1000\n",
            "86/86 [==============================] - 0s 788us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 693/1000\n",
            "86/86 [==============================] - 0s 826us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 694/1000\n",
            "86/86 [==============================] - 0s 884us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 695/1000\n",
            "86/86 [==============================] - 0s 826us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 696/1000\n",
            "86/86 [==============================] - 0s 836us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 697/1000\n",
            "86/86 [==============================] - 0s 852us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 698/1000\n",
            "86/86 [==============================] - 0s 824us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 699/1000\n",
            "86/86 [==============================] - 0s 896us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 700/1000\n",
            "86/86 [==============================] - 0s 846us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 701/1000\n",
            "86/86 [==============================] - 0s 816us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 702/1000\n",
            "86/86 [==============================] - 0s 782us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 703/1000\n",
            "86/86 [==============================] - 0s 819us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 704/1000\n",
            "86/86 [==============================] - 0s 815us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 705/1000\n",
            "86/86 [==============================] - 0s 840us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 706/1000\n",
            "86/86 [==============================] - 0s 831us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 707/1000\n",
            "86/86 [==============================] - 0s 806us/step - loss: 0.0587 - val_loss: 0.0542\n",
            "Epoch 708/1000\n",
            "86/86 [==============================] - 0s 796us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 709/1000\n",
            "86/86 [==============================] - 0s 911us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 710/1000\n",
            "86/86 [==============================] - 0s 774us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 711/1000\n",
            "86/86 [==============================] - 0s 850us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 712/1000\n",
            "86/86 [==============================] - 0s 991us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 713/1000\n",
            "86/86 [==============================] - 0s 759us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 714/1000\n",
            "86/86 [==============================] - 0s 826us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 715/1000\n",
            "86/86 [==============================] - 0s 884us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 716/1000\n",
            "86/86 [==============================] - 0s 824us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 717/1000\n",
            "86/86 [==============================] - 0s 856us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 718/1000\n",
            "86/86 [==============================] - 0s 842us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 719/1000\n",
            "86/86 [==============================] - 0s 955us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 720/1000\n",
            "86/86 [==============================] - 0s 841us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 721/1000\n",
            "86/86 [==============================] - 0s 825us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 722/1000\n",
            "86/86 [==============================] - 0s 785us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 723/1000\n",
            "86/86 [==============================] - 0s 956us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 724/1000\n",
            "86/86 [==============================] - 0s 799us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 725/1000\n",
            "86/86 [==============================] - 0s 881us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 726/1000\n",
            "86/86 [==============================] - 0s 811us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 727/1000\n",
            "86/86 [==============================] - 0s 787us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 728/1000\n",
            "86/86 [==============================] - 0s 789us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 729/1000\n",
            "86/86 [==============================] - 0s 809us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 730/1000\n",
            "86/86 [==============================] - 0s 946us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 731/1000\n",
            "86/86 [==============================] - 0s 792us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 732/1000\n",
            "86/86 [==============================] - 0s 801us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 733/1000\n",
            "86/86 [==============================] - 0s 933us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 734/1000\n",
            "86/86 [==============================] - 0s 831us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 735/1000\n",
            "86/86 [==============================] - 0s 869us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 736/1000\n",
            "86/86 [==============================] - 0s 876us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 737/1000\n",
            "86/86 [==============================] - 0s 814us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 738/1000\n",
            "86/86 [==============================] - 0s 828us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 739/1000\n",
            "86/86 [==============================] - 0s 819us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 740/1000\n",
            "86/86 [==============================] - 0s 836us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 741/1000\n",
            "86/86 [==============================] - 0s 826us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 742/1000\n",
            "86/86 [==============================] - 0s 807us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 743/1000\n",
            "86/86 [==============================] - 0s 828us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 744/1000\n",
            "86/86 [==============================] - 0s 837us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 745/1000\n",
            "86/86 [==============================] - 0s 813us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 746/1000\n",
            "86/86 [==============================] - 0s 771us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 747/1000\n",
            "86/86 [==============================] - 0s 826us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 748/1000\n",
            "86/86 [==============================] - 0s 914us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 749/1000\n",
            "86/86 [==============================] - 0s 807us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 750/1000\n",
            "86/86 [==============================] - 0s 801us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 751/1000\n",
            "86/86 [==============================] - 0s 816us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 752/1000\n",
            "86/86 [==============================] - 0s 771us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 753/1000\n",
            "86/86 [==============================] - 0s 796us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 754/1000\n",
            "86/86 [==============================] - 0s 789us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 755/1000\n",
            "86/86 [==============================] - 0s 837us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 756/1000\n",
            "86/86 [==============================] - 0s 835us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 757/1000\n",
            "86/86 [==============================] - 0s 841us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 758/1000\n",
            "86/86 [==============================] - 0s 778us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 759/1000\n",
            "86/86 [==============================] - 0s 765us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 760/1000\n",
            "86/86 [==============================] - 0s 827us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 761/1000\n",
            "86/86 [==============================] - 0s 831us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 762/1000\n",
            "86/86 [==============================] - 0s 762us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 763/1000\n",
            "86/86 [==============================] - 0s 887us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 764/1000\n",
            "86/86 [==============================] - 0s 847us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 765/1000\n",
            "86/86 [==============================] - 0s 929us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 766/1000\n",
            "86/86 [==============================] - 0s 773us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 767/1000\n",
            "86/86 [==============================] - 0s 765us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 768/1000\n",
            "86/86 [==============================] - 0s 820us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 769/1000\n",
            "86/86 [==============================] - 0s 854us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 770/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 771/1000\n",
            "86/86 [==============================] - 0s 924us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 772/1000\n",
            "86/86 [==============================] - 0s 844us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 773/1000\n",
            "86/86 [==============================] - 0s 835us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 774/1000\n",
            "86/86 [==============================] - 0s 960us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 775/1000\n",
            "86/86 [==============================] - 0s 803us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 776/1000\n",
            "86/86 [==============================] - 0s 776us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 777/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 778/1000\n",
            "86/86 [==============================] - 0s 816us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 779/1000\n",
            "86/86 [==============================] - 0s 791us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 780/1000\n",
            "86/86 [==============================] - 0s 773us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 781/1000\n",
            "86/86 [==============================] - 0s 847us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 782/1000\n",
            "86/86 [==============================] - 0s 832us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 783/1000\n",
            "86/86 [==============================] - 0s 803us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 784/1000\n",
            "86/86 [==============================] - 0s 809us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 785/1000\n",
            "86/86 [==============================] - 0s 829us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 786/1000\n",
            "86/86 [==============================] - 0s 836us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 787/1000\n",
            "86/86 [==============================] - 0s 895us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 788/1000\n",
            "86/86 [==============================] - 0s 987us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 789/1000\n",
            "86/86 [==============================] - 0s 787us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 790/1000\n",
            "86/86 [==============================] - 0s 795us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 791/1000\n",
            "86/86 [==============================] - 0s 935us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 792/1000\n",
            "86/86 [==============================] - 0s 846us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 793/1000\n",
            "86/86 [==============================] - 0s 866us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 794/1000\n",
            "86/86 [==============================] - 0s 824us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 795/1000\n",
            "86/86 [==============================] - 0s 857us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 796/1000\n",
            "86/86 [==============================] - 0s 882us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 797/1000\n",
            "86/86 [==============================] - 0s 975us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 798/1000\n",
            "86/86 [==============================] - 0s 842us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 799/1000\n",
            "86/86 [==============================] - 0s 870us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 800/1000\n",
            "86/86 [==============================] - 0s 893us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 801/1000\n",
            "86/86 [==============================] - 0s 801us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 802/1000\n",
            "86/86 [==============================] - 0s 840us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 803/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 804/1000\n",
            "86/86 [==============================] - 0s 916us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 805/1000\n",
            "86/86 [==============================] - 0s 785us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 806/1000\n",
            "86/86 [==============================] - 0s 944us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 807/1000\n",
            "86/86 [==============================] - 0s 818us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 808/1000\n",
            "86/86 [==============================] - 0s 922us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 809/1000\n",
            "86/86 [==============================] - 0s 811us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 810/1000\n",
            "86/86 [==============================] - 0s 957us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 811/1000\n",
            "86/86 [==============================] - 0s 824us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 812/1000\n",
            "86/86 [==============================] - 0s 825us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 813/1000\n",
            "86/86 [==============================] - 0s 918us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 814/1000\n",
            "86/86 [==============================] - 0s 930us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 815/1000\n",
            "86/86 [==============================] - 0s 770us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 816/1000\n",
            "86/86 [==============================] - 0s 953us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 817/1000\n",
            "86/86 [==============================] - 0s 947us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 818/1000\n",
            "86/86 [==============================] - 0s 818us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 819/1000\n",
            "86/86 [==============================] - 0s 820us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 820/1000\n",
            "86/86 [==============================] - 0s 850us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 821/1000\n",
            "86/86 [==============================] - 0s 811us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 822/1000\n",
            "86/86 [==============================] - 0s 929us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 823/1000\n",
            "86/86 [==============================] - 0s 847us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 824/1000\n",
            "86/86 [==============================] - 0s 925us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 825/1000\n",
            "86/86 [==============================] - 0s 862us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 826/1000\n",
            "86/86 [==============================] - 0s 836us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 827/1000\n",
            "86/86 [==============================] - 0s 872us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 828/1000\n",
            "86/86 [==============================] - 0s 949us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 829/1000\n",
            "86/86 [==============================] - 0s 841us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 830/1000\n",
            "86/86 [==============================] - 0s 822us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 831/1000\n",
            "86/86 [==============================] - 0s 775us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 832/1000\n",
            "86/86 [==============================] - 0s 937us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 833/1000\n",
            "86/86 [==============================] - 0s 926us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 834/1000\n",
            "86/86 [==============================] - 0s 789us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 835/1000\n",
            "86/86 [==============================] - 0s 787us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 836/1000\n",
            "86/86 [==============================] - 0s 950us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 837/1000\n",
            "86/86 [==============================] - 0s 886us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 838/1000\n",
            "86/86 [==============================] - 0s 811us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 839/1000\n",
            "86/86 [==============================] - 0s 817us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 840/1000\n",
            "86/86 [==============================] - 0s 822us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 841/1000\n",
            "86/86 [==============================] - 0s 842us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 842/1000\n",
            "86/86 [==============================] - 0s 924us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 843/1000\n",
            "86/86 [==============================] - 0s 784us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 844/1000\n",
            "86/86 [==============================] - 0s 831us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 845/1000\n",
            "86/86 [==============================] - 0s 815us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 846/1000\n",
            "86/86 [==============================] - 0s 805us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 847/1000\n",
            "86/86 [==============================] - 0s 808us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 848/1000\n",
            "86/86 [==============================] - 0s 802us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 849/1000\n",
            "86/86 [==============================] - 0s 786us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 850/1000\n",
            "86/86 [==============================] - 0s 785us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 851/1000\n",
            "86/86 [==============================] - 0s 807us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 852/1000\n",
            "86/86 [==============================] - 0s 961us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 853/1000\n",
            "86/86 [==============================] - 0s 798us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 854/1000\n",
            "86/86 [==============================] - 0s 818us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 855/1000\n",
            "86/86 [==============================] - 0s 990us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 856/1000\n",
            "86/86 [==============================] - 0s 765us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 857/1000\n",
            "86/86 [==============================] - 0s 833us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 858/1000\n",
            "86/86 [==============================] - 0s 875us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 859/1000\n",
            "86/86 [==============================] - 0s 805us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 860/1000\n",
            "86/86 [==============================] - 0s 765us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 861/1000\n",
            "86/86 [==============================] - 0s 770us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 862/1000\n",
            "86/86 [==============================] - 0s 790us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 863/1000\n",
            "86/86 [==============================] - 0s 791us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 864/1000\n",
            "86/86 [==============================] - 0s 855us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 865/1000\n",
            "86/86 [==============================] - 0s 836us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 866/1000\n",
            "86/86 [==============================] - 0s 812us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 867/1000\n",
            "86/86 [==============================] - 0s 800us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 868/1000\n",
            "86/86 [==============================] - 0s 784us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 869/1000\n",
            "86/86 [==============================] - 0s 829us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 870/1000\n",
            "86/86 [==============================] - 0s 845us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 871/1000\n",
            "86/86 [==============================] - 0s 959us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 872/1000\n",
            "86/86 [==============================] - 0s 796us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 873/1000\n",
            "86/86 [==============================] - 0s 807us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 874/1000\n",
            "86/86 [==============================] - 0s 803us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 875/1000\n",
            "86/86 [==============================] - 0s 803us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 876/1000\n",
            "86/86 [==============================] - 0s 838us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 877/1000\n",
            "86/86 [==============================] - 0s 823us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 878/1000\n",
            "86/86 [==============================] - 0s 830us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 879/1000\n",
            "86/86 [==============================] - 0s 795us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 880/1000\n",
            "86/86 [==============================] - 0s 786us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 881/1000\n",
            "86/86 [==============================] - 0s 840us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 882/1000\n",
            "86/86 [==============================] - 0s 835us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 883/1000\n",
            "86/86 [==============================] - 0s 810us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 884/1000\n",
            "86/86 [==============================] - 0s 791us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 885/1000\n",
            "86/86 [==============================] - 0s 943us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 886/1000\n",
            "86/86 [==============================] - 0s 805us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 887/1000\n",
            "86/86 [==============================] - 0s 827us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 888/1000\n",
            "86/86 [==============================] - 0s 894us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 889/1000\n",
            "86/86 [==============================] - 0s 810us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 890/1000\n",
            "86/86 [==============================] - 0s 770us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 891/1000\n",
            "86/86 [==============================] - 0s 797us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 892/1000\n",
            "86/86 [==============================] - 0s 843us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 893/1000\n",
            "86/86 [==============================] - 0s 803us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 894/1000\n",
            "86/86 [==============================] - 0s 849us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 895/1000\n",
            "86/86 [==============================] - 0s 830us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 896/1000\n",
            "86/86 [==============================] - 0s 894us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 897/1000\n",
            "86/86 [==============================] - 0s 768us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 898/1000\n",
            "86/86 [==============================] - 0s 806us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 899/1000\n",
            "86/86 [==============================] - 0s 777us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 900/1000\n",
            "86/86 [==============================] - 0s 782us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 901/1000\n",
            "86/86 [==============================] - 0s 786us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 902/1000\n",
            "86/86 [==============================] - 0s 772us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 903/1000\n",
            "86/86 [==============================] - 0s 762us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 904/1000\n",
            "86/86 [==============================] - 0s 809us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 905/1000\n",
            "86/86 [==============================] - 0s 826us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 906/1000\n",
            "86/86 [==============================] - 0s 799us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 907/1000\n",
            "86/86 [==============================] - 0s 773us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 908/1000\n",
            "86/86 [==============================] - 0s 962us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 909/1000\n",
            "86/86 [==============================] - 0s 876us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 910/1000\n",
            "86/86 [==============================] - 0s 792us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 911/1000\n",
            "86/86 [==============================] - 0s 821us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 912/1000\n",
            "86/86 [==============================] - 0s 814us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 913/1000\n",
            "86/86 [==============================] - 0s 826us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 914/1000\n",
            "86/86 [==============================] - 0s 781us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 915/1000\n",
            "86/86 [==============================] - 0s 877us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 916/1000\n",
            "86/86 [==============================] - 0s 861us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 917/1000\n",
            "86/86 [==============================] - 0s 766us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 918/1000\n",
            "86/86 [==============================] - 0s 843us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 919/1000\n",
            "86/86 [==============================] - 0s 884us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 920/1000\n",
            "86/86 [==============================] - 0s 774us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 921/1000\n",
            "86/86 [==============================] - 0s 759us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 922/1000\n",
            "86/86 [==============================] - 0s 807us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 923/1000\n",
            "86/86 [==============================] - 0s 909us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 924/1000\n",
            "86/86 [==============================] - 0s 805us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 925/1000\n",
            "86/86 [==============================] - 0s 874us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 926/1000\n",
            "86/86 [==============================] - 0s 837us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 927/1000\n",
            "86/86 [==============================] - 0s 824us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 928/1000\n",
            "86/86 [==============================] - 0s 843us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 929/1000\n",
            "86/86 [==============================] - 0s 799us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 930/1000\n",
            "86/86 [==============================] - 0s 807us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 931/1000\n",
            "86/86 [==============================] - 0s 801us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 932/1000\n",
            "86/86 [==============================] - 0s 829us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 933/1000\n",
            "86/86 [==============================] - 0s 834us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 934/1000\n",
            "86/86 [==============================] - 0s 887us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 935/1000\n",
            "86/86 [==============================] - 0s 789us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 936/1000\n",
            "86/86 [==============================] - 0s 880us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 937/1000\n",
            "86/86 [==============================] - 0s 829us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 938/1000\n",
            "86/86 [==============================] - 0s 896us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 939/1000\n",
            "86/86 [==============================] - 0s 846us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 940/1000\n",
            "86/86 [==============================] - 0s 844us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 941/1000\n",
            "86/86 [==============================] - 0s 780us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 942/1000\n",
            "86/86 [==============================] - 0s 788us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 943/1000\n",
            "86/86 [==============================] - 0s 772us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 944/1000\n",
            "86/86 [==============================] - 0s 750us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 945/1000\n",
            "86/86 [==============================] - 0s 979us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 946/1000\n",
            "86/86 [==============================] - 0s 800us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 947/1000\n",
            "86/86 [==============================] - 0s 788us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 948/1000\n",
            "86/86 [==============================] - 0s 773us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 949/1000\n",
            "86/86 [==============================] - 0s 821us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 950/1000\n",
            "86/86 [==============================] - 0s 934us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 951/1000\n",
            "86/86 [==============================] - 0s 794us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 952/1000\n",
            "86/86 [==============================] - 0s 846us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 953/1000\n",
            "86/86 [==============================] - 0s 855us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 954/1000\n",
            "86/86 [==============================] - 0s 936us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 955/1000\n",
            "86/86 [==============================] - 0s 788us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 956/1000\n",
            "86/86 [==============================] - 0s 805us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 957/1000\n",
            "86/86 [==============================] - 0s 845us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 958/1000\n",
            "86/86 [==============================] - 0s 800us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 959/1000\n",
            "86/86 [==============================] - 0s 803us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 960/1000\n",
            "86/86 [==============================] - 0s 930us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 961/1000\n",
            "86/86 [==============================] - 0s 791us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 962/1000\n",
            "86/86 [==============================] - 0s 817us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 963/1000\n",
            "86/86 [==============================] - 0s 942us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 964/1000\n",
            "86/86 [==============================] - 0s 807us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 965/1000\n",
            "86/86 [==============================] - 0s 829us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 966/1000\n",
            "86/86 [==============================] - 0s 877us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 967/1000\n",
            "86/86 [==============================] - 0s 814us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 968/1000\n",
            "86/86 [==============================] - 0s 824us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 969/1000\n",
            "86/86 [==============================] - 0s 907us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 970/1000\n",
            "86/86 [==============================] - 0s 803us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 971/1000\n",
            "86/86 [==============================] - 0s 897us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 972/1000\n",
            "86/86 [==============================] - 0s 797us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 973/1000\n",
            "86/86 [==============================] - 0s 804us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 974/1000\n",
            "86/86 [==============================] - 0s 830us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 975/1000\n",
            "86/86 [==============================] - 0s 791us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 976/1000\n",
            "86/86 [==============================] - 0s 844us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 977/1000\n",
            "86/86 [==============================] - 0s 823us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 978/1000\n",
            "86/86 [==============================] - 0s 813us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 979/1000\n",
            "86/86 [==============================] - 0s 850us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 980/1000\n",
            "86/86 [==============================] - 0s 794us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 981/1000\n",
            "86/86 [==============================] - 0s 797us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 982/1000\n",
            "86/86 [==============================] - 0s 880us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 983/1000\n",
            "86/86 [==============================] - 0s 827us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 984/1000\n",
            "86/86 [==============================] - 0s 845us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 985/1000\n",
            "86/86 [==============================] - 0s 818us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 986/1000\n",
            "86/86 [==============================] - 0s 917us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 987/1000\n",
            "86/86 [==============================] - 0s 773us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 988/1000\n",
            "86/86 [==============================] - 0s 768us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 989/1000\n",
            "86/86 [==============================] - 0s 779us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 990/1000\n",
            "86/86 [==============================] - 0s 932us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 991/1000\n",
            "86/86 [==============================] - 0s 817us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 992/1000\n",
            "86/86 [==============================] - 0s 834us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 993/1000\n",
            "86/86 [==============================] - 0s 832us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 994/1000\n",
            "86/86 [==============================] - 0s 857us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 995/1000\n",
            "86/86 [==============================] - 0s 760us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 996/1000\n",
            "86/86 [==============================] - 0s 792us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 997/1000\n",
            "86/86 [==============================] - 0s 806us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 998/1000\n",
            "86/86 [==============================] - 0s 772us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 999/1000\n",
            "86/86 [==============================] - 0s 851us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 1000/1000\n",
            "86/86 [==============================] - 0s 834us/step - loss: 0.0587 - val_loss: 0.0540\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qmz5OeNpcaKy",
        "outputId": "c8d17214-8ddf-46b2-b9cc-35d27a3a3ea5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "loss = model.evaluate(feature_test, label_test, verbose=2)\n",
        "\n",
        "print(\"Test loss:\", loss)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29/29 - 0s - loss: 0.0540\n",
            "Test loss: 0.05398981645703316\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97j0EAmHcjFC",
        "outputId": "50189ce9-45cb-4260-9e89-e0f5f880afa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "history_dataframe = pd.DataFrame(history.history)\n",
        "history_dataframe['epoch'] = history.epoch\n",
        "history_dataframe.sort_values(by='val_loss', ascending=True)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>238</th>\n",
              "      <td>0.058748</td>\n",
              "      <td>0.053976</td>\n",
              "      <td>238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>453</th>\n",
              "      <td>0.058748</td>\n",
              "      <td>0.053976</td>\n",
              "      <td>453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>505</th>\n",
              "      <td>0.058796</td>\n",
              "      <td>0.053976</td>\n",
              "      <td>505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>603</th>\n",
              "      <td>0.058731</td>\n",
              "      <td>0.053976</td>\n",
              "      <td>603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>0.058794</td>\n",
              "      <td>0.053977</td>\n",
              "      <td>764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.059083</td>\n",
              "      <td>0.054231</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.059230</td>\n",
              "      <td>0.054280</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.059445</td>\n",
              "      <td>0.054366</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.059935</td>\n",
              "      <td>0.054529</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.066392</td>\n",
              "      <td>0.056087</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         loss  val_loss  epoch\n",
              "238  0.058748  0.053976    238\n",
              "453  0.058748  0.053976    453\n",
              "505  0.058796  0.053976    505\n",
              "603  0.058731  0.053976    603\n",
              "764  0.058794  0.053977    764\n",
              "..        ...       ...    ...\n",
              "4    0.059083  0.054231      4\n",
              "3    0.059230  0.054280      3\n",
              "2    0.059445  0.054366      2\n",
              "1    0.059935  0.054529      1\n",
              "0    0.066392  0.056087      0\n",
              "\n",
              "[1000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vr3MulkmcjKS",
        "outputId": "f6c37db5-b20a-40ef-fa9e-c8766f9f4e3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "plot_loss(history) # epoch vs loss graph"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEGCAYAAABy53LJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxcVd348c83M1mbNOmaLimkpYXaBVoIm5ZSFitVoYhgqaiAKA8oIPJ7+VCEBwRRHxRBUQSrIAgoIFWfAsWqtGlBoHSh+0a6p3vS7JnJZGa+vz/uTZrMJJNMmmnS5Pt+veaVe8895845c+/MN+eeu4iqYowxxrRXUldXwBhjzInFAocxxpi4WOAwxhgTFwscxhhj4mKBwxhjTFy8XV2B42HgwIGan5/fobI1NTX06dOncyvUzVmbewdrc+9wLG1euXJliaoOikzvFYEjPz+fFStWdKhsYWEh06ZN69wKdXPW5t7B2tw7HEubRWRXS+l2qMoYY0xcLHAYY4yJiwUOY4wxcekVYxzGmN6nvr6e4uJi/H5/Y1p2djabNm3qwlodf+1pc1paGnl5eSQnJ7drnRY4jDE9UnFxMVlZWeTn5yMiAFRVVZGVldXFNTu+2mqzqlJaWkpxcTEjR45s1zrtUJUxpkfy+/0MGDCgMWiYlokIAwYMaNYza4sFDmNMj2VBo33i/ZwscMTw3H92sGx/sKurYYwx3YqNccTw4rLd5IgFDmNMx2RmZlJdXd3V1eh01uOIwTq5xhgTzQKHMcYkmKryve99jwkTJjBx4kReeeUVAPbv38/UqVOZNGkSEyZM4J133iEUCnHDDTc05n388ce7uPbREnqoSkQuA34JeIDfq+r/RixPBf4InAWUArNUdae77HTgt0BfIAycrap+EUkBfg1Mc9PvVdV5iak/2IN1jTnxPfj6BjbuqyQUCuHxeDplneOG9eWBy8e3K+9f//pXVq9ezZo1aygpKeHss89m6tSp/OlPf+Izn/kM9957L6FQiNraWlavXs3evXtZv349AOXl5Z1S386UsMAhIh7gSeDTQDGwXETmq+rGJtluAspUdbSIXAs8AswSES/wIvBVVV0jIgOAerfMvcAhVT1VRJKA/glrgx2sMsZ0gnfffZfZs2fj8XjIzc3lwgsvZPny5Zx99tl8/etfp76+niuvvJJJkyYxatQotm/fzu23387nPvc5pk+f3tXVj5LIHsc5QJGqbgcQkZeBmUDTwDET+IE7/Rrwa3HOC5sOrFXVNQCqWtqkzNeBsW56GChJVANEsC6HMT1AQ8+gu10AOHXqVJYuXcqbb77JDTfcwF133cXXvvY11qxZw8KFC3n66ad59dVXefbZZ7u6qs0kMnAMB/Y0mS8Gzm0tj6oGRaQCGACcCqiILAQGAS+r6k9FJMct90MRmQZsA25T1YORby4iNwM3A+Tm5lJYWBh3A6qra0lJCXeo7Imsurra2twL9PQ2Z2dnU1VV1SwtFApFpSVaVVUVBQUFPPvss1x11VWUlZWxZMkSHnjgATZs2MDw4cO59tprqaio4IMPPmDq1KkkJyczffp08vLy+OY3v3lMdW5vm/1+f7v3h+56Oq4XmAKcDdQCb4vISmANkAe8p6p3ichdwKPAVyNXoKpzgbkABQUF2pH70WeuXoonXGv37+8FrM09z6ZNm6J6F13R48jKyuLLX/4yq1evZsqUKYgIP/vZzxg9ejTPP/88s2bNIjk5mczMTP74xz9SUVHBjTfeSDgcBuCRRx45pjq3t81paWlMnjy5XetMZODYC4xoMp/nprWUp9gd18jGGSQvBpaqagmAiCwAzgQW4QSSv7rl/4IzTpIQdtWpMeZYNFzD0RAsfvaznzVbfv3113P99ddHlVu1atVxqV9HJfJ03OXAGBEZ6Z4JdS0wPyLPfKDhU7saWKSqCiwEJopIhhtQLgQ2ustexzmjCuASmo+ZdCoB1MY4jDGmmYT1ONwxi9twgoAHeFZVN4jIQ8AKVZ0PPAO8ICJFwBGc4IKqlonIYzjBR4EFqvqmu+q73TK/AA4DNyaqDdbhMMaYaAkd41DVBcCCiLT7m0z7gWtaKfsizim5kem7gKmdW9PWWYfDGGOasyvHY7AehzHGRLPAEYMg1uMwxpgIFjhisB6HMcZEs8DRFutyGGNMMxY4YrA7jhhjjqfMzMxWl+3cuZMJEyYcx9q0zgJHLGJjHMYYE6m73nKkW7AhDmN6iLfmwIF1pIeC4Omkn70hE2HG/8bMMmfOHEaMGMG3v/1tAH7wgx/g9XpZvHgxZWVl1NfX8/DDDzNz5sy43trv93PrrbeyYsUKvF4vjz32GBdddBEbNmzgxhtvJBAIEA6HmTdvHllZWVx77bUUFxcTCoX4n//5H2bNmtXhZoMFjrZZl8MY00GzZs3izjvvbAwcr776KgsXLuSOO+6gb9++lJSUcN5553HFFVfEdYujJ598EhFh3bp1bN68menTp7N161aefvppvvOd73DdddcRCAQIhULMmzePYcOG8eabzjXUFRUVx9wuCxwxOA9ysshhzAnP7Rn4jvNNDidPnsyhQ4fYt28fhw8fpl+/fgwZMoTvfve7LF26lKSkJPbu3cvBgwcZMmRIu9f77rvvcvvttwMwduxYTj75ZLZu3cr555/Pj370I4qLi7nqqqsYM2YM48aN47777uPuu+/m85//PBdccMExt8vGOGKwQ1XGmGN1zTXX8Nprr/HKK68wa9YsXnrpJQ4fPszKlStZvXo1ubm5+P3+TnmvL3/5y8yfP5/09HQ++9nPsmjRIsaMGcOqVauYOHEi9913Hw899NAxv4/1OGKwu+MaY47VrFmz+OY3v0lJSQlLlizh1VdfZfDgwSQnJ7N48WJ27doV9zovuOACXnrpJS6++GK2bt3K7t27Oe2009i+fTujRo3ijjvuYPfu3axdu5a8vDxOOukkvvKVr5CTk8Pvf//7Y26TBY422IEqY8yxGD9+PFVVVQwfPpyhQ4dy3XXXcfnllzNx4kQKCgoYO3Zs3Ov81re+xa233srEiRPxer0899xzpKam8uqrr/LCCy+QnJzMkCFD+P73v8+SJUu4+uqrSUpKIjk5maeeeuqY22SBIwa7rboxpjOsW7eucXrgwIG8//77LeZreH5HS/Lz81m/fj3gPHTpD3/4Q1SeOXPmMGfOnGZpl156KV/4whc6Uu1W2RhHDHakyhhjolmPIwax4XFjzHG2bt06vvrV5k/DTk1NZdmyZV1Uo2gWONpgR6qMOXGp6gl3ksvEiRNZvXr1cX1PjfOYvB2qikVsjMOYE1VaWhqlpaVx/yj2NqpKaWkpaWlp7S5jPY4YTqz/U4wxTeXl5VFcXMzhw4cb0/x+f1w/kD1Be9qclpZGXl5eu9dpgSMG58pxY8yJKDk5mZEjRzZLKywsZPLkyV1Uo66RiDbboaoYbHDcGGOiWeAwxhgTFwscMYgNjhtjTBQLHDHYGIcxxkRLaOAQkctEZIuIFInInBaWp4rIK+7yZSKS32TZ6SLyvohsEJF1IpIWUXa+iKxPaP1tjMMYY6IkLHCIiAd4EpgBjANmi8i4iGw3AWWqOhp4HHjELesFXgRuUdXxwDSgvsm6rwJav6mLMcaYhElkj+McoEhVt6tqAHgZiHw+4kzgeXf6NeAScS7znA6sVdU1AKpaqqohABHJBO4CHk5g3XHey8Y4jDEmUiKv4xgO7GkyXwyc21oeVQ2KSAUwADgVUBFZCAwCXlbVn7plfgj8HKiN9eYicjNwM0Bubi6FhYVxN6DsiJ9QONShsiey6upqa3MvYG3uHRLR5u56AaAXmAKcjRMg3haRlUApcIqqfrfpeEhLVHUuMBegoKBAp02bFnclnt3+IbUHS+lI2RNZYWGhtbkXsDb3DolocyIDx15gRJP5PDetpTzF7rhGNk5wKAaWqmoJgIgsAM7EGdcoEJGdbt0Hi0ihqk5LYDuMMcY0kcgxjuXAGBEZKSIpwLXA/Ig884Hr3emrgUXq3JFsITBRRDLcgHIhsFFVn1LVYaqaj9Mj2ZrIoCHY6bjGGBMpYT0Od8ziNpwg4AGeVdUNIvIQsEJV5wPPAC+ISBFwBCe4oKplIvIYTvBRYIGqvpmourZGLHIYY0yUhI5xqOoCYEFE2v1Npv3ANa2UfRHnlNzW1r0TmNApFW2FXcVhjDHR7MrxNliHwxhjmrPAEYOIWOAwxpgIFjhisENVxhgTzQJHDHbluDHGRLPAEZP1OYwxJpIFjjZYh8MYY5qzwBGDWIfDGGOiWOCIQQC1QQ5jjGnGAkcM1uMwxphoFjiMMcbExQJHDIJdAGiMMZEscMQgYmdVGWNMJAscMdgYhzHGRLPA0RbrchhjTDMWOGKwMQ5jjIlmgSMWG+MwxpgoFjhisCEOY4yJZoGjLdblMMaYZixwxGAPcjLGmGgWOGKwQ1XGGBPNAkcMdh2HMcZEs8DRBjtUZYwxzVngiMG5rXpX18IYY7qXhAYOEblMRLaISJGIzGlheaqIvOIuXyYi+U2WnS4i74vIBhFZJyJpIpIhIm+KyGY3/X8TXP9Ert4YY05ICQscIuIBngRmAOOA2SIyLiLbTUCZqo4GHgcecct6gReBW1R1PDANqHfLPKqqY4HJwKdEZEbC2oAdqjLGmEiJ7HGcAxSp6nZVDQAvAzMj8swEnnenXwMuEeff/OnAWlVdA6CqpaoaUtVaVV3spgWAVUBewlpgHQ5jjIniTeC6hwN7mswXA+e2lkdVgyJSAQwATgVURBYCg4CXVfWnTQuKSA5wOfDLlt5cRG4GbgbIzc2lsLAw7gYcPFBHOBzuUNkTWXV1tbW5F7A29w6JaHMiA8ex8AJTgLOBWuBtEVmpqm9D46GsPwNPqOr2llagqnOBuQAFBQU6bdq0uCvx+qE1bD6yl46UPZEVFhZam3sBa3PvkIg2J/JQ1V5gRJP5PDetxTxuMMgGSnF6J0tVtURVa4EFwJlNys0FPlbVXySo7jh1sjEOY4yJlMjAsRwYIyIjRSQFuBaYH5FnPnC9O301sEhVFVgITHTPovICFwIbAUTkYZwAc2cC6w7YEIcxxrQkrsAhIn3cs6XapKpB4DacILAJeFVVN4jIQyJyhZvtGWCAiBQBdwFz3LJlwGM4wWc1sEpV3xSRPOBenLO0VonIahH5RjxtMMYYc2xijnGISBJOT+E6nPGGOiBVREqAN4HfqmpRa+VVdQHOYaamafc3mfYD17RS9kWcU3KbphVzHDsCInYBoDHGRGqrx7EYOAW4BxiiqiNUdTDOwPUHwCMi8pUE17HL2BMAjTEmWltnVV2qqvWRiap6BJgHzBOR5ITUrBuwC8eNMSZaWz2OCxomRGRk0wUichVAS4HFGGNMz9VW4Hi0yfS8iGX3dXJduh07HdcYY6K1FTiklemW5nsgscFxY4yJ0Fbg0FamW5rvcWyMwxhjorU1OD5KRObj9C4apnHnR7ZerCfp8fHRGGPi0lbgaHo320cjlkXO9zh2W3VjjIkWM3Co6pKm8+6ptxOAvap6KJEV6w7EIocxxkSJOcYhIk+LyHh3OhtYA/wR+EhEZh+H+nUpuwDQGGOitXkdh6pucKdvBLaq6kTgLOC/E1ozY4wx3VJbgSPQZPrTwN8BVPVAwmrUjdh1HMYYE62twFEuIp8XkcnAp4B/QOOzM9ITXbmuZmfjGmNMtLbOqvov4AlgCHBnk57GJTh3x+3RROwCQGOMidTWWVVbgctaSF+I85wNY4wxvUxbz+N4ItZyVb2jc6vT/ViHwxhjmmvrUNUtwHrgVWAfveywv91yxBhjorUVOIbiPKFvFhAEXgFeU9XyRFesOxC7yaExxkSJeVaVqpaq6tOqehHOdRw5wEYR+epxqV0Xsx6HMcZEa6vHAYCInAnMxrmW4y1gZSIrZYwxpvtqa3D8IeBzwCbgZeAeVQ0ej4p1B3arKmOMidZWj+M+YAdwhvv6sTjHbwRQVT09sdXrWnbluDHGRGsrcPSSZ260TGyQwxhjorR1y5HdqrqrtReAxPh1FZHLRGSLiBSJyJwWlqeKyCvu8mUikt9k2eki8r6IbBCRdSKS5qaf5c4XicgTsd6/U1iXwxhjmmkrcCwWkdtF5KSmiSKSIiIXi8jzwPUtFRQRD/AkMAMYB8wWkXER2W4CylR1NPA48Ihb1gu8CNyiquOBaUC9W+Yp4JvAGPcVdWV7Z7ExDmOMidZW4LgMCAF/FpF9IrJRRLYDH+OcZfULVX2ulbLnAEWqul1VAziD6zMj8swEnnenXwMucXsQ04G1qroGGk8LDonIUKCvqn6gqorzbJAr42lwXGyMwxhjorR1ryo/8BvgN+7T/wYCvnZeADgc2NNkvhg4t7U8qhoUkQpgAHAqoCKyEBgEvKyqP3XzF0esc3hLby4iNwM3A+Tm5lJYWNiOKje3Z3cAVDtU9kRWXV1tbe4FrM29QyLa3K7rOABUtR7Y36nv3jovMAU4G6gF3haRlUBFe1egqnOBuQAFBQU6bdq0uCuxMrCF0I4iLrzwwl41UF5YWEhHPq8TmbW5d7A2d462DlUdi73AiCbzeW5ai3nccY1soBSnJ7FUVUtUtRZYAJzp5s9rY52dJi3ZgwKBUDhRb2GMMSecRAaO5cAYERkpIinAtcD8iDzzOTq4fjWwyB27WAhMFJEMN6BcCGxU1f1ApYic546FfA34v0Q1ID3ZA4A/YIHDGGMatCtwiEgfEUlyp08VkSvcMY9WuVeY34YTBDYBr6rqBhF5SESucLM9AwwQkSLgLmCOW7YMeAwn+KwGVqlqw4OjvgX8HigCtuHcAiUh0lOcwOGrDyXqLYwx5oTT3jGOpcAFItIP+CfOD/os4LpYhVR1Ac5hpqZp9zeZ9uPcfbelsi/inJIbmb4CmNDOeh+Thh5HbaDX3GXFGGPa1N5DVeKONVwF/EZVrwHGJ65a3UNasvU4jDEmUrsDh4icj9PDaDhk5ElMlbqPhkNVfgscxhjTqL2B407gHuBv7jjFKGBx4qrVPRw9VGWBwxhjGrRrjENVlwBLANxB8pLe8Lzx/n2c8f8jNYEurokxxnQf7T2r6k8i0ldE+uA8g3yjiHwvsVXrerl90wA4UOHv4poYY0z30d5DVeNUtRLnvlBv4dxuvcc/PjYrLZk0DxyotMBhjDEN2hs4kt3rNq4E5ru3H+kV9//LSRMOWuAwxphG7Q0cvwV2An2ApSJyMlCZqEp1J/1SxQ5VGWNME+0KHKr6hKoOV9XPqmMXcFGC69Yt9E9LYveRWsLhXtHBMsaYNrV3cDxbRB4TkRXu6+c4vY8eb/xADyXVAX73zvaurooxxnQL7T1U9SxQBXzJfVUCf0hUpbqTSYM8eJKEn7y1mW88v5xDVc5hK+dejI6ymgDhsHKo0k/RoaquqqoxCREOKyHrcZsm2hs4TlHVB9yn+W1X1QeBUYmsWHeRkSy8cfsUAP696RDn/OhtTr3vLUbes4CZT/6HV5bvZvIP/8XDb27inB+/zaWPLWXT/koWrNvP/gof2w5Xs6/c1yzQxGPZ9lL2V/janf9AhZ8b//Ahmw9ED0EdrqprDHzH4snFRTy9ZFuHyqoqK3cdodJf33bmDnp700Hy57zJW+va//iYrWUhbvjDhwSCzp2QQ2Glwhd/HUur6xoPayayjZ2luKyW5TuPxMxz6WNLOOdH/465D7e1f5fVBPjzh7s7/D1osHFfJWv2tP4cuWNdf6RwWNlVWtPuvHuO1MbMEworb286GFXPUFiprjtx7onX3psc+kRkiqq+CyAinwLa/2t2gvvE0L68cfsUZv/uA6r8wcYflzV7yht34mf/s6Mx/4xfvhO1jnPy+xNSZeWuMgDuuHg0xeU+Fm0+xJcKRtAnxcvEvL78a+NBLhgziMxUL//ceIAXP9gNwMI7p/L+thKmjBnI8JwMistqKS7zccqgTN4tKmFoThojB/Rh2qOFACzecpjnbjybIzUBpo8fwtricr78u2UAzLv1fEJhWLjhAB8fqmb6uFwmjcjh7x/tJTPNy5K1fhaUrCEQDLNxfyVfKhjBxWMHIyIs3HCAny3cAsC5I/szenAmIsJ7RSWkJXsIhsOEw84pzHvLfYzol8F/tpXw2JfO4Pt/Xc8nhmbx8JubAPj6p0by3rYSfnntZHaU1HDLiyu5acpIDlfVMWPCEP6x4QDXfzKfpVsP819TT6G6LkiSwI8WbCJJhIdmjmddcQX7Kny8+3Ep1513EimeJG56fgUAt760isdnncHMM4azeMshJgzPZsO+Cv60bDdfOe9k8vplcMqgPlTXBfnxMj/g5421+8hI8bJ48yFeWbGHR744kez0ZFbvqeCagjz+tGw3MyYMoSC/P6GwUlJdx9riCoZmp1EfCvOF37zH0Ow09rsnVPTvk8KcGWN5/r2d3PXpU5k4PLuxLs+/t5Mxg7MIhMLMmDAEBVbtKmP04Ez6piczpG8ae8t9DMpMpU+ql9dWFjNuWF/2lvnYV+7jiknDKC6rJdXrYWh2Ghv2VfL3j/Zy94yxvLethItOG8xVv3mPumCYOy4ZzSeG9mX93kpmTBhCha8ef1C5+NElBEJh7r5sLMP7pXPFGcPYXVrLrxd/zMb9lXxjyii2lzg/nI/+cwtXThrO3nIfb607wP2Xj0ME7nx5NYVbDrP2B9MJq5LiSWLT/ioU58dw/NBsPvXIImoDIR58fQOv3fJJ0lM8LN9xhCO1AU4fnsPwfunc/dpaPj0ul91HavmvC0dRGwix7VA1owZlUlYb4Nq5HzR+n964fQpjcjN58YPd7CqtIUmEQVmp/GzhFp6YPZnLxg/h7U0HKakJcMqgPgjCoSo/H+ysJ2dPOcNy0li1q5wjNQFSvUk88+4OLjh1IBedNpjJJ+WQ4kkiFFZ+vbiIX/z7Y+Z+9SwemL+BH86cwLTTBrG/ws+wnHSee28n9aEwG/dVMn/NPgDumTGWjw9VM2fGWPaV+3h70yHOGJHNRacN5vfvbOcnb23midmTqfTV079PCjMmDOG2P63irfUHuGfGWHaU1HD/5eMA2LCvkgdf38BPvnA6I/qns/tILaqws7SGZTuO0C8jmR0lNXxu4jCGZKeyfm8lF48dzKCsVFbuKmPySTnH8MvXOmlPhBaRM3Ce753tJpUB16vq2oTUqpMVFBToihUrOlS26dOzAsFw43+hniThZws3s/VgNWOHZLGmuJzdpbVMO21w4w5kerYUb1LjPxE9xaCsVEqq6+jkf9xNF8nJSOYnn0xmxqUdO5dJRFaqakFkentvObIGOENE+rrzlSJyJ3BCBI7OkuJNYlBWauP8T646vcV8P//SGewr93FS/wyCYWVfuY/6UBh/fZhfLyri5AEZeJKEgZmp+IMh1hVXsHF/JaMHZfLFs/J4dOEWBmWlsqOkhkNVdY3r7d8nhcxUL5d+IpdVu8tY3UKXfcLwvqR4kli1O3qZN0kItvNY9VVnDmfc0L5s3FfJPzYcaHa/rnFD+7KnrJYqf5DLzxhGha+epVsPA5CV5qXK33KXO69fOqfmZpHqTaK0OtCsBzZpRA6r95QzflhfNuyLPsx2Rl42NYEQE4b1ZfWecs46uT87SqrJ7ZvG9PG5fPeVNe1qV4M+KR5q3Dbl9UunuMzHZ8bnsnDDwRbzjxval/LaAPuanJo9sE8KJdUBAqEwp+Zmkp2ezLCcdP5vdfQ/DkkCsT769GRPzLswTxyezZYDVe16GqUnSdo9JjEsO61Zmw5X1ZHbN5UrzhhGqtfDS8t2UVYb+5BbZqo36jDLSf0z8CYJ20tqGve7KycNY93eCrYdbt+hnwZTRg8kK83LW+sPNKZ9buJQUrxJHKz0MzQ7nf59knlp2e4W7ysX2cbhOelU+Oq5bMIQXltZzNRTB3HrhafwjeeXN+4TkWZOGta4XYfnpHPmyf143f0HcUCfFEojbkt01eThbNxfyeYDrY95DumbRp9UT5ufR4oniU8MzUJEmn3nr5w0jJyMFJJE2FFSTeHWw+QP6EMwHGbK6EHuoUFITcTtaFW1Qy9gd0fLHu/XWWedpR21ePHiDpftDKFQWOvqQ60u9wWCLabvLKnWYCisVf56Xbz5oG47VBXzfar99RoKhfXjg5W6aNGiqDocqvS3u8519SH9/Tvbtbw2oHuO1MTMu3xHqQZD4aj0hvf0BYIaamF5pJq6eg0EQxoOh/WdrYf15Lvf0H9tOKDhcFhX7jqiQfdzPFjp03A4en0N27k+GNJFmw/qwUqfbt5fqZW+QLP8Fb6AllbXaXlNoNW6fHywqrGMvz6o+8prG5cdrPBpaXWd/vG9Hbp5f2Wz9gWCzbezvz6owVC42ecTDoc1HA5HfSaRbQqHw+oLBPU3i4t00/6KqDz++mCzfTscDuvaPeWtbotY76WqWuWv19dW7NHX1+zVCl8g5jar9AV026EqLa2u092lNVpWU9e4rD4Yaix7sNLX6jpiqasP6QfbSvRw1dF9tqHODft2S+1syFflr2/X+1S7+Ro+63A4rM+8s13XFZc35llXfPQzrQ+GtLYu2LifNiivCeiSLYdU1fk+V/pa37fKawL64Y7SdtWvwbH8hgErtIXf1HYdqmqJiOxR1RFt5+x6nXWoqrfoCW0+WOlvvNdYe/SENsfL2tw7HEubWztUdSzPHLejoKbbiidoGGPiE3OMQ0SqaDlACJCekBoZY4zp1mIGDlXNOl4VMcYYc2I4lkNVxhhjeiELHMYYY+JigcMYY0xcEho4ROQyEdkiIkUiMqeF5aki8oq7fJmI5Lvp+SLiE5HV7uvpJmVmi8g6EVkrIv8QkYGJbIMxxpjmEhY4RMQDPAnMAMYBs0VkXES2m4AyVR0NPA480mTZNlWd5L5ucdfpBX4JXKSqp+NcuX5botpgjDEmWiJ7HOcARercTTcAvAzMjMgzE3jenX4NuEREJMY6xX31cfP1BezGUMYYcxy19+64HTEc2NNkvhg4t7U8qhoUkQpggLtspIh8hPPsj/tU9R1VrReRW4F1QA3wMfDtlt5cRG4GbgbIzc2lsLCwQ42orq7ucNkTlbW5d7A29w6JaHMiA8ex2A+cpKqlInIW8F0B5ngAABUoSURBVHcRGY9zK/dbgcnAduBXwD3Aw5ErUNW5wFxwbjnS0Uvu7RYFvYO1uXewNneORB6q2gs0vZdVnpvWYh53/CIbKFXVOlUtBVDVlcA24FRgkpu2zb0B16vAJxPYBmOMMRESGTiWA2NEZKSIpADXAvMj8swHrnenrwYWqaqKyCB3cB0RGQWMwelh7AXGicggt8yngU0JbIMxxpgICTtU5Y5Z3AYsBDzAs6q6QUQewrlV73zgGeAFESkCjuAEF4CpwEMiUg+EgVtU9QiAiDwILHWX7QJuSFQbjDHGREvoGIeqLgAWRKTd32TaD1zTQrl5wLxW1vk08HRLy4wxxiSeXTlujDEmLhY4jDHGxMUChzHGmLhY4DDGGBMXCxzGGGPiYoHDGGNMXCxwGGOMiYsFDmOMMXGxwGGMMSYuFjiMMcbExQKHMcaYuFjgMMYYExcLHMYYY+JigcMYY0xcLHAYY4yJiwUOY4wxcbHAYYwxJi4WOIwxxsTFAocxxpi4WOAwxhgTFwscxhhj4mKBwxhjTFwscBhjjIlLQgOHiFwmIltEpEhE5rSwPFVEXnGXLxORfDc9X0R8IrLafT3dpEyKiMwVka0isllEvpiwBnz0IgNKliVs9cYYcyLyJmrFIuIBngQ+DRQDy0VkvqpubJLtJqBMVUeLyLXAI8Asd9k2VZ3UwqrvBQ6p6qkikgT0T1QbeO9XDNF+wN0JewtjjDnRJLLHcQ5QpKrbVTUAvAzMjMgzE3jenX4NuEREpI31fh34CYCqhlW1pBPr3Jx4gHDCVm+MMSeihPU4gOHAnibzxcC5reVR1aCIVAAD3GUjReQjoBK4T1XfEZEcd9kPRWQasA24TVUPRr65iNwM3AyQm5tLYWFh3A04q7aWkCe1Q2VPZNXV1dbmXsDa3Dskos2JDBzHYj9wkqqWishZwN9FZDxOffOA91T1LhG5C3gU+GrkClR1LjAXoKCgQKdNmxZ/LbZkE6gTOlT2BFZYWGht7gWszb1DItqcyENVe4ERTebz3LQW84iIF8gGSlW1TlVLAVR1JU7P4lSgFKgF/uqW/wtwZqIaQJIXUTtUZYwxTSUycCwHxojISBFJAa4F5kfkmQ9c705fDSxSVRWRQe7gOiIyChgDbFdVBV4HprllLgE2kihJHkRDCVu9McaciBJ2qMods7gNWAh4gGdVdYOIPASsUNX5wDPACyJSBBzBCS4AU4GHRKQeZ3T6FlU94i672y3zC+AwcGOi2mCD48YYEy2hYxyqugBYEJF2f5NpP3BNC+XmAfNaWecunMCSeEkeO1RljDER7MrxWCTJAocxxkSwwBGL9TiMMSaKBY5YbIzDGGOiWOCIxXocxhgTxQJHLEleOx3XGGMiWOCIxQbHjTEmigWOWOxQlTHGRLHAEYsNjhtjTBQLHLFYj8MYY6JY4IhFLHAYY0wkCxyxJNnguDHGRLLAEYvY3XGNMSaSBY5YkrzY4LgxxjRngSMWGxw3xpgoFjhiscFxY4yJYoEjFutxGGNMFAscsUgSNsZhjDHNWeCIJTULTzgA9f6urokxxnQbFjhiyc5z/lbu7dp6GGNMN2KBI5aGwFG2s0urYYwx3YkFjlhyJzh/933UtfUwxphuxAJHLBn9qco8Bdb9BYKBrq6NiUflvq6ugYml+jBUHezqWpgOSmjgEJHLRGSLiBSJyJwWlqeKyCvu8mUiku+m54uIT0RWu6+nWyg7X0TWJ7L+ALtO/hIc3gy/uwj8lYl+u6PqfdGD8r4yKPn4+NUhHnuWQ/nurq6F4/3fwGOfgC3/aD3PB0/B4h933nvuXwuqnbe+eKm2/P7718A7j3VsnYFaqD50bPVqzaOj4eendqysv9Jpl+kyCQscIuIBngRmAOOA2SIyLiLbTUCZqo4GHgceabJsm6pOcl+3RKz7KqA6UXVvqmTQefCpO+Hgenjus/D2D6Gi2FnY9Ita7zs6XXUA9q2G338adiyFUPDoslAQwk3uf1W8wpmv2Nt8LOXx8fDE5OaVefYy+HVB8/dd/gyUbmue7/AWWPGH5mnle+DAOqdsrN5ToLb1ZeDUdd9HEKxrnv7MpUfr6yuDed+Ane/C6j9F/6AFauHD3zmBcdGPoPZI9PuE6o9+zpX7nfn2WniP87f4Q6cugZroPP+YA0seiU6vPQL/esDpsfjKW15/KNj8B3XbYvjtBfDhXPjPE86PWkOba4/Arvec/WDD346WCdbB4a0Q7qTTvf/2X/Bw7tF5VWd/euYz8PaDLX8GbXnhC/DoGNheCHUxvm6heme/8JXDD7LhX/c7+18o2PI/E6v/fHT68QnO96Utu5fB0ked6T/Pht9Ojd4Ha0pg5XNHP/tAbcv7c7AOPv6Xs/8dj55pXXXz34DWbHnL+QcklpIi5zvT1n4TCjrf9wTxJmzNcA5QpKrbAUTkZWAmsLFJnpnAD9zp14Bfi4jEWqmIZAJ3ATcDr3ZynVv26Qdh2GR48y5451Hn1WDgaZCS4fyYfu4x8B2BRQ8fXf785dHr6zMYPvtT54v97x/AyAthxxJn2bTvw6mfgdpSZ77qIFTth+QMp+cDsGcZeFNBw06dAL7xtvMFrtwL825y0g5thJFTYdUL8PFCJ+2sG5z5m/4FW94EBE6fBW/cCfkXwJL/ZeD4e2BzLax+CTL6w7m3QlpfeP1O2LvSaSMCD5Q5X7yPXnTWHXa/HFv/6RzeW/cXZ75fPvQd5gSsfvlQ+GN471ew5s/O+lY8A3nnwJTvQs4Id50vOD8C59zs/CBP+S4MGAOnzXA+h6yhsPt950dnxbNQscd5ry/8tskHLfDHK2H/aqd8v5Ew4hznb4MPnobc8eSUrYPnHzu6Hf7zC+fvdfNg61vOj35tKXhSoO9wKNsB530LzpgNB9wv+1v/3Xw7X/k0/P2W5mlr/wInnw//vO/ovvCp78CkLzs/aEG/c4+0rf+A0iIY/wXns6k5DMXL4ZXrnHJf+z8YeCokpztBuujfTvqBdbBtkfPj3dRvL4RPXO68lyTB9sUMKNkMG8qd/eYTl8Oq553/5gec4mzvPR84Zf84E1Kz4YbXnX129zJnOx3aBHlnw8J7Yfjko8HpP790/r5xp7tN5kLfoc66y3bCP+89Wq+KPfDiF+HKp0AEDm50vk/5U6BsFwwc4+wPz0538xfDrned6X/eB5ted74fE69xgnP1QWc/TfIc3R9nvwLZwyEcIilU5/RGG75fAPcUg7/CaeeoafC5nzvp4bCTr2QLfPQSTP8hpGRCcprzXn0GO9+FrCHOZ7hjqRPcRpwNF86BPoNgzZ+c7/hJ58OFd8P7v4ZLH4RQHfztFue7l+RxvufLnnLe91sfwKCxzncjNQvScmDz6zDoEzD/djiyDfIKnH1/0FjYtwrqayF3ItSWwNjPO5/NqufhuteAZDqbaIK61yJyNXCZqn7Dnf8qcK6q3tYkz3o3T7E7vw04F8gENgBbgUrgPlV9x83zOLAU+Ah4Q1UntFWXgoICXbFiRYfaUVhYyLRp05yZUBDe/5XzX6Wvhf+SDaT3c/7Lb01KFgSqjl99egJJcv5JaHGZB+wOzp3Lmw6oE8QjJXmPBqRE8qQ6waUT/OeTL/Cp6Vd0qKyIrFTVgsj0RPY4jsV+4CRVLRWRs4C/i8h4YBRwiqp+t2E8pDUicjNOr4Tc3FwKCws7VJHq6uqIspPh3KOHgVL9h/AGa8ms3o5oGE/Ix5H+Z+LLGE5SyA8I2RWb8IT8+NMGkeY/jDdYjWiYpHAdfWp2EfJk4An5qUvtj4qH1LpSQAh5UvGnDSbozSSjdg+BlP6k+/YRSOmHP20QGbX7CXoz8KUPY9Dhd+l/ZDVH+k+mNmMYQW8WQW8GA0s+JORJxROqQ8WDL30I4SRns6f7DpIUDlCX2p/ynNPJrthIv7LVVKQMIaduL3Wpg/ClD6FPzW7qUvuTXF9FyJNGVdYYMmqLCSd5GVC6ktqMEQwsXcaRfpOoSx0A2YJoiKC3Dznl66hPziK17gi+9GEEUvoSTkoj6E0ns3oXdan9yagtxhusobLvWEKedLzBakAZWPIBhwZfQHXmSPrU7CbNf4j65CxElaA3g5zyDVRnjuLwoPMYtu+fBFL6ouIhKVwPCEnhekSDhJNSSPMfpC51EJ6Qn3BSMum+A4Q8aVT2HU2/snWUZoyC9P5k1O7hYO5F9D+yChUP4aRkUgIVpATKKOs3EW/Qh4qH+uQssqq2EU7yIqp4Qj53facR9PYhJVBOum8fWVVFlOdMwJ+WS9/KrXiDNWRVbaU+uS8pgQqC3gwCKTl4gz4O5k4lu2IjtRnDqU/OId23H0+o1t2W6eSUr+dI/zPJrthIOCkFFQ8qXlTE3V/SSa0rIbm+ktqMEWRVbaV0wNmIhtzt5fznGU5KdfZV32HCaf1J9x1w95k+DChdTk2fk/GlDyPkScMbrEIlmTT/QZLC9fjSh+AJ+UkJlOMN1lCRPZaM2mJCnjTSfQfwBqsp6zeJdN9+QKhPzsSXPpxwUgqDD71Dec44+lZuJZDSn5KBZ1OXOhhPyEdW1VYGHX6PcFIa/rTB1KX2I6N2H9WZ+ah4Sfft50j/yQw+9A7FeZeTXbGJNP8hQFBJoj45m3TfXrxBH+U54wmk5OAJBRANkVm9nfrkbDKrt3Ewcxy51RvZdfI1eIM+Bh96B3/aYDJq9wBJ1Cf3bdwmomEGlnxAdeYokusrKM85naRwAG+wmozaYqqyTnW/h3tRSaL/kVX40oe5n5mXmj4nkxIooy51IBm1xSTXl1OXOhAVLxm1e/CnDUY0RDgphdqMEfjShxLypJDuO0hq3WF3ny+hOvNkgt5MRMPUJ2fhSx9KRu1eUgJHSK6vpKbPyWTU7kPFGXnwpecS8qTTt3ILB4ZcTIU/1OHfv1apakJewPnAwibz9wD3RORZCJzvTnuBEtxeUES+QqAAuBXYB+wEioEAUNhWXc466yztqMWLF3e47InK2tw7WJt7h2NpM7BCW/hNTeRZVcuBMSIyUkRSgGuB+RF55gPXu9NXA4tUVUVkkDu4joiMAsYA21X1KVUdpqr5wBRgq6pOS2AbjDHGREjYoSpVDYrIbTi9Cg/wrKpuEJGHcKLYfOAZ4AURKQKO4AQXgKnAQyJSj3OXwVtU1QYVjDGmG0joGIeqLgAWRKTd32TaD1zTQrl5wLw21r0TaHNg3BhjTOeyK8eNMcbExQKHMcaYuFjgMMYYExcLHMYYY+JigcMYY0xcEnbLke5ERA4DuzpYfCDOhYm9ibW5d7A29w7H0uaTVXVQZGKvCBzHQkRWaAv3aunJrM29g7W5d0hEm+1QlTHGmLhY4DDGGBMXCxxtm9vVFegC1ubewdrcO3R6m22MwxhjTFysx2GMMSYuFjiMMcbExQJHK0TkMhHZIiJFIjKnq+vTWURkhIgsFpGNIrJBRL7jpvcXkX+JyMfu335uuojIE+7nsFZEzuzaFnSciHhE5CMRecOdHykiy9y2veI+NwYRSXXni9zl+V1Z744SkRwReU1ENovIJhE5v6dvZxH5rrtfrxeRP4tIWk/bziLyrIgcch+93ZAW93YVkevd/B+LyPUtvVdrLHC0wH2I1JPADGAcMFtExnVtrTpNEPh/qjoOOA/4ttu2OcDbqjoGeNudB+czGOO+bgaeOv5V7jTfATY1mX8EeFxVRwNlwE1u+k1AmZv+uJvvRPRL4B+qOhY4A6ftPXY7i8hw4A6gQFUn4DwH6Fp63nZ+DrgsIi2u7Soi/YEHgHOBc4AHGoJNu7T0WMDe/qIdj73tKS/g/4BPA1uAoW7aUGCLO/1bYHaT/I35TqQXkOd+oS4G3gAE52pab+Q2p52PNO7OLyAb2BFZ7568nYHhwB6gv7vd3gA+0xO3M5APrO/odgVmA79tkt4sX1sv63G0rGEHbFDspvUobtd8MrAMyFXV/e6iA0CuO91TPotfAP+N80RJgAFAuaoG3fmm7Wpss7u8ws1/IhkJHAb+4B6e+72I9KEHb2dV3Qs8CuwG9uNst5X07O3cIN7tekzb2wJHLyUimThPWbxTVSubLlPnX5Aec562iHweOKSqK7u6LseRFzgTeEpVJwM1HD18AfTI7dwPmIkTNIcBfYg+pNPjHY/taoGjZXuBEU3m89y0HkFEknGCxkuq+lc3+aCIDHWXDwUOuek94bP4FHCFiOwEXsY5XPVLIEdEGh6f3LRdjW12l2cDpcezwp2gGChW1WXu/Gs4gaQnb+dLgR2qelhV64G/4mz7nrydG8S7XY9pe1vgaNlyYIx7NkYKzgDb/C6uU6cQEQGeATap6mNNFs0HGs6suB5n7KMh/Wvu2RnnARVNusQnBFW9R1XzVDUfZ1suUtXrgMXA1W62yDY3fBZXu/lPqP/MVfUAsEdETnOTLgE20oO3M84hqvNEJMPdzxva3GO3cxPxbteFwHQR6ef21Ka7ae3T1YM83fUFfBbYCmwD7u3q+nRiu6bgdGPXAqvd12dxju2+DXwM/Bvo7+YXnDPMtgHrcM5Y6fJ2HEP7pwFvuNOjgA+BIuAvQKqbnubOF7nLR3V1vTvY1knACndb/x3o19O3M/AgsBlYD7wApPa07Qz8GWcMpx6nZ3lTR7Yr8HW37UXAjfHUwW45YowxJi52qMoYY0xcLHAYY4yJiwUOY4wxcbHAYYwxJi4WOIwxxsTFAocxnUBEQiKyusmr0+6oLCL5Te+EakxX87adxRjTDj5VndTVlTDmeLAehzEJJCI7ReSnIrJORD4UkdFuer6ILHKfkfC2iJzkpueKyN9EZI37+qS7Ko+I/M591sQ/RSS9yxplej0LHMZ0jvSIQ1WzmiyrUNWJwK9x7tIL8CvgeVU9HXgJeMJNfwJYoqpn4NxbaoObPgZ4UlXHA+XAFxPcHmNaZVeOG9MJRKRaVTNbSN8JXKyq292bSx5Q1QEiUoLz/IR6N32/qg4UkcNAnqrWNVlHPvAvdR7Sg4jcDSSr6sOJb5kx0azHYUziaSvT8ahrMh3CxidNF7LAYUzizWry9313+j2cO/UCXAe8406/DdwKjc9Izz5elTSmvey/FmM6R7qIrG4y/w9VbTglt5+IrMXpNcx2027HeTrf93Ce1Hejm/4dYK6I3ITTs7gV506oxnQbNsZhTAK5YxwFqlrS1XUxprPYoSpjjDFxsR6HMcaYuFiPwxhjTFwscBhjjImLBQ5jjDFxscBhjDEmLhY4jDHGxOX/A+wR28dottwyAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBH51VPldBHi"
      },
      "source": [
        "### Deeper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkFr46IucjZa",
        "outputId": "02f89f7e-42af-4887-e18d-23e22f683068",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "neurons = 1\n",
        "epoch = 1000\n",
        "batch_size = 32\n",
        "\n",
        "deeper_model = Sequential()\n",
        "deeper_model.add(Dense(neurons, activation='relu', input_dim=feature_train.shape[1]))\n",
        "deeper_model.add(Dense(5, activation='relu'))\n",
        "deeper_model.add(Dense(1))\n",
        "deeper_model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "deeper_model_history = deeper_model.fit(feature_train, label_train, epochs=epoch, batch_size=batch_size, validation_data=(feature_test, label_test))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0663 - val_loss: 0.0556\n",
            "Epoch 2/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0601 - val_loss: 0.0552\n",
            "Epoch 3/1000\n",
            "86/86 [==============================] - 0s 893us/step - loss: 0.0598 - val_loss: 0.0550\n",
            "Epoch 4/1000\n",
            "86/86 [==============================] - 0s 813us/step - loss: 0.0597 - val_loss: 0.0549\n",
            "Epoch 5/1000\n",
            "86/86 [==============================] - 0s 833us/step - loss: 0.0595 - val_loss: 0.0547\n",
            "Epoch 6/1000\n",
            "86/86 [==============================] - 0s 810us/step - loss: 0.0594 - val_loss: 0.0546\n",
            "Epoch 7/1000\n",
            "86/86 [==============================] - 0s 819us/step - loss: 0.0592 - val_loss: 0.0546\n",
            "Epoch 8/1000\n",
            "86/86 [==============================] - 0s 943us/step - loss: 0.0593 - val_loss: 0.0544\n",
            "Epoch 9/1000\n",
            "86/86 [==============================] - 0s 950us/step - loss: 0.0591 - val_loss: 0.0543\n",
            "Epoch 10/1000\n",
            "86/86 [==============================] - 0s 809us/step - loss: 0.0591 - val_loss: 0.0543\n",
            "Epoch 11/1000\n",
            "86/86 [==============================] - 0s 862us/step - loss: 0.0590 - val_loss: 0.0542\n",
            "Epoch 12/1000\n",
            "86/86 [==============================] - 0s 977us/step - loss: 0.0589 - val_loss: 0.0544\n",
            "Epoch 13/1000\n",
            "86/86 [==============================] - 0s 903us/step - loss: 0.0590 - val_loss: 0.0541\n",
            "Epoch 14/1000\n",
            "86/86 [==============================] - 0s 832us/step - loss: 0.0590 - val_loss: 0.0541\n",
            "Epoch 15/1000\n",
            "86/86 [==============================] - 0s 928us/step - loss: 0.0589 - val_loss: 0.0541\n",
            "Epoch 16/1000\n",
            "86/86 [==============================] - 0s 810us/step - loss: 0.0589 - val_loss: 0.0541\n",
            "Epoch 17/1000\n",
            "86/86 [==============================] - 0s 795us/step - loss: 0.0589 - val_loss: 0.0541\n",
            "Epoch 18/1000\n",
            "86/86 [==============================] - 0s 847us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 19/1000\n",
            "86/86 [==============================] - 0s 828us/step - loss: 0.0589 - val_loss: 0.0541\n",
            "Epoch 20/1000\n",
            "86/86 [==============================] - 0s 813us/step - loss: 0.0589 - val_loss: 0.0543\n",
            "Epoch 21/1000\n",
            "86/86 [==============================] - 0s 818us/step - loss: 0.0589 - val_loss: 0.0541\n",
            "Epoch 22/1000\n",
            "86/86 [==============================] - 0s 968us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 23/1000\n",
            "86/86 [==============================] - 0s 861us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 24/1000\n",
            "86/86 [==============================] - 0s 791us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 25/1000\n",
            "86/86 [==============================] - 0s 835us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 26/1000\n",
            "86/86 [==============================] - 0s 814us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 27/1000\n",
            "86/86 [==============================] - 0s 840us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 28/1000\n",
            "86/86 [==============================] - 0s 910us/step - loss: 0.0589 - val_loss: 0.0541\n",
            "Epoch 29/1000\n",
            "86/86 [==============================] - 0s 832us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 30/1000\n",
            "86/86 [==============================] - 0s 830us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 31/1000\n",
            "86/86 [==============================] - 0s 967us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 32/1000\n",
            "86/86 [==============================] - 0s 901us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 33/1000\n",
            "86/86 [==============================] - 0s 849us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 34/1000\n",
            "86/86 [==============================] - 0s 835us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 35/1000\n",
            "86/86 [==============================] - 0s 963us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 36/1000\n",
            "86/86 [==============================] - 0s 827us/step - loss: 0.0589 - val_loss: 0.0541\n",
            "Epoch 37/1000\n",
            "86/86 [==============================] - 0s 854us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 38/1000\n",
            "86/86 [==============================] - 0s 913us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 39/1000\n",
            "86/86 [==============================] - 0s 902us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 40/1000\n",
            "86/86 [==============================] - 0s 808us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 41/1000\n",
            "86/86 [==============================] - 0s 846us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 42/1000\n",
            "86/86 [==============================] - 0s 834us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 43/1000\n",
            "86/86 [==============================] - 0s 919us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 44/1000\n",
            "86/86 [==============================] - 0s 840us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 45/1000\n",
            "86/86 [==============================] - 0s 800us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 46/1000\n",
            "86/86 [==============================] - 0s 814us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 47/1000\n",
            "86/86 [==============================] - 0s 928us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 48/1000\n",
            "86/86 [==============================] - 0s 899us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 49/1000\n",
            "86/86 [==============================] - 0s 843us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 50/1000\n",
            "86/86 [==============================] - 0s 909us/step - loss: 0.0588 - val_loss: 0.0542\n",
            "Epoch 51/1000\n",
            "86/86 [==============================] - 0s 961us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 52/1000\n",
            "86/86 [==============================] - 0s 806us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 53/1000\n",
            "86/86 [==============================] - 0s 861us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 54/1000\n",
            "86/86 [==============================] - 0s 898us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 55/1000\n",
            "86/86 [==============================] - 0s 813us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 56/1000\n",
            "86/86 [==============================] - 0s 914us/step - loss: 0.0588 - val_loss: 0.0542\n",
            "Epoch 57/1000\n",
            "86/86 [==============================] - 0s 825us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 58/1000\n",
            "86/86 [==============================] - 0s 820us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 59/1000\n",
            "86/86 [==============================] - 0s 916us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 60/1000\n",
            "86/86 [==============================] - 0s 818us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 61/1000\n",
            "86/86 [==============================] - 0s 876us/step - loss: 0.0588 - val_loss: 0.0542\n",
            "Epoch 62/1000\n",
            "86/86 [==============================] - 0s 832us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 63/1000\n",
            "86/86 [==============================] - 0s 828us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 64/1000\n",
            "86/86 [==============================] - 0s 822us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 65/1000\n",
            "86/86 [==============================] - 0s 818us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 66/1000\n",
            "86/86 [==============================] - 0s 930us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 67/1000\n",
            "86/86 [==============================] - 0s 855us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 68/1000\n",
            "86/86 [==============================] - 0s 832us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 69/1000\n",
            "86/86 [==============================] - 0s 852us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 70/1000\n",
            "86/86 [==============================] - 0s 820us/step - loss: 0.0589 - val_loss: 0.0541\n",
            "Epoch 71/1000\n",
            "86/86 [==============================] - 0s 803us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 72/1000\n",
            "86/86 [==============================] - 0s 802us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 73/1000\n",
            "86/86 [==============================] - 0s 829us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 74/1000\n",
            "86/86 [==============================] - 0s 960us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 75/1000\n",
            "86/86 [==============================] - 0s 858us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 76/1000\n",
            "86/86 [==============================] - 0s 947us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 77/1000\n",
            "86/86 [==============================] - 0s 891us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 78/1000\n",
            "86/86 [==============================] - 0s 862us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 79/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 80/1000\n",
            "86/86 [==============================] - 0s 830us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 81/1000\n",
            "86/86 [==============================] - 0s 918us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 82/1000\n",
            "86/86 [==============================] - 0s 836us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 83/1000\n",
            "86/86 [==============================] - 0s 814us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 84/1000\n",
            "86/86 [==============================] - 0s 988us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 85/1000\n",
            "86/86 [==============================] - 0s 804us/step - loss: 0.0588 - val_loss: 0.0542\n",
            "Epoch 86/1000\n",
            "86/86 [==============================] - 0s 850us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 87/1000\n",
            "86/86 [==============================] - 0s 828us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 88/1000\n",
            "86/86 [==============================] - 0s 848us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 89/1000\n",
            "86/86 [==============================] - 0s 817us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 90/1000\n",
            "86/86 [==============================] - 0s 812us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 91/1000\n",
            "86/86 [==============================] - 0s 851us/step - loss: 0.0589 - val_loss: 0.0541\n",
            "Epoch 92/1000\n",
            "86/86 [==============================] - 0s 913us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 93/1000\n",
            "86/86 [==============================] - 0s 831us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 94/1000\n",
            "86/86 [==============================] - 0s 839us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 95/1000\n",
            "86/86 [==============================] - 0s 932us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 96/1000\n",
            "86/86 [==============================] - 0s 829us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 97/1000\n",
            "86/86 [==============================] - 0s 820us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 98/1000\n",
            "86/86 [==============================] - 0s 820us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 99/1000\n",
            "86/86 [==============================] - 0s 857us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 100/1000\n",
            "86/86 [==============================] - 0s 800us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 101/1000\n",
            "86/86 [==============================] - 0s 957us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 102/1000\n",
            "86/86 [==============================] - 0s 837us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 103/1000\n",
            "86/86 [==============================] - 0s 833us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 104/1000\n",
            "86/86 [==============================] - 0s 868us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 105/1000\n",
            "86/86 [==============================] - 0s 853us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 106/1000\n",
            "86/86 [==============================] - 0s 873us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 107/1000\n",
            "86/86 [==============================] - 0s 846us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 108/1000\n",
            "86/86 [==============================] - 0s 816us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 109/1000\n",
            "86/86 [==============================] - 0s 801us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 110/1000\n",
            "86/86 [==============================] - 0s 834us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 111/1000\n",
            "86/86 [==============================] - 0s 823us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 112/1000\n",
            "86/86 [==============================] - 0s 930us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 113/1000\n",
            "86/86 [==============================] - 0s 972us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 114/1000\n",
            "86/86 [==============================] - 0s 827us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 115/1000\n",
            "86/86 [==============================] - 0s 926us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 116/1000\n",
            "86/86 [==============================] - 0s 863us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 117/1000\n",
            "86/86 [==============================] - 0s 841us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 118/1000\n",
            "86/86 [==============================] - 0s 921us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 119/1000\n",
            "86/86 [==============================] - 0s 843us/step - loss: 0.0587 - val_loss: 0.0542\n",
            "Epoch 120/1000\n",
            "86/86 [==============================] - 0s 899us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 121/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 122/1000\n",
            "86/86 [==============================] - 0s 879us/step - loss: 0.0588 - val_loss: 0.0543\n",
            "Epoch 123/1000\n",
            "86/86 [==============================] - 0s 835us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 124/1000\n",
            "86/86 [==============================] - 0s 856us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 125/1000\n",
            "86/86 [==============================] - 0s 903us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 126/1000\n",
            "86/86 [==============================] - 0s 836us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 127/1000\n",
            "86/86 [==============================] - 0s 808us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 128/1000\n",
            "86/86 [==============================] - 0s 849us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 129/1000\n",
            "86/86 [==============================] - 0s 895us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 130/1000\n",
            "86/86 [==============================] - 0s 984us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 131/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 132/1000\n",
            "86/86 [==============================] - 0s 930us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 133/1000\n",
            "86/86 [==============================] - 0s 966us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 134/1000\n",
            "86/86 [==============================] - 0s 961us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 135/1000\n",
            "86/86 [==============================] - 0s 935us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 136/1000\n",
            "86/86 [==============================] - 0s 919us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 137/1000\n",
            "86/86 [==============================] - 0s 940us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 138/1000\n",
            "86/86 [==============================] - 0s 808us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 139/1000\n",
            "86/86 [==============================] - 0s 786us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 140/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 141/1000\n",
            "86/86 [==============================] - 0s 846us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 142/1000\n",
            "86/86 [==============================] - 0s 840us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 143/1000\n",
            "86/86 [==============================] - 0s 816us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 144/1000\n",
            "86/86 [==============================] - 0s 828us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 145/1000\n",
            "86/86 [==============================] - 0s 854us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 146/1000\n",
            "86/86 [==============================] - 0s 827us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 147/1000\n",
            "86/86 [==============================] - 0s 863us/step - loss: 0.0588 - val_loss: 0.0542\n",
            "Epoch 148/1000\n",
            "86/86 [==============================] - 0s 875us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 149/1000\n",
            "86/86 [==============================] - 0s 850us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 150/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 151/1000\n",
            "86/86 [==============================] - 0s 814us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 152/1000\n",
            "86/86 [==============================] - 0s 878us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 153/1000\n",
            "86/86 [==============================] - 0s 802us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 154/1000\n",
            "86/86 [==============================] - 0s 792us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 155/1000\n",
            "86/86 [==============================] - 0s 888us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 156/1000\n",
            "86/86 [==============================] - 0s 905us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 157/1000\n",
            "86/86 [==============================] - 0s 927us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 158/1000\n",
            "86/86 [==============================] - 0s 802us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 159/1000\n",
            "86/86 [==============================] - 0s 818us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 160/1000\n",
            "86/86 [==============================] - 0s 810us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 161/1000\n",
            "86/86 [==============================] - 0s 824us/step - loss: 0.0587 - val_loss: 0.0543\n",
            "Epoch 162/1000\n",
            "86/86 [==============================] - 0s 795us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 163/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 164/1000\n",
            "86/86 [==============================] - 0s 853us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 165/1000\n",
            "86/86 [==============================] - 0s 923us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 166/1000\n",
            "86/86 [==============================] - 0s 840us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 167/1000\n",
            "86/86 [==============================] - 0s 844us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 168/1000\n",
            "86/86 [==============================] - 0s 843us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 169/1000\n",
            "86/86 [==============================] - 0s 831us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 170/1000\n",
            "86/86 [==============================] - 0s 970us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 171/1000\n",
            "86/86 [==============================] - 0s 845us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 172/1000\n",
            "86/86 [==============================] - 0s 854us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 173/1000\n",
            "86/86 [==============================] - 0s 906us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 174/1000\n",
            "86/86 [==============================] - 0s 809us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 175/1000\n",
            "86/86 [==============================] - 0s 904us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 176/1000\n",
            "86/86 [==============================] - 0s 917us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 177/1000\n",
            "86/86 [==============================] - 0s 835us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 178/1000\n",
            "86/86 [==============================] - 0s 915us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 179/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 180/1000\n",
            "86/86 [==============================] - 0s 845us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 181/1000\n",
            "86/86 [==============================] - 0s 875us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 182/1000\n",
            "86/86 [==============================] - 0s 864us/step - loss: 0.0588 - val_loss: 0.0542\n",
            "Epoch 183/1000\n",
            "86/86 [==============================] - 0s 858us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 184/1000\n",
            "86/86 [==============================] - 0s 816us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 185/1000\n",
            "86/86 [==============================] - 0s 999us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 186/1000\n",
            "86/86 [==============================] - 0s 936us/step - loss: 0.0588 - val_loss: 0.0542\n",
            "Epoch 187/1000\n",
            "86/86 [==============================] - 0s 845us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 188/1000\n",
            "86/86 [==============================] - 0s 944us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 189/1000\n",
            "86/86 [==============================] - 0s 940us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 190/1000\n",
            "86/86 [==============================] - 0s 944us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 191/1000\n",
            "86/86 [==============================] - 0s 816us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 192/1000\n",
            "86/86 [==============================] - 0s 824us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 193/1000\n",
            "86/86 [==============================] - 0s 808us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 194/1000\n",
            "86/86 [==============================] - 0s 828us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 195/1000\n",
            "86/86 [==============================] - 0s 771us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 196/1000\n",
            "86/86 [==============================] - 0s 771us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 197/1000\n",
            "86/86 [==============================] - 0s 778us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 198/1000\n",
            "86/86 [==============================] - 0s 743us/step - loss: 0.0589 - val_loss: 0.0542\n",
            "Epoch 199/1000\n",
            "86/86 [==============================] - 0s 732us/step - loss: 0.0589 - val_loss: 0.0542\n",
            "Epoch 200/1000\n",
            "86/86 [==============================] - 0s 776us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 201/1000\n",
            "86/86 [==============================] - 0s 961us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 202/1000\n",
            "86/86 [==============================] - 0s 785us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 203/1000\n",
            "86/86 [==============================] - 0s 807us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 204/1000\n",
            "86/86 [==============================] - 0s 815us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 205/1000\n",
            "86/86 [==============================] - 0s 779us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 206/1000\n",
            "86/86 [==============================] - 0s 789us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 207/1000\n",
            "86/86 [==============================] - 0s 805us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 208/1000\n",
            "86/86 [==============================] - 0s 936us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 209/1000\n",
            "86/86 [==============================] - 0s 770us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 210/1000\n",
            "86/86 [==============================] - 0s 774us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 211/1000\n",
            "86/86 [==============================] - 0s 872us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 212/1000\n",
            "86/86 [==============================] - 0s 781us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 213/1000\n",
            "86/86 [==============================] - 0s 786us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 214/1000\n",
            "86/86 [==============================] - 0s 779us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 215/1000\n",
            "86/86 [==============================] - 0s 915us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 216/1000\n",
            "86/86 [==============================] - 0s 971us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 217/1000\n",
            "86/86 [==============================] - 0s 767us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 218/1000\n",
            "86/86 [==============================] - 0s 765us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 219/1000\n",
            "86/86 [==============================] - 0s 807us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 220/1000\n",
            "86/86 [==============================] - 0s 759us/step - loss: 0.0588 - val_loss: 0.0542\n",
            "Epoch 221/1000\n",
            "86/86 [==============================] - 0s 760us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 222/1000\n",
            "86/86 [==============================] - 0s 768us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 223/1000\n",
            "86/86 [==============================] - 0s 806us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 224/1000\n",
            "86/86 [==============================] - 0s 763us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 225/1000\n",
            "86/86 [==============================] - 0s 749us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 226/1000\n",
            "86/86 [==============================] - 0s 759us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 227/1000\n",
            "86/86 [==============================] - 0s 831us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 228/1000\n",
            "86/86 [==============================] - 0s 796us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 229/1000\n",
            "86/86 [==============================] - 0s 979us/step - loss: 0.0588 - val_loss: 0.0542\n",
            "Epoch 230/1000\n",
            "86/86 [==============================] - 0s 743us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 231/1000\n",
            "86/86 [==============================] - 0s 748us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 232/1000\n",
            "86/86 [==============================] - 0s 837us/step - loss: 0.0590 - val_loss: 0.0540\n",
            "Epoch 233/1000\n",
            "86/86 [==============================] - 0s 802us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 234/1000\n",
            "86/86 [==============================] - 0s 791us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 235/1000\n",
            "86/86 [==============================] - 0s 792us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 236/1000\n",
            "86/86 [==============================] - 0s 804us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 237/1000\n",
            "86/86 [==============================] - 0s 763us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 238/1000\n",
            "86/86 [==============================] - 0s 750us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 239/1000\n",
            "86/86 [==============================] - 0s 863us/step - loss: 0.0587 - val_loss: 0.0542\n",
            "Epoch 240/1000\n",
            "86/86 [==============================] - 0s 801us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 241/1000\n",
            "86/86 [==============================] - 0s 788us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 242/1000\n",
            "86/86 [==============================] - 0s 778us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 243/1000\n",
            "86/86 [==============================] - 0s 943us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 244/1000\n",
            "86/86 [==============================] - 0s 858us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 245/1000\n",
            "86/86 [==============================] - 0s 774us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 246/1000\n",
            "86/86 [==============================] - 0s 832us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 247/1000\n",
            "86/86 [==============================] - 0s 797us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 248/1000\n",
            "86/86 [==============================] - 0s 796us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 249/1000\n",
            "86/86 [==============================] - 0s 775us/step - loss: 0.0588 - val_loss: 0.0542\n",
            "Epoch 250/1000\n",
            "86/86 [==============================] - 0s 797us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 251/1000\n",
            "86/86 [==============================] - 0s 778us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 252/1000\n",
            "86/86 [==============================] - 0s 759us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 253/1000\n",
            "86/86 [==============================] - 0s 761us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 254/1000\n",
            "86/86 [==============================] - 0s 815us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 255/1000\n",
            "86/86 [==============================] - 0s 761us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 256/1000\n",
            "86/86 [==============================] - 0s 794us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 257/1000\n",
            "86/86 [==============================] - 0s 750us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 258/1000\n",
            "86/86 [==============================] - 0s 810us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 259/1000\n",
            "86/86 [==============================] - 0s 829us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 260/1000\n",
            "86/86 [==============================] - 0s 796us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 261/1000\n",
            "86/86 [==============================] - 0s 789us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 262/1000\n",
            "86/86 [==============================] - 0s 766us/step - loss: 0.0588 - val_loss: 0.0542\n",
            "Epoch 263/1000\n",
            "86/86 [==============================] - 0s 775us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 264/1000\n",
            "86/86 [==============================] - 0s 766us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 265/1000\n",
            "86/86 [==============================] - 0s 825us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 266/1000\n",
            "86/86 [==============================] - 0s 793us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 267/1000\n",
            "86/86 [==============================] - 0s 763us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 268/1000\n",
            "86/86 [==============================] - 0s 815us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 269/1000\n",
            "86/86 [==============================] - 0s 770us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 270/1000\n",
            "86/86 [==============================] - 0s 744us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 271/1000\n",
            "86/86 [==============================] - 0s 943us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 272/1000\n",
            "86/86 [==============================] - 0s 811us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 273/1000\n",
            "86/86 [==============================] - 0s 752us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 274/1000\n",
            "86/86 [==============================] - 0s 866us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 275/1000\n",
            "86/86 [==============================] - 0s 828us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 276/1000\n",
            "86/86 [==============================] - 0s 741us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 277/1000\n",
            "86/86 [==============================] - 0s 760us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 278/1000\n",
            "86/86 [==============================] - 0s 754us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 279/1000\n",
            "86/86 [==============================] - 0s 742us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 280/1000\n",
            "86/86 [==============================] - 0s 732us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 281/1000\n",
            "86/86 [==============================] - 0s 788us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 282/1000\n",
            "86/86 [==============================] - 0s 746us/step - loss: 0.0587 - val_loss: 0.0542\n",
            "Epoch 283/1000\n",
            "86/86 [==============================] - 0s 774us/step - loss: 0.0588 - val_loss: 0.0543\n",
            "Epoch 284/1000\n",
            "86/86 [==============================] - 0s 810us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 285/1000\n",
            "86/86 [==============================] - 0s 919us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 286/1000\n",
            "86/86 [==============================] - 0s 757us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 287/1000\n",
            "86/86 [==============================] - 0s 781us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 288/1000\n",
            "86/86 [==============================] - 0s 795us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 289/1000\n",
            "86/86 [==============================] - 0s 776us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 290/1000\n",
            "86/86 [==============================] - 0s 783us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 291/1000\n",
            "86/86 [==============================] - 0s 791us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 292/1000\n",
            "86/86 [==============================] - 0s 768us/step - loss: 0.0588 - val_loss: 0.0543\n",
            "Epoch 293/1000\n",
            "86/86 [==============================] - 0s 813us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 294/1000\n",
            "86/86 [==============================] - 0s 756us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 295/1000\n",
            "86/86 [==============================] - 0s 740us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 296/1000\n",
            "86/86 [==============================] - 0s 814us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 297/1000\n",
            "86/86 [==============================] - 0s 743us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 298/1000\n",
            "86/86 [==============================] - 0s 779us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 299/1000\n",
            "86/86 [==============================] - 0s 804us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 300/1000\n",
            "86/86 [==============================] - 0s 785us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 301/1000\n",
            "86/86 [==============================] - 0s 796us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 302/1000\n",
            "86/86 [==============================] - 0s 757us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 303/1000\n",
            "86/86 [==============================] - 0s 807us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 304/1000\n",
            "86/86 [==============================] - 0s 765us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 305/1000\n",
            "86/86 [==============================] - 0s 792us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 306/1000\n",
            "86/86 [==============================] - 0s 773us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 307/1000\n",
            "86/86 [==============================] - 0s 997us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 308/1000\n",
            "86/86 [==============================] - 0s 792us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 309/1000\n",
            "86/86 [==============================] - 0s 815us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 310/1000\n",
            "86/86 [==============================] - 0s 777us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 311/1000\n",
            "86/86 [==============================] - 0s 792us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 312/1000\n",
            "86/86 [==============================] - 0s 771us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 313/1000\n",
            "86/86 [==============================] - 0s 896us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 314/1000\n",
            "86/86 [==============================] - 0s 846us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 315/1000\n",
            "86/86 [==============================] - 0s 785us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 316/1000\n",
            "86/86 [==============================] - 0s 816us/step - loss: 0.0587 - val_loss: 0.0543\n",
            "Epoch 317/1000\n",
            "86/86 [==============================] - 0s 798us/step - loss: 0.0590 - val_loss: 0.0541\n",
            "Epoch 318/1000\n",
            "86/86 [==============================] - 0s 783us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 319/1000\n",
            "86/86 [==============================] - 0s 791us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 320/1000\n",
            "86/86 [==============================] - 0s 816us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 321/1000\n",
            "86/86 [==============================] - 0s 767us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 322/1000\n",
            "86/86 [==============================] - 0s 762us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 323/1000\n",
            "86/86 [==============================] - 0s 765us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 324/1000\n",
            "86/86 [==============================] - 0s 774us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 325/1000\n",
            "86/86 [==============================] - 0s 760us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 326/1000\n",
            "86/86 [==============================] - 0s 751us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 327/1000\n",
            "86/86 [==============================] - 0s 816us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 328/1000\n",
            "86/86 [==============================] - 0s 911us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 329/1000\n",
            "86/86 [==============================] - 0s 788us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 330/1000\n",
            "86/86 [==============================] - 0s 796us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 331/1000\n",
            "86/86 [==============================] - 0s 832us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 332/1000\n",
            "86/86 [==============================] - 0s 774us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 333/1000\n",
            "86/86 [==============================] - 0s 845us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 334/1000\n",
            "86/86 [==============================] - 0s 837us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 335/1000\n",
            "86/86 [==============================] - 0s 909us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 336/1000\n",
            "86/86 [==============================] - 0s 817us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 337/1000\n",
            "86/86 [==============================] - 0s 814us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 338/1000\n",
            "86/86 [==============================] - 0s 772us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 339/1000\n",
            "86/86 [==============================] - 0s 920us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 340/1000\n",
            "86/86 [==============================] - 0s 860us/step - loss: 0.0588 - val_loss: 0.0543\n",
            "Epoch 341/1000\n",
            "86/86 [==============================] - 0s 972us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 342/1000\n",
            "86/86 [==============================] - 0s 825us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 343/1000\n",
            "86/86 [==============================] - 0s 872us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 344/1000\n",
            "86/86 [==============================] - 0s 913us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 345/1000\n",
            "86/86 [==============================] - 0s 914us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 346/1000\n",
            "86/86 [==============================] - 0s 833us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 347/1000\n",
            "86/86 [==============================] - 0s 776us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 348/1000\n",
            "86/86 [==============================] - 0s 969us/step - loss: 0.0588 - val_loss: 0.0542\n",
            "Epoch 349/1000\n",
            "86/86 [==============================] - 0s 780us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 350/1000\n",
            "86/86 [==============================] - 0s 782us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 351/1000\n",
            "86/86 [==============================] - 0s 805us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 352/1000\n",
            "86/86 [==============================] - 0s 875us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 353/1000\n",
            "86/86 [==============================] - 0s 809us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 354/1000\n",
            "86/86 [==============================] - 0s 801us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 355/1000\n",
            "86/86 [==============================] - 0s 826us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 356/1000\n",
            "86/86 [==============================] - 0s 781us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 357/1000\n",
            "86/86 [==============================] - 0s 810us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 358/1000\n",
            "86/86 [==============================] - 0s 772us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 359/1000\n",
            "86/86 [==============================] - 0s 794us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 360/1000\n",
            "86/86 [==============================] - 0s 733us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 361/1000\n",
            "86/86 [==============================] - 0s 766us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 362/1000\n",
            "86/86 [==============================] - 0s 754us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 363/1000\n",
            "86/86 [==============================] - 0s 795us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 364/1000\n",
            "86/86 [==============================] - 0s 783us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 365/1000\n",
            "86/86 [==============================] - 0s 799us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 366/1000\n",
            "86/86 [==============================] - 0s 849us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 367/1000\n",
            "86/86 [==============================] - 0s 833us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 368/1000\n",
            "86/86 [==============================] - 0s 769us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 369/1000\n",
            "86/86 [==============================] - 0s 779us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 370/1000\n",
            "86/86 [==============================] - 0s 805us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 371/1000\n",
            "86/86 [==============================] - 0s 938us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 372/1000\n",
            "86/86 [==============================] - 0s 731us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 373/1000\n",
            "86/86 [==============================] - 0s 800us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 374/1000\n",
            "86/86 [==============================] - 0s 801us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 375/1000\n",
            "86/86 [==============================] - 0s 777us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 376/1000\n",
            "86/86 [==============================] - 0s 769us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 377/1000\n",
            "86/86 [==============================] - 0s 744us/step - loss: 0.0588 - val_loss: 0.0543\n",
            "Epoch 378/1000\n",
            "86/86 [==============================] - 0s 787us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 379/1000\n",
            "86/86 [==============================] - 0s 848us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 380/1000\n",
            "86/86 [==============================] - 0s 788us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 381/1000\n",
            "86/86 [==============================] - 0s 945us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 382/1000\n",
            "86/86 [==============================] - 0s 760us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 383/1000\n",
            "86/86 [==============================] - 0s 765us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 384/1000\n",
            "86/86 [==============================] - 0s 848us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 385/1000\n",
            "86/86 [==============================] - 0s 800us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 386/1000\n",
            "86/86 [==============================] - 0s 786us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 387/1000\n",
            "86/86 [==============================] - 0s 781us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 388/1000\n",
            "86/86 [==============================] - 0s 797us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 389/1000\n",
            "86/86 [==============================] - 0s 793us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 390/1000\n",
            "86/86 [==============================] - 0s 792us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 391/1000\n",
            "86/86 [==============================] - 0s 789us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 392/1000\n",
            "86/86 [==============================] - 0s 849us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 393/1000\n",
            "86/86 [==============================] - 0s 811us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 394/1000\n",
            "86/86 [==============================] - 0s 764us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 395/1000\n",
            "86/86 [==============================] - 0s 931us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 396/1000\n",
            "86/86 [==============================] - 0s 777us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 397/1000\n",
            "86/86 [==============================] - 0s 773us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 398/1000\n",
            "86/86 [==============================] - 0s 845us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 399/1000\n",
            "86/86 [==============================] - 0s 777us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 400/1000\n",
            "86/86 [==============================] - 0s 768us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 401/1000\n",
            "86/86 [==============================] - 0s 796us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 402/1000\n",
            "86/86 [==============================] - 0s 854us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 403/1000\n",
            "86/86 [==============================] - 0s 794us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 404/1000\n",
            "86/86 [==============================] - 0s 774us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 405/1000\n",
            "86/86 [==============================] - 0s 840us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 406/1000\n",
            "86/86 [==============================] - 0s 862us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 407/1000\n",
            "86/86 [==============================] - 0s 764us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 408/1000\n",
            "86/86 [==============================] - 0s 758us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 409/1000\n",
            "86/86 [==============================] - 0s 907us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 410/1000\n",
            "86/86 [==============================] - 0s 813us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 411/1000\n",
            "86/86 [==============================] - 0s 844us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 412/1000\n",
            "86/86 [==============================] - 0s 783us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 413/1000\n",
            "86/86 [==============================] - 0s 815us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 414/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0542\n",
            "Epoch 415/1000\n",
            "86/86 [==============================] - 0s 886us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 416/1000\n",
            "86/86 [==============================] - 0s 832us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 417/1000\n",
            "86/86 [==============================] - 0s 789us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 418/1000\n",
            "86/86 [==============================] - 0s 885us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 419/1000\n",
            "86/86 [==============================] - 0s 801us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 420/1000\n",
            "86/86 [==============================] - 0s 805us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 421/1000\n",
            "86/86 [==============================] - 0s 819us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 422/1000\n",
            "86/86 [==============================] - 0s 986us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 423/1000\n",
            "86/86 [==============================] - 0s 841us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 424/1000\n",
            "86/86 [==============================] - 0s 803us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 425/1000\n",
            "86/86 [==============================] - 0s 786us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 426/1000\n",
            "86/86 [==============================] - 0s 757us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 427/1000\n",
            "86/86 [==============================] - 0s 839us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 428/1000\n",
            "86/86 [==============================] - 0s 745us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 429/1000\n",
            "86/86 [==============================] - 0s 746us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 430/1000\n",
            "86/86 [==============================] - 0s 767us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 431/1000\n",
            "86/86 [==============================] - 0s 864us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 432/1000\n",
            "86/86 [==============================] - 0s 897us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 433/1000\n",
            "86/86 [==============================] - 0s 935us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 434/1000\n",
            "86/86 [==============================] - 0s 882us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 435/1000\n",
            "86/86 [==============================] - 0s 843us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 436/1000\n",
            "86/86 [==============================] - 0s 820us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 437/1000\n",
            "86/86 [==============================] - 0s 911us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 438/1000\n",
            "86/86 [==============================] - 0s 804us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 439/1000\n",
            "86/86 [==============================] - 0s 773us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 440/1000\n",
            "86/86 [==============================] - 0s 816us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 441/1000\n",
            "86/86 [==============================] - 0s 847us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 442/1000\n",
            "86/86 [==============================] - 0s 793us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 443/1000\n",
            "86/86 [==============================] - 0s 880us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 444/1000\n",
            "86/86 [==============================] - 0s 840us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 445/1000\n",
            "86/86 [==============================] - 0s 781us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 446/1000\n",
            "86/86 [==============================] - 0s 798us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 447/1000\n",
            "86/86 [==============================] - 0s 810us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 448/1000\n",
            "86/86 [==============================] - 0s 809us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 449/1000\n",
            "86/86 [==============================] - 0s 866us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 450/1000\n",
            "86/86 [==============================] - 0s 788us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 451/1000\n",
            "86/86 [==============================] - 0s 800us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 452/1000\n",
            "86/86 [==============================] - 0s 773us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 453/1000\n",
            "86/86 [==============================] - 0s 746us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 454/1000\n",
            "86/86 [==============================] - 0s 797us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 455/1000\n",
            "86/86 [==============================] - 0s 801us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 456/1000\n",
            "86/86 [==============================] - 0s 751us/step - loss: 0.0587 - val_loss: 0.0542\n",
            "Epoch 457/1000\n",
            "86/86 [==============================] - 0s 957us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 458/1000\n",
            "86/86 [==============================] - 0s 760us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 459/1000\n",
            "86/86 [==============================] - 0s 818us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 460/1000\n",
            "86/86 [==============================] - 0s 872us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 461/1000\n",
            "86/86 [==============================] - 0s 810us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 462/1000\n",
            "86/86 [==============================] - 0s 818us/step - loss: 0.0589 - val_loss: 0.0541\n",
            "Epoch 463/1000\n",
            "86/86 [==============================] - 0s 822us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 464/1000\n",
            "86/86 [==============================] - 0s 775us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 465/1000\n",
            "86/86 [==============================] - 0s 848us/step - loss: 0.0588 - val_loss: 0.0542\n",
            "Epoch 466/1000\n",
            "86/86 [==============================] - 0s 816us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 467/1000\n",
            "86/86 [==============================] - 0s 769us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 468/1000\n",
            "86/86 [==============================] - 0s 795us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 469/1000\n",
            "86/86 [==============================] - 0s 775us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 470/1000\n",
            "86/86 [==============================] - 0s 776us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 471/1000\n",
            "86/86 [==============================] - 0s 774us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 472/1000\n",
            "86/86 [==============================] - 0s 774us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 473/1000\n",
            "86/86 [==============================] - 0s 818us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 474/1000\n",
            "86/86 [==============================] - 0s 791us/step - loss: 0.0591 - val_loss: 0.0540\n",
            "Epoch 475/1000\n",
            "86/86 [==============================] - 0s 765us/step - loss: 0.0590 - val_loss: 0.0541\n",
            "Epoch 476/1000\n",
            "86/86 [==============================] - 0s 780us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 477/1000\n",
            "86/86 [==============================] - 0s 948us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 478/1000\n",
            "86/86 [==============================] - 0s 739us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 479/1000\n",
            "86/86 [==============================] - 0s 802us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 480/1000\n",
            "86/86 [==============================] - 0s 804us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 481/1000\n",
            "86/86 [==============================] - 0s 751us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 482/1000\n",
            "86/86 [==============================] - 0s 795us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 483/1000\n",
            "86/86 [==============================] - 0s 743us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 484/1000\n",
            "86/86 [==============================] - 0s 800us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 485/1000\n",
            "86/86 [==============================] - 0s 766us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 486/1000\n",
            "86/86 [==============================] - 0s 792us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 487/1000\n",
            "86/86 [==============================] - 0s 782us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 488/1000\n",
            "86/86 [==============================] - 0s 785us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 489/1000\n",
            "86/86 [==============================] - 0s 790us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 490/1000\n",
            "86/86 [==============================] - 0s 802us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 491/1000\n",
            "86/86 [==============================] - 0s 825us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 492/1000\n",
            "86/86 [==============================] - 0s 765us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 493/1000\n",
            "86/86 [==============================] - 0s 787us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 494/1000\n",
            "86/86 [==============================] - 0s 787us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 495/1000\n",
            "86/86 [==============================] - 0s 807us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 496/1000\n",
            "86/86 [==============================] - 0s 826us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 497/1000\n",
            "86/86 [==============================] - 0s 791us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 498/1000\n",
            "86/86 [==============================] - 0s 805us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 499/1000\n",
            "86/86 [==============================] - 0s 952us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 500/1000\n",
            "86/86 [==============================] - 0s 779us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 501/1000\n",
            "86/86 [==============================] - 0s 752us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 502/1000\n",
            "86/86 [==============================] - 0s 818us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 503/1000\n",
            "86/86 [==============================] - 0s 752us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 504/1000\n",
            "86/86 [==============================] - 0s 746us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 505/1000\n",
            "86/86 [==============================] - 0s 826us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 506/1000\n",
            "86/86 [==============================] - 0s 850us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 507/1000\n",
            "86/86 [==============================] - 0s 858us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 508/1000\n",
            "86/86 [==============================] - 0s 869us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 509/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 510/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0542\n",
            "Epoch 511/1000\n",
            "86/86 [==============================] - 0s 830us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 512/1000\n",
            "86/86 [==============================] - 0s 822us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 513/1000\n",
            "86/86 [==============================] - 0s 944us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 514/1000\n",
            "86/86 [==============================] - 0s 779us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 515/1000\n",
            "86/86 [==============================] - 0s 771us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 516/1000\n",
            "86/86 [==============================] - 0s 948us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 517/1000\n",
            "86/86 [==============================] - 0s 819us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 518/1000\n",
            "86/86 [==============================] - 0s 739us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 519/1000\n",
            "86/86 [==============================] - 0s 783us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 520/1000\n",
            "86/86 [==============================] - 0s 736us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 521/1000\n",
            "86/86 [==============================] - 0s 772us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 522/1000\n",
            "86/86 [==============================] - 0s 796us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 523/1000\n",
            "86/86 [==============================] - 0s 809us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 524/1000\n",
            "86/86 [==============================] - 0s 785us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 525/1000\n",
            "86/86 [==============================] - 0s 779us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 526/1000\n",
            "86/86 [==============================] - 0s 783us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 527/1000\n",
            "86/86 [==============================] - 0s 830us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 528/1000\n",
            "86/86 [==============================] - 0s 776us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 529/1000\n",
            "86/86 [==============================] - 0s 770us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 530/1000\n",
            "86/86 [==============================] - 0s 781us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 531/1000\n",
            "86/86 [==============================] - 0s 897us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 532/1000\n",
            "86/86 [==============================] - 0s 786us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 533/1000\n",
            "86/86 [==============================] - 0s 812us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 534/1000\n",
            "86/86 [==============================] - 0s 762us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 535/1000\n",
            "86/86 [==============================] - 0s 750us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 536/1000\n",
            "86/86 [==============================] - 0s 931us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 537/1000\n",
            "86/86 [==============================] - 0s 770us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 538/1000\n",
            "86/86 [==============================] - 0s 766us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 539/1000\n",
            "86/86 [==============================] - 0s 814us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 540/1000\n",
            "86/86 [==============================] - 0s 861us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 541/1000\n",
            "86/86 [==============================] - 0s 910us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 542/1000\n",
            "86/86 [==============================] - 0s 851us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 543/1000\n",
            "86/86 [==============================] - 0s 785us/step - loss: 0.0587 - val_loss: 0.0542\n",
            "Epoch 544/1000\n",
            "86/86 [==============================] - 0s 770us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 545/1000\n",
            "86/86 [==============================] - 0s 826us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 546/1000\n",
            "86/86 [==============================] - 0s 798us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 547/1000\n",
            "86/86 [==============================] - 0s 793us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 548/1000\n",
            "86/86 [==============================] - 0s 897us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 549/1000\n",
            "86/86 [==============================] - 0s 789us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 550/1000\n",
            "86/86 [==============================] - 0s 786us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 551/1000\n",
            "86/86 [==============================] - 0s 786us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 552/1000\n",
            "86/86 [==============================] - 0s 753us/step - loss: 0.0589 - val_loss: 0.0541\n",
            "Epoch 553/1000\n",
            "86/86 [==============================] - 0s 771us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 554/1000\n",
            "86/86 [==============================] - 0s 788us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 555/1000\n",
            "86/86 [==============================] - 0s 886us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 556/1000\n",
            "86/86 [==============================] - 0s 783us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 557/1000\n",
            "86/86 [==============================] - 0s 760us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 558/1000\n",
            "86/86 [==============================] - 0s 766us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 559/1000\n",
            "86/86 [==============================] - 0s 816us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 560/1000\n",
            "86/86 [==============================] - 0s 780us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 561/1000\n",
            "86/86 [==============================] - 0s 851us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 562/1000\n",
            "86/86 [==============================] - 0s 766us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 563/1000\n",
            "86/86 [==============================] - 0s 759us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 564/1000\n",
            "86/86 [==============================] - 0s 782us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 565/1000\n",
            "86/86 [==============================] - 0s 811us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 566/1000\n",
            "86/86 [==============================] - 0s 761us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 567/1000\n",
            "86/86 [==============================] - 0s 764us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 568/1000\n",
            "86/86 [==============================] - 0s 780us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 569/1000\n",
            "86/86 [==============================] - 0s 810us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 570/1000\n",
            "86/86 [==============================] - 0s 757us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 571/1000\n",
            "86/86 [==============================] - 0s 763us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 572/1000\n",
            "86/86 [==============================] - 0s 790us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 573/1000\n",
            "86/86 [==============================] - 0s 871us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 574/1000\n",
            "86/86 [==============================] - 0s 980us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 575/1000\n",
            "86/86 [==============================] - 0s 790us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 576/1000\n",
            "86/86 [==============================] - 0s 795us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 577/1000\n",
            "86/86 [==============================] - 0s 827us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 578/1000\n",
            "86/86 [==============================] - 0s 756us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 579/1000\n",
            "86/86 [==============================] - 0s 783us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 580/1000\n",
            "86/86 [==============================] - 0s 785us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 581/1000\n",
            "86/86 [==============================] - 0s 823us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 582/1000\n",
            "86/86 [==============================] - 0s 771us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 583/1000\n",
            "86/86 [==============================] - 0s 748us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 584/1000\n",
            "86/86 [==============================] - 0s 808us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 585/1000\n",
            "86/86 [==============================] - 0s 768us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 586/1000\n",
            "86/86 [==============================] - 0s 760us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 587/1000\n",
            "86/86 [==============================] - 0s 831us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 588/1000\n",
            "86/86 [==============================] - 0s 843us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 589/1000\n",
            "86/86 [==============================] - 0s 778us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 590/1000\n",
            "86/86 [==============================] - 0s 761us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 591/1000\n",
            "86/86 [==============================] - 0s 807us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 592/1000\n",
            "86/86 [==============================] - 0s 810us/step - loss: 0.0588 - val_loss: 0.0542\n",
            "Epoch 593/1000\n",
            "86/86 [==============================] - 0s 852us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 594/1000\n",
            "86/86 [==============================] - 0s 757us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 595/1000\n",
            "86/86 [==============================] - 0s 844us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 596/1000\n",
            "86/86 [==============================] - 0s 903us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 597/1000\n",
            "86/86 [==============================] - 0s 788us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 598/1000\n",
            "86/86 [==============================] - 0s 757us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 599/1000\n",
            "86/86 [==============================] - 0s 744us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 600/1000\n",
            "86/86 [==============================] - 0s 765us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 601/1000\n",
            "86/86 [==============================] - 0s 836us/step - loss: 0.0588 - val_loss: 0.0543\n",
            "Epoch 602/1000\n",
            "86/86 [==============================] - 0s 771us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 603/1000\n",
            "86/86 [==============================] - 0s 812us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 604/1000\n",
            "86/86 [==============================] - 0s 798us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 605/1000\n",
            "86/86 [==============================] - 0s 778us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 606/1000\n",
            "86/86 [==============================] - 0s 739us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 607/1000\n",
            "86/86 [==============================] - 0s 784us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 608/1000\n",
            "86/86 [==============================] - 0s 814us/step - loss: 0.0589 - val_loss: 0.0541\n",
            "Epoch 609/1000\n",
            "86/86 [==============================] - 0s 814us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 610/1000\n",
            "86/86 [==============================] - 0s 772us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 611/1000\n",
            "86/86 [==============================] - 0s 760us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 612/1000\n",
            "86/86 [==============================] - 0s 859us/step - loss: 0.0588 - val_loss: 0.0542\n",
            "Epoch 613/1000\n",
            "86/86 [==============================] - 0s 802us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 614/1000\n",
            "86/86 [==============================] - 0s 809us/step - loss: 0.0588 - val_loss: 0.0542\n",
            "Epoch 615/1000\n",
            "86/86 [==============================] - 0s 922us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 616/1000\n",
            "86/86 [==============================] - 0s 778us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 617/1000\n",
            "86/86 [==============================] - 0s 775us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 618/1000\n",
            "86/86 [==============================] - 0s 742us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 619/1000\n",
            "86/86 [==============================] - 0s 763us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 620/1000\n",
            "86/86 [==============================] - 0s 755us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 621/1000\n",
            "86/86 [==============================] - 0s 740us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 622/1000\n",
            "86/86 [==============================] - 0s 817us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 623/1000\n",
            "86/86 [==============================] - 0s 779us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 624/1000\n",
            "86/86 [==============================] - 0s 760us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 625/1000\n",
            "86/86 [==============================] - 0s 794us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 626/1000\n",
            "86/86 [==============================] - 0s 804us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 627/1000\n",
            "86/86 [==============================] - 0s 772us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 628/1000\n",
            "86/86 [==============================] - 0s 778us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 629/1000\n",
            "86/86 [==============================] - 0s 894us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 630/1000\n",
            "86/86 [==============================] - 0s 818us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 631/1000\n",
            "86/86 [==============================] - 0s 802us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 632/1000\n",
            "86/86 [==============================] - 0s 743us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 633/1000\n",
            "86/86 [==============================] - 0s 782us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 634/1000\n",
            "86/86 [==============================] - 0s 749us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 635/1000\n",
            "86/86 [==============================] - 0s 843us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 636/1000\n",
            "86/86 [==============================] - 0s 911us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 637/1000\n",
            "86/86 [==============================] - 0s 805us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 638/1000\n",
            "86/86 [==============================] - 0s 811us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 639/1000\n",
            "86/86 [==============================] - 0s 814us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 640/1000\n",
            "86/86 [==============================] - 0s 778us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 641/1000\n",
            "86/86 [==============================] - 0s 779us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 642/1000\n",
            "86/86 [==============================] - 0s 809us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 643/1000\n",
            "86/86 [==============================] - 0s 921us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 644/1000\n",
            "86/86 [==============================] - 0s 777us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 645/1000\n",
            "86/86 [==============================] - 0s 752us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 646/1000\n",
            "86/86 [==============================] - 0s 789us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 647/1000\n",
            "86/86 [==============================] - 0s 846us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 648/1000\n",
            "86/86 [==============================] - 0s 803us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 649/1000\n",
            "86/86 [==============================] - 0s 764us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 650/1000\n",
            "86/86 [==============================] - 0s 770us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 651/1000\n",
            "86/86 [==============================] - 0s 801us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 652/1000\n",
            "86/86 [==============================] - 0s 959us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 653/1000\n",
            "86/86 [==============================] - 0s 753us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 654/1000\n",
            "86/86 [==============================] - 0s 790us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 655/1000\n",
            "86/86 [==============================] - 0s 778us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 656/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 657/1000\n",
            "86/86 [==============================] - 0s 815us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 658/1000\n",
            "86/86 [==============================] - 0s 751us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 659/1000\n",
            "86/86 [==============================] - 0s 812us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 660/1000\n",
            "86/86 [==============================] - 0s 830us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 661/1000\n",
            "86/86 [==============================] - 0s 792us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 662/1000\n",
            "86/86 [==============================] - 0s 873us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 663/1000\n",
            "86/86 [==============================] - 0s 775us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 664/1000\n",
            "86/86 [==============================] - 0s 762us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 665/1000\n",
            "86/86 [==============================] - 0s 788us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 666/1000\n",
            "86/86 [==============================] - 0s 801us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 667/1000\n",
            "86/86 [==============================] - 0s 794us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 668/1000\n",
            "86/86 [==============================] - 0s 811us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 669/1000\n",
            "86/86 [==============================] - 0s 876us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 670/1000\n",
            "86/86 [==============================] - 0s 842us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 671/1000\n",
            "86/86 [==============================] - 0s 797us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 672/1000\n",
            "86/86 [==============================] - 0s 774us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 673/1000\n",
            "86/86 [==============================] - 0s 799us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 674/1000\n",
            "86/86 [==============================] - 0s 785us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 675/1000\n",
            "86/86 [==============================] - 0s 806us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 676/1000\n",
            "86/86 [==============================] - 0s 781us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 677/1000\n",
            "86/86 [==============================] - 0s 779us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 678/1000\n",
            "86/86 [==============================] - 0s 789us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 679/1000\n",
            "86/86 [==============================] - 0s 775us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 680/1000\n",
            "86/86 [==============================] - 0s 810us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 681/1000\n",
            "86/86 [==============================] - 0s 829us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 682/1000\n",
            "86/86 [==============================] - 0s 766us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 683/1000\n",
            "86/86 [==============================] - 0s 758us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 684/1000\n",
            "86/86 [==============================] - 0s 811us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 685/1000\n",
            "86/86 [==============================] - 0s 812us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 686/1000\n",
            "86/86 [==============================] - 0s 836us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 687/1000\n",
            "86/86 [==============================] - 0s 799us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 688/1000\n",
            "86/86 [==============================] - 0s 776us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 689/1000\n",
            "86/86 [==============================] - 0s 806us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 690/1000\n",
            "86/86 [==============================] - 0s 813us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 691/1000\n",
            "86/86 [==============================] - 0s 852us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 692/1000\n",
            "86/86 [==============================] - 0s 793us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 693/1000\n",
            "86/86 [==============================] - 0s 788us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 694/1000\n",
            "86/86 [==============================] - 0s 782us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 695/1000\n",
            "86/86 [==============================] - 0s 771us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 696/1000\n",
            "86/86 [==============================] - 0s 790us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 697/1000\n",
            "86/86 [==============================] - 0s 794us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 698/1000\n",
            "86/86 [==============================] - 0s 921us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 699/1000\n",
            "86/86 [==============================] - 0s 768us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 700/1000\n",
            "86/86 [==============================] - 0s 750us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 701/1000\n",
            "86/86 [==============================] - 0s 927us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 702/1000\n",
            "86/86 [==============================] - 0s 758us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 703/1000\n",
            "86/86 [==============================] - 0s 756us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 704/1000\n",
            "86/86 [==============================] - 0s 788us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 705/1000\n",
            "86/86 [==============================] - 0s 787us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 706/1000\n",
            "86/86 [==============================] - 0s 747us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 707/1000\n",
            "86/86 [==============================] - 0s 761us/step - loss: 0.0588 - val_loss: 0.0542\n",
            "Epoch 708/1000\n",
            "86/86 [==============================] - 0s 816us/step - loss: 0.0588 - val_loss: 0.0543\n",
            "Epoch 709/1000\n",
            "86/86 [==============================] - 0s 837us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 710/1000\n",
            "86/86 [==============================] - 0s 810us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 711/1000\n",
            "86/86 [==============================] - 0s 807us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 712/1000\n",
            "86/86 [==============================] - 0s 929us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 713/1000\n",
            "86/86 [==============================] - 0s 778us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 714/1000\n",
            "86/86 [==============================] - 0s 764us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 715/1000\n",
            "86/86 [==============================] - 0s 776us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 716/1000\n",
            "86/86 [==============================] - 0s 772us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 717/1000\n",
            "86/86 [==============================] - 0s 790us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 718/1000\n",
            "86/86 [==============================] - 0s 760us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 719/1000\n",
            "86/86 [==============================] - 0s 796us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 720/1000\n",
            "86/86 [==============================] - 0s 796us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 721/1000\n",
            "86/86 [==============================] - 0s 834us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 722/1000\n",
            "86/86 [==============================] - 0s 756us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 723/1000\n",
            "86/86 [==============================] - 0s 789us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 724/1000\n",
            "86/86 [==============================] - 0s 795us/step - loss: 0.0590 - val_loss: 0.0540\n",
            "Epoch 725/1000\n",
            "86/86 [==============================] - 0s 862us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 726/1000\n",
            "86/86 [==============================] - 0s 962us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 727/1000\n",
            "86/86 [==============================] - 0s 837us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 728/1000\n",
            "86/86 [==============================] - 0s 816us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 729/1000\n",
            "86/86 [==============================] - 0s 849us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 730/1000\n",
            "86/86 [==============================] - 0s 785us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 731/1000\n",
            "86/86 [==============================] - 0s 736us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 732/1000\n",
            "86/86 [==============================] - 0s 746us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 733/1000\n",
            "86/86 [==============================] - 0s 768us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 734/1000\n",
            "86/86 [==============================] - 0s 890us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 735/1000\n",
            "86/86 [==============================] - 0s 757us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 736/1000\n",
            "86/86 [==============================] - 0s 756us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 737/1000\n",
            "86/86 [==============================] - 0s 784us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 738/1000\n",
            "86/86 [==============================] - 0s 776us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 739/1000\n",
            "86/86 [==============================] - 0s 956us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 740/1000\n",
            "86/86 [==============================] - 0s 825us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 741/1000\n",
            "86/86 [==============================] - 0s 779us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 742/1000\n",
            "86/86 [==============================] - 0s 832us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 743/1000\n",
            "86/86 [==============================] - 0s 762us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 744/1000\n",
            "86/86 [==============================] - 0s 838us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 745/1000\n",
            "86/86 [==============================] - 0s 762us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 746/1000\n",
            "86/86 [==============================] - 0s 746us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 747/1000\n",
            "86/86 [==============================] - 0s 769us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 748/1000\n",
            "86/86 [==============================] - 0s 838us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 749/1000\n",
            "86/86 [==============================] - 0s 805us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 750/1000\n",
            "86/86 [==============================] - 0s 764us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 751/1000\n",
            "86/86 [==============================] - 0s 857us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 752/1000\n",
            "86/86 [==============================] - 0s 778us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 753/1000\n",
            "86/86 [==============================] - 0s 880us/step - loss: 0.0588 - val_loss: 0.0542\n",
            "Epoch 754/1000\n",
            "86/86 [==============================] - 0s 808us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 755/1000\n",
            "86/86 [==============================] - 0s 885us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 756/1000\n",
            "86/86 [==============================] - 0s 875us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 757/1000\n",
            "86/86 [==============================] - 0s 782us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 758/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 759/1000\n",
            "86/86 [==============================] - 0s 794us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 760/1000\n",
            "86/86 [==============================] - 0s 811us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 761/1000\n",
            "86/86 [==============================] - 0s 794us/step - loss: 0.0588 - val_loss: 0.0542\n",
            "Epoch 762/1000\n",
            "86/86 [==============================] - 0s 833us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 763/1000\n",
            "86/86 [==============================] - 0s 891us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 764/1000\n",
            "86/86 [==============================] - 0s 847us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 765/1000\n",
            "86/86 [==============================] - 0s 779us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 766/1000\n",
            "86/86 [==============================] - 0s 852us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 767/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 768/1000\n",
            "86/86 [==============================] - 0s 774us/step - loss: 0.0587 - val_loss: 0.0542\n",
            "Epoch 769/1000\n",
            "86/86 [==============================] - 0s 739us/step - loss: 0.0588 - val_loss: 0.0542\n",
            "Epoch 770/1000\n",
            "86/86 [==============================] - 0s 797us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 771/1000\n",
            "86/86 [==============================] - 0s 740us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 772/1000\n",
            "86/86 [==============================] - 0s 772us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 773/1000\n",
            "86/86 [==============================] - 0s 741us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 774/1000\n",
            "86/86 [==============================] - 0s 844us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 775/1000\n",
            "86/86 [==============================] - 0s 832us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 776/1000\n",
            "86/86 [==============================] - 0s 807us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 777/1000\n",
            "86/86 [==============================] - 0s 782us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 778/1000\n",
            "86/86 [==============================] - 0s 771us/step - loss: 0.0589 - val_loss: 0.0542\n",
            "Epoch 779/1000\n",
            "86/86 [==============================] - 0s 880us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 780/1000\n",
            "86/86 [==============================] - 0s 890us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 781/1000\n",
            "86/86 [==============================] - 0s 811us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 782/1000\n",
            "86/86 [==============================] - 0s 779us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 783/1000\n",
            "86/86 [==============================] - 0s 771us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 784/1000\n",
            "86/86 [==============================] - 0s 769us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 785/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 786/1000\n",
            "86/86 [==============================] - 0s 795us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 787/1000\n",
            "86/86 [==============================] - 0s 801us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 788/1000\n",
            "86/86 [==============================] - 0s 821us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 789/1000\n",
            "86/86 [==============================] - 0s 782us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 790/1000\n",
            "86/86 [==============================] - 0s 763us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 791/1000\n",
            "86/86 [==============================] - 0s 739us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 792/1000\n",
            "86/86 [==============================] - 0s 790us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 793/1000\n",
            "86/86 [==============================] - 0s 825us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 794/1000\n",
            "86/86 [==============================] - 0s 839us/step - loss: 0.0587 - val_loss: 0.0542\n",
            "Epoch 795/1000\n",
            "86/86 [==============================] - 0s 851us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 796/1000\n",
            "86/86 [==============================] - 0s 787us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 797/1000\n",
            "86/86 [==============================] - 0s 786us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 798/1000\n",
            "86/86 [==============================] - 0s 772us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 799/1000\n",
            "86/86 [==============================] - 0s 757us/step - loss: 0.0587 - val_loss: 0.0543\n",
            "Epoch 800/1000\n",
            "86/86 [==============================] - 0s 776us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 801/1000\n",
            "86/86 [==============================] - 0s 809us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 802/1000\n",
            "86/86 [==============================] - 0s 798us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 803/1000\n",
            "86/86 [==============================] - 0s 818us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 804/1000\n",
            "86/86 [==============================] - 0s 862us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 805/1000\n",
            "86/86 [==============================] - 0s 864us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 806/1000\n",
            "86/86 [==============================] - 0s 780us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 807/1000\n",
            "86/86 [==============================] - 0s 828us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 808/1000\n",
            "86/86 [==============================] - 0s 856us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 809/1000\n",
            "86/86 [==============================] - 0s 768us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 810/1000\n",
            "86/86 [==============================] - 0s 757us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 811/1000\n",
            "86/86 [==============================] - 0s 777us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 812/1000\n",
            "86/86 [==============================] - 0s 921us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 813/1000\n",
            "86/86 [==============================] - 0s 799us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 814/1000\n",
            "86/86 [==============================] - 0s 763us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 815/1000\n",
            "86/86 [==============================] - 0s 792us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 816/1000\n",
            "86/86 [==============================] - 0s 758us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 817/1000\n",
            "86/86 [==============================] - 0s 749us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 818/1000\n",
            "86/86 [==============================] - 0s 745us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 819/1000\n",
            "86/86 [==============================] - 0s 758us/step - loss: 0.0588 - val_loss: 0.0542\n",
            "Epoch 820/1000\n",
            "86/86 [==============================] - 0s 788us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 821/1000\n",
            "86/86 [==============================] - 0s 882us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 822/1000\n",
            "86/86 [==============================] - 0s 936us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 823/1000\n",
            "86/86 [==============================] - 0s 758us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 824/1000\n",
            "86/86 [==============================] - 0s 776us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 825/1000\n",
            "86/86 [==============================] - 0s 755us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 826/1000\n",
            "86/86 [==============================] - 0s 731us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 827/1000\n",
            "86/86 [==============================] - 0s 744us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 828/1000\n",
            "86/86 [==============================] - 0s 866us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 829/1000\n",
            "86/86 [==============================] - 0s 912us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 830/1000\n",
            "86/86 [==============================] - 0s 789us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 831/1000\n",
            "86/86 [==============================] - 0s 743us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 832/1000\n",
            "86/86 [==============================] - 0s 786us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 833/1000\n",
            "86/86 [==============================] - 0s 781us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 834/1000\n",
            "86/86 [==============================] - 0s 810us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 835/1000\n",
            "86/86 [==============================] - 0s 785us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 836/1000\n",
            "86/86 [==============================] - 0s 820us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 837/1000\n",
            "86/86 [==============================] - 0s 755us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 838/1000\n",
            "86/86 [==============================] - 0s 744us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 839/1000\n",
            "86/86 [==============================] - 0s 740us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 840/1000\n",
            "86/86 [==============================] - 0s 763us/step - loss: 0.0587 - val_loss: 0.0542\n",
            "Epoch 841/1000\n",
            "86/86 [==============================] - 0s 757us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 842/1000\n",
            "86/86 [==============================] - 0s 793us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 843/1000\n",
            "86/86 [==============================] - 0s 809us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 844/1000\n",
            "86/86 [==============================] - 0s 825us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 845/1000\n",
            "86/86 [==============================] - 0s 910us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 846/1000\n",
            "86/86 [==============================] - 0s 788us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 847/1000\n",
            "86/86 [==============================] - 0s 762us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 848/1000\n",
            "86/86 [==============================] - 0s 780us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 849/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 850/1000\n",
            "86/86 [==============================] - 0s 771us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 851/1000\n",
            "86/86 [==============================] - 0s 780us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 852/1000\n",
            "86/86 [==============================] - 0s 901us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 853/1000\n",
            "86/86 [==============================] - 0s 795us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 854/1000\n",
            "86/86 [==============================] - 0s 803us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 855/1000\n",
            "86/86 [==============================] - 0s 777us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 856/1000\n",
            "86/86 [==============================] - 0s 780us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 857/1000\n",
            "86/86 [==============================] - 0s 785us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 858/1000\n",
            "86/86 [==============================] - 0s 774us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 859/1000\n",
            "86/86 [==============================] - 0s 773us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 860/1000\n",
            "86/86 [==============================] - 0s 850us/step - loss: 0.0589 - val_loss: 0.0541\n",
            "Epoch 861/1000\n",
            "86/86 [==============================] - 0s 757us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 862/1000\n",
            "86/86 [==============================] - 0s 818us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 863/1000\n",
            "86/86 [==============================] - 0s 864us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 864/1000\n",
            "86/86 [==============================] - 0s 808us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 865/1000\n",
            "86/86 [==============================] - 0s 780us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 866/1000\n",
            "86/86 [==============================] - 0s 773us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 867/1000\n",
            "86/86 [==============================] - 0s 756us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 868/1000\n",
            "86/86 [==============================] - 0s 781us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 869/1000\n",
            "86/86 [==============================] - 0s 821us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 870/1000\n",
            "86/86 [==============================] - 0s 796us/step - loss: 0.0588 - val_loss: 0.0543\n",
            "Epoch 871/1000\n",
            "86/86 [==============================] - 0s 774us/step - loss: 0.0589 - val_loss: 0.0541\n",
            "Epoch 872/1000\n",
            "86/86 [==============================] - 0s 851us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 873/1000\n",
            "86/86 [==============================] - 0s 828us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 874/1000\n",
            "86/86 [==============================] - 0s 754us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 875/1000\n",
            "86/86 [==============================] - 0s 761us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 876/1000\n",
            "86/86 [==============================] - 0s 796us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 877/1000\n",
            "86/86 [==============================] - 0s 786us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 878/1000\n",
            "86/86 [==============================] - 0s 793us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 879/1000\n",
            "86/86 [==============================] - 0s 758us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 880/1000\n",
            "86/86 [==============================] - 0s 775us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 881/1000\n",
            "86/86 [==============================] - 0s 766us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 882/1000\n",
            "86/86 [==============================] - 0s 918us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 883/1000\n",
            "86/86 [==============================] - 0s 771us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 884/1000\n",
            "86/86 [==============================] - 0s 803us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 885/1000\n",
            "86/86 [==============================] - 0s 769us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 886/1000\n",
            "86/86 [==============================] - 0s 832us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 887/1000\n",
            "86/86 [==============================] - 0s 757us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 888/1000\n",
            "86/86 [==============================] - 0s 866us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 889/1000\n",
            "86/86 [==============================] - 0s 827us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 890/1000\n",
            "86/86 [==============================] - 0s 773us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 891/1000\n",
            "86/86 [==============================] - 0s 819us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 892/1000\n",
            "86/86 [==============================] - 0s 817us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 893/1000\n",
            "86/86 [==============================] - 0s 878us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 894/1000\n",
            "86/86 [==============================] - 0s 816us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 895/1000\n",
            "86/86 [==============================] - 0s 777us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 896/1000\n",
            "86/86 [==============================] - 0s 766us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 897/1000\n",
            "86/86 [==============================] - 0s 794us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 898/1000\n",
            "86/86 [==============================] - 0s 768us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 899/1000\n",
            "86/86 [==============================] - 0s 824us/step - loss: 0.0586 - val_loss: 0.0543\n",
            "Epoch 900/1000\n",
            "86/86 [==============================] - 0s 810us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 901/1000\n",
            "86/86 [==============================] - 0s 763us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 902/1000\n",
            "86/86 [==============================] - 0s 770us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 903/1000\n",
            "86/86 [==============================] - 0s 806us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 904/1000\n",
            "86/86 [==============================] - 0s 805us/step - loss: 0.0588 - val_loss: 0.0543\n",
            "Epoch 905/1000\n",
            "86/86 [==============================] - 0s 879us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 906/1000\n",
            "86/86 [==============================] - 0s 817us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 907/1000\n",
            "86/86 [==============================] - 0s 782us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 908/1000\n",
            "86/86 [==============================] - 0s 768us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 909/1000\n",
            "86/86 [==============================] - 0s 737us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 910/1000\n",
            "86/86 [==============================] - 0s 743us/step - loss: 0.0588 - val_loss: 0.0543\n",
            "Epoch 911/1000\n",
            "86/86 [==============================] - 0s 777us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 912/1000\n",
            "86/86 [==============================] - 0s 751us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 913/1000\n",
            "86/86 [==============================] - 0s 778us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 914/1000\n",
            "86/86 [==============================] - 0s 839us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 915/1000\n",
            "86/86 [==============================] - 0s 786us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 916/1000\n",
            "86/86 [==============================] - 0s 904us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 917/1000\n",
            "86/86 [==============================] - 0s 818us/step - loss: 0.0587 - val_loss: 0.0543\n",
            "Epoch 918/1000\n",
            "86/86 [==============================] - 0s 826us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 919/1000\n",
            "86/86 [==============================] - 0s 901us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 920/1000\n",
            "86/86 [==============================] - 0s 752us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 921/1000\n",
            "86/86 [==============================] - 0s 919us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 922/1000\n",
            "86/86 [==============================] - 0s 841us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 923/1000\n",
            "86/86 [==============================] - 0s 815us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 924/1000\n",
            "86/86 [==============================] - 0s 795us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 925/1000\n",
            "86/86 [==============================] - 0s 840us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 926/1000\n",
            "86/86 [==============================] - 0s 786us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 927/1000\n",
            "86/86 [==============================] - 0s 797us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 928/1000\n",
            "86/86 [==============================] - 0s 805us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 929/1000\n",
            "86/86 [==============================] - 0s 780us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 930/1000\n",
            "86/86 [==============================] - 0s 758us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 931/1000\n",
            "86/86 [==============================] - 0s 739us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 932/1000\n",
            "86/86 [==============================] - 0s 872us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 933/1000\n",
            "86/86 [==============================] - 0s 812us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 934/1000\n",
            "86/86 [==============================] - 0s 989us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 935/1000\n",
            "86/86 [==============================] - 0s 861us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 936/1000\n",
            "86/86 [==============================] - 0s 826us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 937/1000\n",
            "86/86 [==============================] - 0s 807us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 938/1000\n",
            "86/86 [==============================] - 0s 753us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 939/1000\n",
            "86/86 [==============================] - 0s 785us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 940/1000\n",
            "86/86 [==============================] - 0s 784us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 941/1000\n",
            "86/86 [==============================] - 0s 797us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 942/1000\n",
            "86/86 [==============================] - 0s 782us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 943/1000\n",
            "86/86 [==============================] - 0s 799us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 944/1000\n",
            "86/86 [==============================] - 0s 771us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 945/1000\n",
            "86/86 [==============================] - 0s 797us/step - loss: 0.0588 - val_loss: 0.0543\n",
            "Epoch 946/1000\n",
            "86/86 [==============================] - 0s 953us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 947/1000\n",
            "86/86 [==============================] - 0s 772us/step - loss: 0.0587 - val_loss: 0.0542\n",
            "Epoch 948/1000\n",
            "86/86 [==============================] - 0s 773us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 949/1000\n",
            "86/86 [==============================] - 0s 764us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 950/1000\n",
            "86/86 [==============================] - 0s 814us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 951/1000\n",
            "86/86 [==============================] - 0s 817us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 952/1000\n",
            "86/86 [==============================] - 0s 793us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 953/1000\n",
            "86/86 [==============================] - 0s 794us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 954/1000\n",
            "86/86 [==============================] - 0s 825us/step - loss: 0.0587 - val_loss: 0.0543\n",
            "Epoch 955/1000\n",
            "86/86 [==============================] - 0s 857us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 956/1000\n",
            "86/86 [==============================] - 0s 764us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 957/1000\n",
            "86/86 [==============================] - 0s 781us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 958/1000\n",
            "86/86 [==============================] - 0s 833us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 959/1000\n",
            "86/86 [==============================] - 0s 987us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 960/1000\n",
            "86/86 [==============================] - 0s 897us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 961/1000\n",
            "86/86 [==============================] - 0s 795us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 962/1000\n",
            "86/86 [==============================] - 0s 861us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 963/1000\n",
            "86/86 [==============================] - 0s 791us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 964/1000\n",
            "86/86 [==============================] - 0s 777us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 965/1000\n",
            "86/86 [==============================] - 0s 765us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 966/1000\n",
            "86/86 [==============================] - 0s 828us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 967/1000\n",
            "86/86 [==============================] - 0s 826us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 968/1000\n",
            "86/86 [==============================] - 0s 755us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 969/1000\n",
            "86/86 [==============================] - 0s 755us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 970/1000\n",
            "86/86 [==============================] - 0s 810us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 971/1000\n",
            "86/86 [==============================] - 0s 919us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 972/1000\n",
            "86/86 [==============================] - 0s 749us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 973/1000\n",
            "86/86 [==============================] - 0s 815us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 974/1000\n",
            "86/86 [==============================] - 0s 753us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 975/1000\n",
            "86/86 [==============================] - 0s 782us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 976/1000\n",
            "86/86 [==============================] - 0s 783us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 977/1000\n",
            "86/86 [==============================] - 0s 762us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 978/1000\n",
            "86/86 [==============================] - 0s 928us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 979/1000\n",
            "86/86 [==============================] - 0s 773us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 980/1000\n",
            "86/86 [==============================] - 0s 813us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 981/1000\n",
            "86/86 [==============================] - 0s 780us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 982/1000\n",
            "86/86 [==============================] - 0s 755us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 983/1000\n",
            "86/86 [==============================] - 0s 784us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 984/1000\n",
            "86/86 [==============================] - 0s 768us/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 985/1000\n",
            "86/86 [==============================] - 0s 872us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 986/1000\n",
            "86/86 [==============================] - 0s 756us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 987/1000\n",
            "86/86 [==============================] - 0s 771us/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 988/1000\n",
            "86/86 [==============================] - 0s 827us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 989/1000\n",
            "86/86 [==============================] - 0s 776us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 990/1000\n",
            "86/86 [==============================] - 0s 772us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 991/1000\n",
            "86/86 [==============================] - 0s 808us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 992/1000\n",
            "86/86 [==============================] - 0s 756us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 993/1000\n",
            "86/86 [==============================] - 0s 763us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 994/1000\n",
            "86/86 [==============================] - 0s 781us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 995/1000\n",
            "86/86 [==============================] - 0s 781us/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 996/1000\n",
            "86/86 [==============================] - 0s 803us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 997/1000\n",
            "86/86 [==============================] - 0s 794us/step - loss: 0.0587 - val_loss: 0.0542\n",
            "Epoch 998/1000\n",
            "86/86 [==============================] - 0s 913us/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 999/1000\n",
            "86/86 [==============================] - 0s 870us/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 1000/1000\n",
            "86/86 [==============================] - 0s 802us/step - loss: 0.0588 - val_loss: 0.0540\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOF0cAI5cjP6",
        "outputId": "19ad6fe3-3ae1-430b-b822-fa5937189ed2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "deeper_history_dataframe = pd.DataFrame(deeper_model_history.history)\n",
        "deeper_history_dataframe['epoch'] = deeper_model_history.epoch\n",
        "deeper_history_dataframe.sort_values(by='val_loss', ascending=True)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>402</th>\n",
              "      <td>0.058752</td>\n",
              "      <td>0.053977</td>\n",
              "      <td>402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>693</th>\n",
              "      <td>0.058766</td>\n",
              "      <td>0.053977</td>\n",
              "      <td>693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>883</th>\n",
              "      <td>0.058751</td>\n",
              "      <td>0.053978</td>\n",
              "      <td>883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>428</th>\n",
              "      <td>0.058780</td>\n",
              "      <td>0.053978</td>\n",
              "      <td>428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>759</th>\n",
              "      <td>0.058774</td>\n",
              "      <td>0.053978</td>\n",
              "      <td>759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.059546</td>\n",
              "      <td>0.054666</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.059669</td>\n",
              "      <td>0.054934</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.059816</td>\n",
              "      <td>0.054998</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.060114</td>\n",
              "      <td>0.055194</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.066305</td>\n",
              "      <td>0.055639</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         loss  val_loss  epoch\n",
              "402  0.058752  0.053977    402\n",
              "693  0.058766  0.053977    693\n",
              "883  0.058751  0.053978    883\n",
              "428  0.058780  0.053978    428\n",
              "759  0.058774  0.053978    759\n",
              "..        ...       ...    ...\n",
              "4    0.059546  0.054666      4\n",
              "3    0.059669  0.054934      3\n",
              "2    0.059816  0.054998      2\n",
              "1    0.060114  0.055194      1\n",
              "0    0.066305  0.055639      0\n",
              "\n",
              "[1000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oY21Tu9QcjHr",
        "outputId": "83dbfb76-2818-4276-9230-1526531e28b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "plot_loss(deeper_model_history) # epoch vs loss graph"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7j2rsHWdJdH"
      },
      "source": [
        "### Wider"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nY1RWmfUdHhy",
        "outputId": "59b208b8-91af-4a29-e46d-45c2afd54ad0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "neurons = 50\n",
        "epoch = 1000\n",
        "batch_size = 32\n",
        "\n",
        "wider_model = Sequential()\n",
        "wider_model.add(Dense(neurons, activation='relu', input_dim=feature_train.shape[1]))\n",
        "wider_model.add(Dense(1))\n",
        "wider_model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "wider_model_history = wider_model.fit(feature_train, label_train, epochs=epoch, batch_size=batch_size, validation_data=(feature_test, label_test))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0642 - val_loss: 0.0540\n",
            "Epoch 2/1000\n",
            "86/86 [==============================] - 0s 756us/step - loss: 0.0585 - val_loss: 0.0539\n",
            "Epoch 3/1000\n",
            "86/86 [==============================] - 0s 751us/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 4/1000\n",
            "86/86 [==============================] - 0s 766us/step - loss: 0.0583 - val_loss: 0.0538\n",
            "Epoch 5/1000\n",
            "86/86 [==============================] - 0s 816us/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 6/1000\n",
            "86/86 [==============================] - 0s 812us/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 7/1000\n",
            "86/86 [==============================] - 0s 751us/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 8/1000\n",
            "86/86 [==============================] - 0s 956us/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 9/1000\n",
            "86/86 [==============================] - 0s 790us/step - loss: 0.0581 - val_loss: 0.0537\n",
            "Epoch 10/1000\n",
            "86/86 [==============================] - 0s 744us/step - loss: 0.0582 - val_loss: 0.0537\n",
            "Epoch 11/1000\n",
            "86/86 [==============================] - 0s 796us/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 12/1000\n",
            "86/86 [==============================] - 0s 772us/step - loss: 0.0580 - val_loss: 0.0537\n",
            "Epoch 13/1000\n",
            "86/86 [==============================] - 0s 739us/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 14/1000\n",
            "86/86 [==============================] - 0s 787us/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 15/1000\n",
            "86/86 [==============================] - 0s 872us/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 16/1000\n",
            "86/86 [==============================] - 0s 790us/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 17/1000\n",
            "86/86 [==============================] - 0s 791us/step - loss: 0.0579 - val_loss: 0.0542\n",
            "Epoch 18/1000\n",
            "86/86 [==============================] - 0s 732us/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 19/1000\n",
            "86/86 [==============================] - 0s 738us/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 20/1000\n",
            "86/86 [==============================] - 0s 934us/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 21/1000\n",
            "86/86 [==============================] - 0s 737us/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 22/1000\n",
            "86/86 [==============================] - 0s 763us/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 23/1000\n",
            "86/86 [==============================] - 0s 841us/step - loss: 0.0580 - val_loss: 0.0537\n",
            "Epoch 24/1000\n",
            "86/86 [==============================] - 0s 801us/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 25/1000\n",
            "86/86 [==============================] - 0s 762us/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 26/1000\n",
            "86/86 [==============================] - 0s 786us/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 27/1000\n",
            "86/86 [==============================] - 0s 783us/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 28/1000\n",
            "86/86 [==============================] - 0s 841us/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 29/1000\n",
            "86/86 [==============================] - 0s 745us/step - loss: 0.0578 - val_loss: 0.0542\n",
            "Epoch 30/1000\n",
            "86/86 [==============================] - 0s 777us/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 31/1000\n",
            "86/86 [==============================] - 0s 826us/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 32/1000\n",
            "86/86 [==============================] - 0s 875us/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 33/1000\n",
            "86/86 [==============================] - 0s 771us/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 34/1000\n",
            "86/86 [==============================] - 0s 786us/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 35/1000\n",
            "86/86 [==============================] - 0s 812us/step - loss: 0.0580 - val_loss: 0.0544\n",
            "Epoch 36/1000\n",
            "86/86 [==============================] - 0s 779us/step - loss: 0.0579 - val_loss: 0.0543\n",
            "Epoch 37/1000\n",
            "86/86 [==============================] - 0s 872us/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 38/1000\n",
            "86/86 [==============================] - 0s 759us/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 39/1000\n",
            "86/86 [==============================] - 0s 743us/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 40/1000\n",
            "86/86 [==============================] - 0s 737us/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 41/1000\n",
            "86/86 [==============================] - 0s 882us/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 42/1000\n",
            "86/86 [==============================] - 0s 817us/step - loss: 0.0580 - val_loss: 0.0541\n",
            "Epoch 43/1000\n",
            "86/86 [==============================] - 0s 848us/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 44/1000\n",
            "86/86 [==============================] - 0s 884us/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 45/1000\n",
            "86/86 [==============================] - 0s 934us/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 46/1000\n",
            "86/86 [==============================] - 0s 744us/step - loss: 0.0581 - val_loss: 0.0542\n",
            "Epoch 47/1000\n",
            "86/86 [==============================] - 0s 790us/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 48/1000\n",
            "86/86 [==============================] - 0s 829us/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 49/1000\n",
            "86/86 [==============================] - 0s 886us/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 50/1000\n",
            "86/86 [==============================] - 0s 784us/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 51/1000\n",
            "86/86 [==============================] - 0s 890us/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 52/1000\n",
            "86/86 [==============================] - 0s 771us/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 53/1000\n",
            "86/86 [==============================] - 0s 774us/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 54/1000\n",
            "86/86 [==============================] - 0s 758us/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 55/1000\n",
            "86/86 [==============================] - 0s 773us/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 56/1000\n",
            "86/86 [==============================] - 0s 805us/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 57/1000\n",
            "86/86 [==============================] - 0s 785us/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 58/1000\n",
            "86/86 [==============================] - 0s 851us/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 59/1000\n",
            "86/86 [==============================] - 0s 818us/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 60/1000\n",
            "86/86 [==============================] - 0s 771us/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 61/1000\n",
            "86/86 [==============================] - 0s 798us/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 62/1000\n",
            "86/86 [==============================] - 0s 780us/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 63/1000\n",
            "86/86 [==============================] - 0s 741us/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 64/1000\n",
            "86/86 [==============================] - 0s 778us/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 65/1000\n",
            "86/86 [==============================] - 0s 963us/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 66/1000\n",
            "86/86 [==============================] - 0s 907us/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 67/1000\n",
            "86/86 [==============================] - 0s 769us/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 68/1000\n",
            "86/86 [==============================] - 0s 756us/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 69/1000\n",
            "86/86 [==============================] - 0s 796us/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 70/1000\n",
            "86/86 [==============================] - 0s 897us/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 71/1000\n",
            "86/86 [==============================] - 0s 815us/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 72/1000\n",
            "86/86 [==============================] - 0s 768us/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 73/1000\n",
            "86/86 [==============================] - 0s 767us/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 74/1000\n",
            "86/86 [==============================] - 0s 787us/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 75/1000\n",
            "86/86 [==============================] - 0s 806us/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 76/1000\n",
            "86/86 [==============================] - 0s 758us/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 77/1000\n",
            "86/86 [==============================] - 0s 830us/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 78/1000\n",
            "86/86 [==============================] - 0s 824us/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 79/1000\n",
            "86/86 [==============================] - 0s 759us/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 80/1000\n",
            "86/86 [==============================] - 0s 819us/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 81/1000\n",
            "86/86 [==============================] - 0s 830us/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 82/1000\n",
            "86/86 [==============================] - 0s 753us/step - loss: 0.0579 - val_loss: 0.0537\n",
            "Epoch 83/1000\n",
            "86/86 [==============================] - 0s 804us/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 84/1000\n",
            "86/86 [==============================] - 0s 747us/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 85/1000\n",
            "86/86 [==============================] - 0s 816us/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 86/1000\n",
            "86/86 [==============================] - 0s 747us/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 87/1000\n",
            "86/86 [==============================] - 0s 782us/step - loss: 0.0579 - val_loss: 0.0537\n",
            "Epoch 88/1000\n",
            "86/86 [==============================] - 0s 792us/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 89/1000\n",
            "86/86 [==============================] - 0s 899us/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 90/1000\n",
            "86/86 [==============================] - 0s 780us/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 91/1000\n",
            "86/86 [==============================] - 0s 750us/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 92/1000\n",
            "86/86 [==============================] - 0s 781us/step - loss: 0.0580 - val_loss: 0.0537\n",
            "Epoch 93/1000\n",
            "86/86 [==============================] - 0s 791us/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 94/1000\n",
            "86/86 [==============================] - 0s 749us/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 95/1000\n",
            "86/86 [==============================] - 0s 735us/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 96/1000\n",
            "86/86 [==============================] - 0s 790us/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 97/1000\n",
            "86/86 [==============================] - 0s 807us/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 98/1000\n",
            "86/86 [==============================] - 0s 750us/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 99/1000\n",
            "86/86 [==============================] - 0s 756us/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 100/1000\n",
            "86/86 [==============================] - 0s 812us/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 101/1000\n",
            "86/86 [==============================] - 0s 792us/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 102/1000\n",
            "86/86 [==============================] - 0s 748us/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 103/1000\n",
            "86/86 [==============================] - 0s 818us/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 104/1000\n",
            "86/86 [==============================] - 0s 775us/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 105/1000\n",
            "86/86 [==============================] - 0s 797us/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 106/1000\n",
            "86/86 [==============================] - 0s 789us/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 107/1000\n",
            "86/86 [==============================] - 0s 854us/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 108/1000\n",
            "86/86 [==============================] - 0s 789us/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 109/1000\n",
            "86/86 [==============================] - 0s 761us/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 110/1000\n",
            "86/86 [==============================] - 0s 870us/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 111/1000\n",
            "86/86 [==============================] - 0s 763us/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 112/1000\n",
            "86/86 [==============================] - 0s 809us/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 113/1000\n",
            "86/86 [==============================] - 0s 818us/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 114/1000\n",
            "86/86 [==============================] - 0s 792us/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 115/1000\n",
            "86/86 [==============================] - 0s 750us/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 116/1000\n",
            "86/86 [==============================] - 0s 770us/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 117/1000\n",
            "86/86 [==============================] - 0s 826us/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 118/1000\n",
            "86/86 [==============================] - 0s 765us/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 119/1000\n",
            "86/86 [==============================] - 0s 793us/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 120/1000\n",
            "86/86 [==============================] - 0s 784us/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 121/1000\n",
            "86/86 [==============================] - 0s 808us/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 122/1000\n",
            "86/86 [==============================] - 0s 755us/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 123/1000\n",
            "86/86 [==============================] - 0s 785us/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 124/1000\n",
            "86/86 [==============================] - 0s 813us/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 125/1000\n",
            "86/86 [==============================] - 0s 783us/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 126/1000\n",
            "86/86 [==============================] - 0s 812us/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 127/1000\n",
            "86/86 [==============================] - 0s 795us/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 128/1000\n",
            "86/86 [==============================] - 0s 933us/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 129/1000\n",
            "86/86 [==============================] - 0s 781us/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 130/1000\n",
            "86/86 [==============================] - 0s 801us/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 131/1000\n",
            "86/86 [==============================] - 0s 825us/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 132/1000\n",
            "86/86 [==============================] - 0s 769us/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 133/1000\n",
            "86/86 [==============================] - 0s 813us/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 134/1000\n",
            "86/86 [==============================] - 0s 863us/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 135/1000\n",
            "86/86 [==============================] - 0s 777us/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 136/1000\n",
            "86/86 [==============================] - 0s 751us/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 137/1000\n",
            "86/86 [==============================] - 0s 746us/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 138/1000\n",
            "86/86 [==============================] - 0s 718us/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 139/1000\n",
            "86/86 [==============================] - 0s 810us/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 140/1000\n",
            "86/86 [==============================] - 0s 769us/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 141/1000\n",
            "86/86 [==============================] - 0s 778us/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 142/1000\n",
            "86/86 [==============================] - 0s 769us/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 143/1000\n",
            "86/86 [==============================] - 0s 761us/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 144/1000\n",
            "86/86 [==============================] - 0s 813us/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 145/1000\n",
            "86/86 [==============================] - 0s 809us/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 146/1000\n",
            "86/86 [==============================] - 0s 812us/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 147/1000\n",
            "86/86 [==============================] - 0s 752us/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 148/1000\n",
            "86/86 [==============================] - 0s 866us/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 149/1000\n",
            "86/86 [==============================] - 0s 940us/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 150/1000\n",
            "86/86 [==============================] - 0s 784us/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 151/1000\n",
            "86/86 [==============================] - 0s 772us/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 152/1000\n",
            "86/86 [==============================] - 0s 778us/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 153/1000\n",
            "86/86 [==============================] - 0s 824us/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 154/1000\n",
            "86/86 [==============================] - 0s 791us/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 155/1000\n",
            "86/86 [==============================] - 0s 729us/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 156/1000\n",
            "86/86 [==============================] - 0s 798us/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 157/1000\n",
            "86/86 [==============================] - 0s 764us/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 158/1000\n",
            "86/86 [==============================] - 0s 771us/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 159/1000\n",
            "86/86 [==============================] - 0s 798us/step - loss: 0.0578 - val_loss: 0.0543\n",
            "Epoch 160/1000\n",
            "86/86 [==============================] - 0s 837us/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 161/1000\n",
            "86/86 [==============================] - 0s 831us/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 162/1000\n",
            "86/86 [==============================] - 0s 811us/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 163/1000\n",
            "86/86 [==============================] - 0s 807us/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 164/1000\n",
            "86/86 [==============================] - 0s 769us/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 165/1000\n",
            "86/86 [==============================] - 0s 765us/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 166/1000\n",
            "86/86 [==============================] - 0s 770us/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 167/1000\n",
            "86/86 [==============================] - 0s 800us/step - loss: 0.0577 - val_loss: 0.0543\n",
            "Epoch 168/1000\n",
            "86/86 [==============================] - 0s 817us/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 169/1000\n",
            "86/86 [==============================] - 0s 785us/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 170/1000\n",
            "86/86 [==============================] - 0s 809us/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 171/1000\n",
            "86/86 [==============================] - 0s 831us/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 172/1000\n",
            "86/86 [==============================] - 0s 810us/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 173/1000\n",
            "86/86 [==============================] - 0s 780us/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 174/1000\n",
            "86/86 [==============================] - 0s 756us/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 175/1000\n",
            "86/86 [==============================] - 0s 871us/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 176/1000\n",
            "86/86 [==============================] - 0s 811us/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 177/1000\n",
            "86/86 [==============================] - 0s 794us/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 178/1000\n",
            "86/86 [==============================] - 0s 778us/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 179/1000\n",
            "86/86 [==============================] - 0s 776us/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 180/1000\n",
            "86/86 [==============================] - 0s 752us/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 181/1000\n",
            "86/86 [==============================] - 0s 788us/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 182/1000\n",
            "86/86 [==============================] - 0s 826us/step - loss: 0.0578 - val_loss: 0.0542\n",
            "Epoch 183/1000\n",
            "86/86 [==============================] - 0s 773us/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 184/1000\n",
            "86/86 [==============================] - 0s 754us/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 185/1000\n",
            "86/86 [==============================] - 0s 773us/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 186/1000\n",
            "86/86 [==============================] - 0s 751us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 187/1000\n",
            "86/86 [==============================] - 0s 786us/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 188/1000\n",
            "86/86 [==============================] - 0s 821us/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 189/1000\n",
            "86/86 [==============================] - 0s 769us/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 190/1000\n",
            "86/86 [==============================] - 0s 758us/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 191/1000\n",
            "86/86 [==============================] - 0s 875us/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 192/1000\n",
            "86/86 [==============================] - 0s 833us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 193/1000\n",
            "86/86 [==============================] - 0s 803us/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 194/1000\n",
            "86/86 [==============================] - 0s 784us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 195/1000\n",
            "86/86 [==============================] - 0s 798us/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 196/1000\n",
            "86/86 [==============================] - 0s 771us/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 197/1000\n",
            "86/86 [==============================] - 0s 780us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 198/1000\n",
            "86/86 [==============================] - 0s 774us/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 199/1000\n",
            "86/86 [==============================] - 0s 777us/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 200/1000\n",
            "86/86 [==============================] - 0s 771us/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 201/1000\n",
            "86/86 [==============================] - 0s 742us/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 202/1000\n",
            "86/86 [==============================] - 0s 785us/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 203/1000\n",
            "86/86 [==============================] - 0s 840us/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 204/1000\n",
            "86/86 [==============================] - 0s 803us/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 205/1000\n",
            "86/86 [==============================] - 0s 821us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 206/1000\n",
            "86/86 [==============================] - 0s 755us/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 207/1000\n",
            "86/86 [==============================] - 0s 835us/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 208/1000\n",
            "86/86 [==============================] - 0s 784us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 209/1000\n",
            "86/86 [==============================] - 0s 787us/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 210/1000\n",
            "86/86 [==============================] - 0s 873us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 211/1000\n",
            "86/86 [==============================] - 0s 762us/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 212/1000\n",
            "86/86 [==============================] - 0s 780us/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 213/1000\n",
            "86/86 [==============================] - 0s 870us/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 214/1000\n",
            "86/86 [==============================] - 0s 766us/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 215/1000\n",
            "86/86 [==============================] - 0s 790us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 216/1000\n",
            "86/86 [==============================] - 0s 782us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 217/1000\n",
            "86/86 [==============================] - 0s 797us/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 218/1000\n",
            "86/86 [==============================] - 0s 756us/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 219/1000\n",
            "86/86 [==============================] - 0s 835us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 220/1000\n",
            "86/86 [==============================] - 0s 766us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 221/1000\n",
            "86/86 [==============================] - 0s 799us/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 222/1000\n",
            "86/86 [==============================] - 0s 808us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 223/1000\n",
            "86/86 [==============================] - 0s 802us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 224/1000\n",
            "86/86 [==============================] - 0s 804us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 225/1000\n",
            "86/86 [==============================] - 0s 768us/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 226/1000\n",
            "86/86 [==============================] - 0s 926us/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 227/1000\n",
            "86/86 [==============================] - 0s 754us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 228/1000\n",
            "86/86 [==============================] - 0s 760us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 229/1000\n",
            "86/86 [==============================] - 0s 810us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 230/1000\n",
            "86/86 [==============================] - 0s 806us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 231/1000\n",
            "86/86 [==============================] - 0s 812us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 232/1000\n",
            "86/86 [==============================] - 0s 777us/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 233/1000\n",
            "86/86 [==============================] - 0s 975us/step - loss: 0.0577 - val_loss: 0.0543\n",
            "Epoch 234/1000\n",
            "86/86 [==============================] - 0s 759us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 235/1000\n",
            "86/86 [==============================] - 0s 742us/step - loss: 0.0579 - val_loss: 0.0544\n",
            "Epoch 236/1000\n",
            "86/86 [==============================] - 0s 776us/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 237/1000\n",
            "86/86 [==============================] - 0s 902us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 238/1000\n",
            "86/86 [==============================] - 0s 818us/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 239/1000\n",
            "86/86 [==============================] - 0s 768us/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 240/1000\n",
            "86/86 [==============================] - 0s 776us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 241/1000\n",
            "86/86 [==============================] - 0s 811us/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 242/1000\n",
            "86/86 [==============================] - 0s 789us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 243/1000\n",
            "86/86 [==============================] - 0s 761us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 244/1000\n",
            "86/86 [==============================] - 0s 777us/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 245/1000\n",
            "86/86 [==============================] - 0s 768us/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 246/1000\n",
            "86/86 [==============================] - 0s 742us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 247/1000\n",
            "86/86 [==============================] - 0s 873us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 248/1000\n",
            "86/86 [==============================] - 0s 779us/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 249/1000\n",
            "86/86 [==============================] - 0s 744us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 250/1000\n",
            "86/86 [==============================] - 0s 832us/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 251/1000\n",
            "86/86 [==============================] - 0s 899us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 252/1000\n",
            "86/86 [==============================] - 0s 794us/step - loss: 0.0576 - val_loss: 0.0537\n",
            "Epoch 253/1000\n",
            "86/86 [==============================] - 0s 772us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 254/1000\n",
            "86/86 [==============================] - 0s 768us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 255/1000\n",
            "86/86 [==============================] - 0s 824us/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 256/1000\n",
            "86/86 [==============================] - 0s 775us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 257/1000\n",
            "86/86 [==============================] - 0s 797us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 258/1000\n",
            "86/86 [==============================] - 0s 801us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 259/1000\n",
            "86/86 [==============================] - 0s 774us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 260/1000\n",
            "86/86 [==============================] - 0s 851us/step - loss: 0.0575 - val_loss: 0.0544\n",
            "Epoch 261/1000\n",
            "86/86 [==============================] - 0s 831us/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 262/1000\n",
            "86/86 [==============================] - 0s 787us/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 263/1000\n",
            "86/86 [==============================] - 0s 781us/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 264/1000\n",
            "86/86 [==============================] - 0s 944us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 265/1000\n",
            "86/86 [==============================] - 0s 816us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 266/1000\n",
            "86/86 [==============================] - 0s 743us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 267/1000\n",
            "86/86 [==============================] - 0s 776us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 268/1000\n",
            "86/86 [==============================] - 0s 840us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 269/1000\n",
            "86/86 [==============================] - 0s 852us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 270/1000\n",
            "86/86 [==============================] - 0s 828us/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 271/1000\n",
            "86/86 [==============================] - 0s 877us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 272/1000\n",
            "86/86 [==============================] - 0s 799us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 273/1000\n",
            "86/86 [==============================] - 0s 779us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 274/1000\n",
            "86/86 [==============================] - 0s 882us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 275/1000\n",
            "86/86 [==============================] - 0s 819us/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 276/1000\n",
            "86/86 [==============================] - 0s 815us/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 277/1000\n",
            "86/86 [==============================] - 0s 746us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 278/1000\n",
            "86/86 [==============================] - 0s 777us/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 279/1000\n",
            "86/86 [==============================] - 0s 793us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 280/1000\n",
            "86/86 [==============================] - 0s 765us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 281/1000\n",
            "86/86 [==============================] - 0s 732us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 282/1000\n",
            "86/86 [==============================] - 0s 754us/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 283/1000\n",
            "86/86 [==============================] - 0s 842us/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 284/1000\n",
            "86/86 [==============================] - 0s 797us/step - loss: 0.0575 - val_loss: 0.0538\n",
            "Epoch 285/1000\n",
            "86/86 [==============================] - 0s 769us/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 286/1000\n",
            "86/86 [==============================] - 0s 767us/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 287/1000\n",
            "86/86 [==============================] - 0s 879us/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 288/1000\n",
            "86/86 [==============================] - 0s 893us/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 289/1000\n",
            "86/86 [==============================] - 0s 752us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 290/1000\n",
            "86/86 [==============================] - 0s 770us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 291/1000\n",
            "86/86 [==============================] - 0s 943us/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 292/1000\n",
            "86/86 [==============================] - 0s 785us/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 293/1000\n",
            "86/86 [==============================] - 0s 773us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 294/1000\n",
            "86/86 [==============================] - 0s 777us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 295/1000\n",
            "86/86 [==============================] - 0s 878us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 296/1000\n",
            "86/86 [==============================] - 0s 747us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 297/1000\n",
            "86/86 [==============================] - 0s 760us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 298/1000\n",
            "86/86 [==============================] - 0s 823us/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 299/1000\n",
            "86/86 [==============================] - 0s 881us/step - loss: 0.0576 - val_loss: 0.0538\n",
            "Epoch 300/1000\n",
            "86/86 [==============================] - 0s 798us/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 301/1000\n",
            "86/86 [==============================] - 0s 791us/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 302/1000\n",
            "86/86 [==============================] - 0s 878us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 303/1000\n",
            "86/86 [==============================] - 0s 859us/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 304/1000\n",
            "86/86 [==============================] - 0s 781us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 305/1000\n",
            "86/86 [==============================] - 0s 790us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 306/1000\n",
            "86/86 [==============================] - 0s 788us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 307/1000\n",
            "86/86 [==============================] - 0s 828us/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 308/1000\n",
            "86/86 [==============================] - 0s 760us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 309/1000\n",
            "86/86 [==============================] - 0s 776us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 310/1000\n",
            "86/86 [==============================] - 0s 791us/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 311/1000\n",
            "86/86 [==============================] - 0s 823us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 312/1000\n",
            "86/86 [==============================] - 0s 788us/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 313/1000\n",
            "86/86 [==============================] - 0s 752us/step - loss: 0.0576 - val_loss: 0.0544\n",
            "Epoch 314/1000\n",
            "86/86 [==============================] - 0s 770us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 315/1000\n",
            "86/86 [==============================] - 0s 808us/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 316/1000\n",
            "86/86 [==============================] - 0s 845us/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 317/1000\n",
            "86/86 [==============================] - 0s 748us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 318/1000\n",
            "86/86 [==============================] - 0s 741us/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 319/1000\n",
            "86/86 [==============================] - 0s 746us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 320/1000\n",
            "86/86 [==============================] - 0s 804us/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 321/1000\n",
            "86/86 [==============================] - 0s 805us/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 322/1000\n",
            "86/86 [==============================] - 0s 788us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 323/1000\n",
            "86/86 [==============================] - 0s 757us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 324/1000\n",
            "86/86 [==============================] - 0s 841us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 325/1000\n",
            "86/86 [==============================] - 0s 803us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 326/1000\n",
            "86/86 [==============================] - 0s 782us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 327/1000\n",
            "86/86 [==============================] - 0s 757us/step - loss: 0.0575 - val_loss: 0.0544\n",
            "Epoch 328/1000\n",
            "86/86 [==============================] - 0s 833us/step - loss: 0.0576 - val_loss: 0.0544\n",
            "Epoch 329/1000\n",
            "86/86 [==============================] - 0s 749us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 330/1000\n",
            "86/86 [==============================] - 0s 837us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 331/1000\n",
            "86/86 [==============================] - 0s 781us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 332/1000\n",
            "86/86 [==============================] - 0s 769us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 333/1000\n",
            "86/86 [==============================] - 0s 781us/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 334/1000\n",
            "86/86 [==============================] - 0s 780us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 335/1000\n",
            "86/86 [==============================] - 0s 783us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 336/1000\n",
            "86/86 [==============================] - 0s 815us/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 337/1000\n",
            "86/86 [==============================] - 0s 766us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 338/1000\n",
            "86/86 [==============================] - 0s 760us/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 339/1000\n",
            "86/86 [==============================] - 0s 761us/step - loss: 0.0576 - val_loss: 0.0544\n",
            "Epoch 340/1000\n",
            "86/86 [==============================] - 0s 790us/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 341/1000\n",
            "86/86 [==============================] - 0s 760us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 342/1000\n",
            "86/86 [==============================] - 0s 788us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 343/1000\n",
            "86/86 [==============================] - 0s 811us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 344/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 345/1000\n",
            "86/86 [==============================] - 0s 827us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 346/1000\n",
            "86/86 [==============================] - 0s 829us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 347/1000\n",
            "86/86 [==============================] - 0s 788us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 348/1000\n",
            "86/86 [==============================] - 0s 751us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 349/1000\n",
            "86/86 [==============================] - 0s 782us/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 350/1000\n",
            "86/86 [==============================] - 0s 787us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 351/1000\n",
            "86/86 [==============================] - 0s 783us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 352/1000\n",
            "86/86 [==============================] - 0s 853us/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 353/1000\n",
            "86/86 [==============================] - 0s 806us/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 354/1000\n",
            "86/86 [==============================] - 0s 844us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 355/1000\n",
            "86/86 [==============================] - 0s 738us/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 356/1000\n",
            "86/86 [==============================] - 0s 749us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 357/1000\n",
            "86/86 [==============================] - 0s 725us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 358/1000\n",
            "86/86 [==============================] - 0s 878us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 359/1000\n",
            "86/86 [==============================] - 0s 836us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 360/1000\n",
            "86/86 [==============================] - 0s 781us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 361/1000\n",
            "86/86 [==============================] - 0s 800us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 362/1000\n",
            "86/86 [==============================] - 0s 803us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 363/1000\n",
            "86/86 [==============================] - 0s 799us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 364/1000\n",
            "86/86 [==============================] - 0s 785us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 365/1000\n",
            "86/86 [==============================] - 0s 876us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 366/1000\n",
            "86/86 [==============================] - 0s 815us/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 367/1000\n",
            "86/86 [==============================] - 0s 771us/step - loss: 0.0576 - val_loss: 0.0538\n",
            "Epoch 368/1000\n",
            "86/86 [==============================] - 0s 787us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 369/1000\n",
            "86/86 [==============================] - 0s 754us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 370/1000\n",
            "86/86 [==============================] - 0s 775us/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 371/1000\n",
            "86/86 [==============================] - 0s 763us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 372/1000\n",
            "86/86 [==============================] - 0s 805us/step - loss: 0.0577 - val_loss: 0.0543\n",
            "Epoch 373/1000\n",
            "86/86 [==============================] - 0s 762us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 374/1000\n",
            "86/86 [==============================] - 0s 994us/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 375/1000\n",
            "86/86 [==============================] - 0s 796us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 376/1000\n",
            "86/86 [==============================] - 0s 766us/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 377/1000\n",
            "86/86 [==============================] - 0s 805us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 378/1000\n",
            "86/86 [==============================] - 0s 822us/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 379/1000\n",
            "86/86 [==============================] - 0s 832us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 380/1000\n",
            "86/86 [==============================] - 0s 794us/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 381/1000\n",
            "86/86 [==============================] - 0s 768us/step - loss: 0.0575 - val_loss: 0.0538\n",
            "Epoch 382/1000\n",
            "86/86 [==============================] - 0s 809us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 383/1000\n",
            "86/86 [==============================] - 0s 851us/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 384/1000\n",
            "86/86 [==============================] - 0s 770us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 385/1000\n",
            "86/86 [==============================] - 0s 836us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 386/1000\n",
            "86/86 [==============================] - 0s 776us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 387/1000\n",
            "86/86 [==============================] - 0s 829us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 388/1000\n",
            "86/86 [==============================] - 0s 753us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 389/1000\n",
            "86/86 [==============================] - 0s 757us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 390/1000\n",
            "86/86 [==============================] - 0s 755us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 391/1000\n",
            "86/86 [==============================] - 0s 754us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 392/1000\n",
            "86/86 [==============================] - 0s 748us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 393/1000\n",
            "86/86 [==============================] - 0s 795us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 394/1000\n",
            "86/86 [==============================] - 0s 807us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 395/1000\n",
            "86/86 [==============================] - 0s 810us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 396/1000\n",
            "86/86 [==============================] - 0s 813us/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 397/1000\n",
            "86/86 [==============================] - 0s 827us/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 398/1000\n",
            "86/86 [==============================] - 0s 944us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 399/1000\n",
            "86/86 [==============================] - 0s 857us/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 400/1000\n",
            "86/86 [==============================] - 0s 788us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 401/1000\n",
            "86/86 [==============================] - 0s 829us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 402/1000\n",
            "86/86 [==============================] - 0s 779us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 403/1000\n",
            "86/86 [==============================] - 0s 815us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 404/1000\n",
            "86/86 [==============================] - 0s 762us/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 405/1000\n",
            "86/86 [==============================] - 0s 837us/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 406/1000\n",
            "86/86 [==============================] - 0s 773us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 407/1000\n",
            "86/86 [==============================] - 0s 800us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 408/1000\n",
            "86/86 [==============================] - 0s 787us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 409/1000\n",
            "86/86 [==============================] - 0s 830us/step - loss: 0.0575 - val_loss: 0.0544\n",
            "Epoch 410/1000\n",
            "86/86 [==============================] - 0s 801us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 411/1000\n",
            "86/86 [==============================] - 0s 790us/step - loss: 0.0576 - val_loss: 0.0538\n",
            "Epoch 412/1000\n",
            "86/86 [==============================] - 0s 887us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 413/1000\n",
            "86/86 [==============================] - 0s 882us/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 414/1000\n",
            "86/86 [==============================] - 0s 748us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 415/1000\n",
            "86/86 [==============================] - 0s 794us/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 416/1000\n",
            "86/86 [==============================] - 0s 751us/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 417/1000\n",
            "86/86 [==============================] - 0s 762us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 418/1000\n",
            "86/86 [==============================] - 0s 753us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 419/1000\n",
            "86/86 [==============================] - 0s 760us/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 420/1000\n",
            "86/86 [==============================] - 0s 766us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 421/1000\n",
            "86/86 [==============================] - 0s 799us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 422/1000\n",
            "86/86 [==============================] - 0s 857us/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 423/1000\n",
            "86/86 [==============================] - 0s 783us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 424/1000\n",
            "86/86 [==============================] - 0s 785us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 425/1000\n",
            "86/86 [==============================] - 0s 767us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 426/1000\n",
            "86/86 [==============================] - 0s 749us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 427/1000\n",
            "86/86 [==============================] - 0s 816us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 428/1000\n",
            "86/86 [==============================] - 0s 847us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 429/1000\n",
            "86/86 [==============================] - 0s 796us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 430/1000\n",
            "86/86 [==============================] - 0s 825us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 431/1000\n",
            "86/86 [==============================] - 0s 800us/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 432/1000\n",
            "86/86 [==============================] - 0s 805us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 433/1000\n",
            "86/86 [==============================] - 0s 780us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 434/1000\n",
            "86/86 [==============================] - 0s 757us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 435/1000\n",
            "86/86 [==============================] - 0s 845us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 436/1000\n",
            "86/86 [==============================] - 0s 829us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 437/1000\n",
            "86/86 [==============================] - 0s 771us/step - loss: 0.0575 - val_loss: 0.0538\n",
            "Epoch 438/1000\n",
            "86/86 [==============================] - 0s 746us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 439/1000\n",
            "86/86 [==============================] - 0s 750us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 440/1000\n",
            "86/86 [==============================] - 0s 749us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 441/1000\n",
            "86/86 [==============================] - 0s 824us/step - loss: 0.0576 - val_loss: 0.0546\n",
            "Epoch 442/1000\n",
            "86/86 [==============================] - 0s 779us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 443/1000\n",
            "86/86 [==============================] - 0s 777us/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 444/1000\n",
            "86/86 [==============================] - 0s 813us/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 445/1000\n",
            "86/86 [==============================] - 0s 783us/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 446/1000\n",
            "86/86 [==============================] - 0s 843us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 447/1000\n",
            "86/86 [==============================] - 0s 814us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 448/1000\n",
            "86/86 [==============================] - 0s 811us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 449/1000\n",
            "86/86 [==============================] - 0s 789us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 450/1000\n",
            "86/86 [==============================] - 0s 759us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 451/1000\n",
            "86/86 [==============================] - 0s 810us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 452/1000\n",
            "86/86 [==============================] - 0s 780us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 453/1000\n",
            "86/86 [==============================] - 0s 830us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 454/1000\n",
            "86/86 [==============================] - 0s 804us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 455/1000\n",
            "86/86 [==============================] - 0s 854us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 456/1000\n",
            "86/86 [==============================] - 0s 774us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 457/1000\n",
            "86/86 [==============================] - 0s 821us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 458/1000\n",
            "86/86 [==============================] - 0s 764us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 459/1000\n",
            "86/86 [==============================] - 0s 749us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 460/1000\n",
            "86/86 [==============================] - 0s 772us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 461/1000\n",
            "86/86 [==============================] - 0s 769us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 462/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 463/1000\n",
            "86/86 [==============================] - 0s 830us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 464/1000\n",
            "86/86 [==============================] - 0s 771us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 465/1000\n",
            "86/86 [==============================] - 0s 791us/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 466/1000\n",
            "86/86 [==============================] - 0s 780us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 467/1000\n",
            "86/86 [==============================] - 0s 765us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 468/1000\n",
            "86/86 [==============================] - 0s 776us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 469/1000\n",
            "86/86 [==============================] - 0s 912us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 470/1000\n",
            "86/86 [==============================] - 0s 792us/step - loss: 0.0575 - val_loss: 0.0544\n",
            "Epoch 471/1000\n",
            "86/86 [==============================] - 0s 791us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 472/1000\n",
            "86/86 [==============================] - 0s 794us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 473/1000\n",
            "86/86 [==============================] - 0s 813us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 474/1000\n",
            "86/86 [==============================] - 0s 762us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 475/1000\n",
            "86/86 [==============================] - 0s 762us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 476/1000\n",
            "86/86 [==============================] - 0s 862us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 477/1000\n",
            "86/86 [==============================] - 0s 800us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 478/1000\n",
            "86/86 [==============================] - 0s 810us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 479/1000\n",
            "86/86 [==============================] - 0s 784us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 480/1000\n",
            "86/86 [==============================] - 0s 958us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 481/1000\n",
            "86/86 [==============================] - 0s 779us/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 482/1000\n",
            "86/86 [==============================] - 0s 791us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 483/1000\n",
            "86/86 [==============================] - 0s 896us/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 484/1000\n",
            "86/86 [==============================] - 0s 771us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 485/1000\n",
            "86/86 [==============================] - 0s 761us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 486/1000\n",
            "86/86 [==============================] - 0s 791us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 487/1000\n",
            "86/86 [==============================] - 0s 813us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 488/1000\n",
            "86/86 [==============================] - 0s 760us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 489/1000\n",
            "86/86 [==============================] - 0s 765us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 490/1000\n",
            "86/86 [==============================] - 0s 801us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 491/1000\n",
            "86/86 [==============================] - 0s 796us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 492/1000\n",
            "86/86 [==============================] - 0s 777us/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 493/1000\n",
            "86/86 [==============================] - 0s 729us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 494/1000\n",
            "86/86 [==============================] - 0s 786us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 495/1000\n",
            "86/86 [==============================] - 0s 789us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 496/1000\n",
            "86/86 [==============================] - 0s 850us/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 497/1000\n",
            "86/86 [==============================] - 0s 835us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 498/1000\n",
            "86/86 [==============================] - 0s 783us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 499/1000\n",
            "86/86 [==============================] - 0s 822us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 500/1000\n",
            "86/86 [==============================] - 0s 770us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 501/1000\n",
            "86/86 [==============================] - 0s 810us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 502/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 503/1000\n",
            "86/86 [==============================] - 0s 799us/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 504/1000\n",
            "86/86 [==============================] - 0s 823us/step - loss: 0.0575 - val_loss: 0.0544\n",
            "Epoch 505/1000\n",
            "86/86 [==============================] - 0s 761us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 506/1000\n",
            "86/86 [==============================] - 0s 824us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 507/1000\n",
            "86/86 [==============================] - 0s 775us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 508/1000\n",
            "86/86 [==============================] - 0s 813us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 509/1000\n",
            "86/86 [==============================] - 0s 917us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 510/1000\n",
            "86/86 [==============================] - 0s 822us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 511/1000\n",
            "86/86 [==============================] - 0s 814us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 512/1000\n",
            "86/86 [==============================] - 0s 771us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 513/1000\n",
            "86/86 [==============================] - 0s 763us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 514/1000\n",
            "86/86 [==============================] - 0s 737us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 515/1000\n",
            "86/86 [==============================] - 0s 751us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 516/1000\n",
            "86/86 [==============================] - 0s 787us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 517/1000\n",
            "86/86 [==============================] - 0s 869us/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 518/1000\n",
            "86/86 [==============================] - 0s 799us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 519/1000\n",
            "86/86 [==============================] - 0s 775us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 520/1000\n",
            "86/86 [==============================] - 0s 767us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 521/1000\n",
            "86/86 [==============================] - 0s 732us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 522/1000\n",
            "86/86 [==============================] - 0s 778us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 523/1000\n",
            "86/86 [==============================] - 0s 758us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 524/1000\n",
            "86/86 [==============================] - 0s 831us/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 525/1000\n",
            "86/86 [==============================] - 0s 866us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 526/1000\n",
            "86/86 [==============================] - 0s 798us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 527/1000\n",
            "86/86 [==============================] - 0s 766us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 528/1000\n",
            "86/86 [==============================] - 0s 739us/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 529/1000\n",
            "86/86 [==============================] - 0s 833us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 530/1000\n",
            "86/86 [==============================] - 0s 777us/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 531/1000\n",
            "86/86 [==============================] - 0s 781us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 532/1000\n",
            "86/86 [==============================] - 0s 759us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 533/1000\n",
            "86/86 [==============================] - 0s 810us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 534/1000\n",
            "86/86 [==============================] - 0s 793us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 535/1000\n",
            "86/86 [==============================] - 0s 750us/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 536/1000\n",
            "86/86 [==============================] - 0s 830us/step - loss: 0.0575 - val_loss: 0.0546\n",
            "Epoch 537/1000\n",
            "86/86 [==============================] - 0s 802us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 538/1000\n",
            "86/86 [==============================] - 0s 813us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 539/1000\n",
            "86/86 [==============================] - 0s 831us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 540/1000\n",
            "86/86 [==============================] - 0s 805us/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 541/1000\n",
            "86/86 [==============================] - 0s 827us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 542/1000\n",
            "86/86 [==============================] - 0s 787us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 543/1000\n",
            "86/86 [==============================] - 0s 716us/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 544/1000\n",
            "86/86 [==============================] - 0s 806us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 545/1000\n",
            "86/86 [==============================] - 0s 799us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 546/1000\n",
            "86/86 [==============================] - 0s 991us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 547/1000\n",
            "86/86 [==============================] - 0s 781us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 548/1000\n",
            "86/86 [==============================] - 0s 779us/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 549/1000\n",
            "86/86 [==============================] - 0s 879us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 550/1000\n",
            "86/86 [==============================] - 0s 798us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 551/1000\n",
            "86/86 [==============================] - 0s 781us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 552/1000\n",
            "86/86 [==============================] - 0s 783us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 553/1000\n",
            "86/86 [==============================] - 0s 893us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 554/1000\n",
            "86/86 [==============================] - 0s 881us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 555/1000\n",
            "86/86 [==============================] - 0s 770us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 556/1000\n",
            "86/86 [==============================] - 0s 745us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 557/1000\n",
            "86/86 [==============================] - 0s 769us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 558/1000\n",
            "86/86 [==============================] - 0s 746us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 559/1000\n",
            "86/86 [==============================] - 0s 776us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 560/1000\n",
            "86/86 [==============================] - 0s 754us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 561/1000\n",
            "86/86 [==============================] - 0s 797us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 562/1000\n",
            "86/86 [==============================] - 0s 763us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 563/1000\n",
            "86/86 [==============================] - 0s 795us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 564/1000\n",
            "86/86 [==============================] - 0s 787us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 565/1000\n",
            "86/86 [==============================] - 0s 758us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 566/1000\n",
            "86/86 [==============================] - 0s 744us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 567/1000\n",
            "86/86 [==============================] - 0s 988us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 568/1000\n",
            "86/86 [==============================] - 0s 805us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 569/1000\n",
            "86/86 [==============================] - 0s 815us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 570/1000\n",
            "86/86 [==============================] - 0s 802us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 571/1000\n",
            "86/86 [==============================] - 0s 794us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 572/1000\n",
            "86/86 [==============================] - 0s 758us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 573/1000\n",
            "86/86 [==============================] - 0s 788us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 574/1000\n",
            "86/86 [==============================] - 0s 776us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 575/1000\n",
            "86/86 [==============================] - 0s 782us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 576/1000\n",
            "86/86 [==============================] - 0s 805us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 577/1000\n",
            "86/86 [==============================] - 0s 781us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 578/1000\n",
            "86/86 [==============================] - 0s 740us/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 579/1000\n",
            "86/86 [==============================] - 0s 881us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 580/1000\n",
            "86/86 [==============================] - 0s 780us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 581/1000\n",
            "86/86 [==============================] - 0s 916us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 582/1000\n",
            "86/86 [==============================] - 0s 819us/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 583/1000\n",
            "86/86 [==============================] - 0s 794us/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 584/1000\n",
            "86/86 [==============================] - 0s 724us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 585/1000\n",
            "86/86 [==============================] - 0s 740us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 586/1000\n",
            "86/86 [==============================] - 0s 744us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 587/1000\n",
            "86/86 [==============================] - 0s 799us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 588/1000\n",
            "86/86 [==============================] - 0s 833us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 589/1000\n",
            "86/86 [==============================] - 0s 885us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 590/1000\n",
            "86/86 [==============================] - 0s 769us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 591/1000\n",
            "86/86 [==============================] - 0s 830us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 592/1000\n",
            "86/86 [==============================] - 0s 759us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 593/1000\n",
            "86/86 [==============================] - 0s 756us/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 594/1000\n",
            "86/86 [==============================] - 0s 807us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 595/1000\n",
            "86/86 [==============================] - 0s 925us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 596/1000\n",
            "86/86 [==============================] - 0s 762us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 597/1000\n",
            "86/86 [==============================] - 0s 769us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 598/1000\n",
            "86/86 [==============================] - 0s 844us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 599/1000\n",
            "86/86 [==============================] - 0s 762us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 600/1000\n",
            "86/86 [==============================] - 0s 772us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 601/1000\n",
            "86/86 [==============================] - 0s 759us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 602/1000\n",
            "86/86 [==============================] - 0s 802us/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 603/1000\n",
            "86/86 [==============================] - 0s 806us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 604/1000\n",
            "86/86 [==============================] - 0s 822us/step - loss: 0.0575 - val_loss: 0.0544\n",
            "Epoch 605/1000\n",
            "86/86 [==============================] - 0s 884us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 606/1000\n",
            "86/86 [==============================] - 0s 769us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 607/1000\n",
            "86/86 [==============================] - 0s 786us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 608/1000\n",
            "86/86 [==============================] - 0s 758us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 609/1000\n",
            "86/86 [==============================] - 0s 866us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 610/1000\n",
            "86/86 [==============================] - 0s 753us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 611/1000\n",
            "86/86 [==============================] - 0s 739us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 612/1000\n",
            "86/86 [==============================] - 0s 743us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 613/1000\n",
            "86/86 [==============================] - 0s 796us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 614/1000\n",
            "86/86 [==============================] - 0s 892us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 615/1000\n",
            "86/86 [==============================] - 0s 778us/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 616/1000\n",
            "86/86 [==============================] - 0s 775us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 617/1000\n",
            "86/86 [==============================] - 0s 753us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 618/1000\n",
            "86/86 [==============================] - 0s 820us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 619/1000\n",
            "86/86 [==============================] - 0s 793us/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 620/1000\n",
            "86/86 [==============================] - 0s 770us/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 621/1000\n",
            "86/86 [==============================] - 0s 741us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 622/1000\n",
            "86/86 [==============================] - 0s 786us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 623/1000\n",
            "86/86 [==============================] - 0s 902us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 624/1000\n",
            "86/86 [==============================] - 0s 784us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 625/1000\n",
            "86/86 [==============================] - 0s 776us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 626/1000\n",
            "86/86 [==============================] - 0s 747us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 627/1000\n",
            "86/86 [==============================] - 0s 780us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 628/1000\n",
            "86/86 [==============================] - 0s 844us/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 629/1000\n",
            "86/86 [==============================] - 0s 795us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 630/1000\n",
            "86/86 [==============================] - 0s 773us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 631/1000\n",
            "86/86 [==============================] - 0s 775us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 632/1000\n",
            "86/86 [==============================] - 0s 977us/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 633/1000\n",
            "86/86 [==============================] - 0s 776us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 634/1000\n",
            "86/86 [==============================] - 0s 764us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 635/1000\n",
            "86/86 [==============================] - 0s 787us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 636/1000\n",
            "86/86 [==============================] - 0s 810us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 637/1000\n",
            "86/86 [==============================] - 0s 907us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 638/1000\n",
            "86/86 [==============================] - 0s 745us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 639/1000\n",
            "86/86 [==============================] - 0s 801us/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 640/1000\n",
            "86/86 [==============================] - 0s 727us/step - loss: 0.0573 - val_loss: 0.0542\n",
            "Epoch 641/1000\n",
            "86/86 [==============================] - 0s 806us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 642/1000\n",
            "86/86 [==============================] - 0s 781us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 643/1000\n",
            "86/86 [==============================] - 0s 750us/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 644/1000\n",
            "86/86 [==============================] - 0s 796us/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 645/1000\n",
            "86/86 [==============================] - 0s 774us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 646/1000\n",
            "86/86 [==============================] - 0s 783us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 647/1000\n",
            "86/86 [==============================] - 0s 755us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 648/1000\n",
            "86/86 [==============================] - 0s 765us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 649/1000\n",
            "86/86 [==============================] - 0s 778us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 650/1000\n",
            "86/86 [==============================] - 0s 890us/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 651/1000\n",
            "86/86 [==============================] - 0s 886us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 652/1000\n",
            "86/86 [==============================] - 0s 806us/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 653/1000\n",
            "86/86 [==============================] - 0s 792us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 654/1000\n",
            "86/86 [==============================] - 0s 838us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 655/1000\n",
            "86/86 [==============================] - 0s 766us/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 656/1000\n",
            "86/86 [==============================] - 0s 900us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 657/1000\n",
            "86/86 [==============================] - 0s 751us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 658/1000\n",
            "86/86 [==============================] - 0s 759us/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 659/1000\n",
            "86/86 [==============================] - 0s 832us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 660/1000\n",
            "86/86 [==============================] - 0s 749us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 661/1000\n",
            "86/86 [==============================] - 0s 786us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 662/1000\n",
            "86/86 [==============================] - 0s 826us/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 663/1000\n",
            "86/86 [==============================] - 0s 781us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 664/1000\n",
            "86/86 [==============================] - 0s 748us/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 665/1000\n",
            "86/86 [==============================] - 0s 869us/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 666/1000\n",
            "86/86 [==============================] - 0s 773us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 667/1000\n",
            "86/86 [==============================] - 0s 800us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 668/1000\n",
            "86/86 [==============================] - 0s 805us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 669/1000\n",
            "86/86 [==============================] - 0s 742us/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 670/1000\n",
            "86/86 [==============================] - 0s 810us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 671/1000\n",
            "86/86 [==============================] - 0s 787us/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 672/1000\n",
            "86/86 [==============================] - 0s 755us/step - loss: 0.0573 - val_loss: 0.0541\n",
            "Epoch 673/1000\n",
            "86/86 [==============================] - 0s 773us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 674/1000\n",
            "86/86 [==============================] - 0s 828us/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 675/1000\n",
            "86/86 [==============================] - 0s 791us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 676/1000\n",
            "86/86 [==============================] - 0s 757us/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 677/1000\n",
            "86/86 [==============================] - 0s 748us/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 678/1000\n",
            "86/86 [==============================] - 0s 804us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 679/1000\n",
            "86/86 [==============================] - 0s 884us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 680/1000\n",
            "86/86 [==============================] - 0s 816us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 681/1000\n",
            "86/86 [==============================] - 0s 814us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 682/1000\n",
            "86/86 [==============================] - 0s 820us/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 683/1000\n",
            "86/86 [==============================] - 0s 796us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 684/1000\n",
            "86/86 [==============================] - 0s 760us/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 685/1000\n",
            "86/86 [==============================] - 0s 839us/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 686/1000\n",
            "86/86 [==============================] - 0s 878us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 687/1000\n",
            "86/86 [==============================] - 0s 739us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 688/1000\n",
            "86/86 [==============================] - 0s 739us/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 689/1000\n",
            "86/86 [==============================] - 0s 789us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 690/1000\n",
            "86/86 [==============================] - 0s 815us/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 691/1000\n",
            "86/86 [==============================] - 0s 778us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 692/1000\n",
            "86/86 [==============================] - 0s 767us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 693/1000\n",
            "86/86 [==============================] - 0s 824us/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 694/1000\n",
            "86/86 [==============================] - 0s 825us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 695/1000\n",
            "86/86 [==============================] - 0s 788us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 696/1000\n",
            "86/86 [==============================] - 0s 892us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 697/1000\n",
            "86/86 [==============================] - 0s 863us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 698/1000\n",
            "86/86 [==============================] - 0s 974us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 699/1000\n",
            "86/86 [==============================] - 0s 898us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 700/1000\n",
            "86/86 [==============================] - 0s 812us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 701/1000\n",
            "86/86 [==============================] - 0s 769us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 702/1000\n",
            "86/86 [==============================] - 0s 763us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 703/1000\n",
            "86/86 [==============================] - 0s 839us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 704/1000\n",
            "86/86 [==============================] - 0s 819us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 705/1000\n",
            "86/86 [==============================] - 0s 776us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 706/1000\n",
            "86/86 [==============================] - 0s 878us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 707/1000\n",
            "86/86 [==============================] - 0s 798us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 708/1000\n",
            "86/86 [==============================] - 0s 812us/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 709/1000\n",
            "86/86 [==============================] - 0s 827us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 710/1000\n",
            "86/86 [==============================] - 0s 754us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 711/1000\n",
            "86/86 [==============================] - 0s 781us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 712/1000\n",
            "86/86 [==============================] - 0s 826us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 713/1000\n",
            "86/86 [==============================] - 0s 793us/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 714/1000\n",
            "86/86 [==============================] - 0s 839us/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 715/1000\n",
            "86/86 [==============================] - 0s 767us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 716/1000\n",
            "86/86 [==============================] - 0s 802us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 717/1000\n",
            "86/86 [==============================] - 0s 773us/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 718/1000\n",
            "86/86 [==============================] - 0s 802us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 719/1000\n",
            "86/86 [==============================] - 0s 803us/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 720/1000\n",
            "86/86 [==============================] - 0s 824us/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 721/1000\n",
            "86/86 [==============================] - 0s 866us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 722/1000\n",
            "86/86 [==============================] - 0s 787us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 723/1000\n",
            "86/86 [==============================] - 0s 779us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 724/1000\n",
            "86/86 [==============================] - 0s 771us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 725/1000\n",
            "86/86 [==============================] - 0s 821us/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 726/1000\n",
            "86/86 [==============================] - 0s 765us/step - loss: 0.0575 - val_loss: 0.0545\n",
            "Epoch 727/1000\n",
            "86/86 [==============================] - 0s 793us/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 728/1000\n",
            "86/86 [==============================] - 0s 906us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 729/1000\n",
            "86/86 [==============================] - 0s 820us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 730/1000\n",
            "86/86 [==============================] - 0s 803us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 731/1000\n",
            "86/86 [==============================] - 0s 785us/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 732/1000\n",
            "86/86 [==============================] - 0s 896us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 733/1000\n",
            "86/86 [==============================] - 0s 808us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 734/1000\n",
            "86/86 [==============================] - 0s 765us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 735/1000\n",
            "86/86 [==============================] - 0s 738us/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 736/1000\n",
            "86/86 [==============================] - 0s 776us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 737/1000\n",
            "86/86 [==============================] - 0s 816us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 738/1000\n",
            "86/86 [==============================] - 0s 850us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 739/1000\n",
            "86/86 [==============================] - 0s 779us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 740/1000\n",
            "86/86 [==============================] - 0s 775us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 741/1000\n",
            "86/86 [==============================] - 0s 792us/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 742/1000\n",
            "86/86 [==============================] - 0s 820us/step - loss: 0.0575 - val_loss: 0.0544\n",
            "Epoch 743/1000\n",
            "86/86 [==============================] - 0s 805us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 744/1000\n",
            "86/86 [==============================] - 0s 770us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 745/1000\n",
            "86/86 [==============================] - 0s 791us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 746/1000\n",
            "86/86 [==============================] - 0s 764us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 747/1000\n",
            "86/86 [==============================] - 0s 793us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 748/1000\n",
            "86/86 [==============================] - 0s 899us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 749/1000\n",
            "86/86 [==============================] - 0s 768us/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 750/1000\n",
            "86/86 [==============================] - 0s 765us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 751/1000\n",
            "86/86 [==============================] - 0s 783us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 752/1000\n",
            "86/86 [==============================] - 0s 834us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 753/1000\n",
            "86/86 [==============================] - 0s 839us/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 754/1000\n",
            "86/86 [==============================] - 0s 796us/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 755/1000\n",
            "86/86 [==============================] - 0s 802us/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 756/1000\n",
            "86/86 [==============================] - 0s 785us/step - loss: 0.0573 - val_loss: 0.0540\n",
            "Epoch 757/1000\n",
            "86/86 [==============================] - 0s 713us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 758/1000\n",
            "86/86 [==============================] - 0s 780us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 759/1000\n",
            "86/86 [==============================] - 0s 788us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 760/1000\n",
            "86/86 [==============================] - 0s 844us/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 761/1000\n",
            "86/86 [==============================] - 0s 839us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 762/1000\n",
            "86/86 [==============================] - 0s 792us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 763/1000\n",
            "86/86 [==============================] - 0s 792us/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 764/1000\n",
            "86/86 [==============================] - 0s 775us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 765/1000\n",
            "86/86 [==============================] - 0s 797us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 766/1000\n",
            "86/86 [==============================] - 0s 762us/step - loss: 0.0573 - val_loss: 0.0541\n",
            "Epoch 767/1000\n",
            "86/86 [==============================] - 0s 808us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 768/1000\n",
            "86/86 [==============================] - 0s 832us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 769/1000\n",
            "86/86 [==============================] - 0s 884us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 770/1000\n",
            "86/86 [==============================] - 0s 753us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 771/1000\n",
            "86/86 [==============================] - 0s 744us/step - loss: 0.0574 - val_loss: 0.0545\n",
            "Epoch 772/1000\n",
            "86/86 [==============================] - 0s 804us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 773/1000\n",
            "86/86 [==============================] - 0s 795us/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 774/1000\n",
            "86/86 [==============================] - 0s 748us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 775/1000\n",
            "86/86 [==============================] - 0s 763us/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 776/1000\n",
            "86/86 [==============================] - 0s 923us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 777/1000\n",
            "86/86 [==============================] - 0s 899us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 778/1000\n",
            "86/86 [==============================] - 0s 785us/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 779/1000\n",
            "86/86 [==============================] - 0s 811us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 780/1000\n",
            "86/86 [==============================] - 0s 817us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 781/1000\n",
            "86/86 [==============================] - 0s 795us/step - loss: 0.0574 - val_loss: 0.0545\n",
            "Epoch 782/1000\n",
            "86/86 [==============================] - 0s 769us/step - loss: 0.0573 - val_loss: 0.0540\n",
            "Epoch 783/1000\n",
            "86/86 [==============================] - 0s 758us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 784/1000\n",
            "86/86 [==============================] - 0s 811us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 785/1000\n",
            "86/86 [==============================] - 0s 793us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 786/1000\n",
            "86/86 [==============================] - 0s 745us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 787/1000\n",
            "86/86 [==============================] - 0s 817us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 788/1000\n",
            "86/86 [==============================] - 0s 783us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 789/1000\n",
            "86/86 [==============================] - 0s 853us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 790/1000\n",
            "86/86 [==============================] - 0s 762us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 791/1000\n",
            "86/86 [==============================] - 0s 778us/step - loss: 0.0573 - val_loss: 0.0542\n",
            "Epoch 792/1000\n",
            "86/86 [==============================] - 0s 809us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 793/1000\n",
            "86/86 [==============================] - 0s 813us/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 794/1000\n",
            "86/86 [==============================] - 0s 790us/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 795/1000\n",
            "86/86 [==============================] - 0s 756us/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 796/1000\n",
            "86/86 [==============================] - 0s 740us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 797/1000\n",
            "86/86 [==============================] - 0s 761us/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 798/1000\n",
            "86/86 [==============================] - 0s 813us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 799/1000\n",
            "86/86 [==============================] - 0s 741us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 800/1000\n",
            "86/86 [==============================] - 0s 751us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 801/1000\n",
            "86/86 [==============================] - 0s 772us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 802/1000\n",
            "86/86 [==============================] - 0s 794us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 803/1000\n",
            "86/86 [==============================] - 0s 771us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 804/1000\n",
            "86/86 [==============================] - 0s 777us/step - loss: 0.0574 - val_loss: 0.0545\n",
            "Epoch 805/1000\n",
            "86/86 [==============================] - 0s 818us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 806/1000\n",
            "86/86 [==============================] - 0s 763us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 807/1000\n",
            "86/86 [==============================] - 0s 817us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 808/1000\n",
            "86/86 [==============================] - 0s 807us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 809/1000\n",
            "86/86 [==============================] - 0s 899us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 810/1000\n",
            "86/86 [==============================] - 0s 788us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 811/1000\n",
            "86/86 [==============================] - 0s 817us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 812/1000\n",
            "86/86 [==============================] - 0s 841us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 813/1000\n",
            "86/86 [==============================] - 0s 762us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 814/1000\n",
            "86/86 [==============================] - 0s 803us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 815/1000\n",
            "86/86 [==============================] - 0s 738us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 816/1000\n",
            "86/86 [==============================] - 0s 735us/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 817/1000\n",
            "86/86 [==============================] - 0s 810us/step - loss: 0.0573 - val_loss: 0.0541\n",
            "Epoch 818/1000\n",
            "86/86 [==============================] - 0s 913us/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 819/1000\n",
            "86/86 [==============================] - 0s 834us/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 820/1000\n",
            "86/86 [==============================] - 0s 770us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 821/1000\n",
            "86/86 [==============================] - 0s 757us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 822/1000\n",
            "86/86 [==============================] - 0s 884us/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 823/1000\n",
            "86/86 [==============================] - 0s 822us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 824/1000\n",
            "86/86 [==============================] - 0s 793us/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 825/1000\n",
            "86/86 [==============================] - 0s 787us/step - loss: 0.0573 - val_loss: 0.0541\n",
            "Epoch 826/1000\n",
            "86/86 [==============================] - 0s 783us/step - loss: 0.0573 - val_loss: 0.0541\n",
            "Epoch 827/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 828/1000\n",
            "86/86 [==============================] - 0s 721us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 829/1000\n",
            "86/86 [==============================] - 0s 824us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 830/1000\n",
            "86/86 [==============================] - 0s 800us/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 831/1000\n",
            "86/86 [==============================] - 0s 873us/step - loss: 0.0575 - val_loss: 0.0546\n",
            "Epoch 832/1000\n",
            "86/86 [==============================] - 0s 763us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 833/1000\n",
            "86/86 [==============================] - 0s 766us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 834/1000\n",
            "86/86 [==============================] - 0s 771us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 835/1000\n",
            "86/86 [==============================] - 0s 829us/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 836/1000\n",
            "86/86 [==============================] - 0s 835us/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 837/1000\n",
            "86/86 [==============================] - 0s 782us/step - loss: 0.0574 - val_loss: 0.0545\n",
            "Epoch 838/1000\n",
            "86/86 [==============================] - 0s 792us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 839/1000\n",
            "86/86 [==============================] - 0s 770us/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 840/1000\n",
            "86/86 [==============================] - 0s 930us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 841/1000\n",
            "86/86 [==============================] - 0s 768us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 842/1000\n",
            "86/86 [==============================] - 0s 767us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 843/1000\n",
            "86/86 [==============================] - 0s 873us/step - loss: 0.0574 - val_loss: 0.0546\n",
            "Epoch 844/1000\n",
            "86/86 [==============================] - 0s 890us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 845/1000\n",
            "86/86 [==============================] - 0s 808us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 846/1000\n",
            "86/86 [==============================] - 0s 759us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 847/1000\n",
            "86/86 [==============================] - 0s 778us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 848/1000\n",
            "86/86 [==============================] - 0s 776us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 849/1000\n",
            "86/86 [==============================] - 0s 754us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 850/1000\n",
            "86/86 [==============================] - 0s 729us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 851/1000\n",
            "86/86 [==============================] - 0s 735us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 852/1000\n",
            "86/86 [==============================] - 0s 779us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 853/1000\n",
            "86/86 [==============================] - 0s 872us/step - loss: 0.0573 - val_loss: 0.0540\n",
            "Epoch 854/1000\n",
            "86/86 [==============================] - 0s 747us/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 855/1000\n",
            "86/86 [==============================] - 0s 794us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 856/1000\n",
            "86/86 [==============================] - 0s 829us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 857/1000\n",
            "86/86 [==============================] - 0s 728us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 858/1000\n",
            "86/86 [==============================] - 0s 761us/step - loss: 0.0573 - val_loss: 0.0541\n",
            "Epoch 859/1000\n",
            "86/86 [==============================] - 0s 896us/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 860/1000\n",
            "86/86 [==============================] - 0s 929us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 861/1000\n",
            "86/86 [==============================] - 0s 758us/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 862/1000\n",
            "86/86 [==============================] - 0s 805us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 863/1000\n",
            "86/86 [==============================] - 0s 873us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 864/1000\n",
            "86/86 [==============================] - 0s 753us/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 865/1000\n",
            "86/86 [==============================] - 0s 737us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 866/1000\n",
            "86/86 [==============================] - 0s 740us/step - loss: 0.0574 - val_loss: 0.0546\n",
            "Epoch 867/1000\n",
            "86/86 [==============================] - 0s 866us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 868/1000\n",
            "86/86 [==============================] - 0s 748us/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 869/1000\n",
            "86/86 [==============================] - 0s 778us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 870/1000\n",
            "86/86 [==============================] - 0s 819us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 871/1000\n",
            "86/86 [==============================] - 0s 795us/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 872/1000\n",
            "86/86 [==============================] - 0s 800us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 873/1000\n",
            "86/86 [==============================] - 0s 815us/step - loss: 0.0573 - val_loss: 0.0539\n",
            "Epoch 874/1000\n",
            "86/86 [==============================] - 0s 782us/step - loss: 0.0573 - val_loss: 0.0543\n",
            "Epoch 875/1000\n",
            "86/86 [==============================] - 0s 743us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 876/1000\n",
            "86/86 [==============================] - 0s 772us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 877/1000\n",
            "86/86 [==============================] - 0s 771us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 878/1000\n",
            "86/86 [==============================] - 0s 835us/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 879/1000\n",
            "86/86 [==============================] - 0s 771us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 880/1000\n",
            "86/86 [==============================] - 0s 759us/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 881/1000\n",
            "86/86 [==============================] - 0s 839us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 882/1000\n",
            "86/86 [==============================] - 0s 825us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 883/1000\n",
            "86/86 [==============================] - 0s 805us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 884/1000\n",
            "86/86 [==============================] - 0s 745us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 885/1000\n",
            "86/86 [==============================] - 0s 807us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 886/1000\n",
            "86/86 [==============================] - 0s 748us/step - loss: 0.0573 - val_loss: 0.0540\n",
            "Epoch 887/1000\n",
            "86/86 [==============================] - 0s 918us/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 888/1000\n",
            "86/86 [==============================] - 0s 793us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 889/1000\n",
            "86/86 [==============================] - 0s 758us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 890/1000\n",
            "86/86 [==============================] - 0s 802us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 891/1000\n",
            "86/86 [==============================] - 0s 851us/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 892/1000\n",
            "86/86 [==============================] - 0s 814us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 893/1000\n",
            "86/86 [==============================] - 0s 737us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 894/1000\n",
            "86/86 [==============================] - 0s 730us/step - loss: 0.0573 - val_loss: 0.0543\n",
            "Epoch 895/1000\n",
            "86/86 [==============================] - 0s 791us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 896/1000\n",
            "86/86 [==============================] - 0s 755us/step - loss: 0.0573 - val_loss: 0.0543\n",
            "Epoch 897/1000\n",
            "86/86 [==============================] - 0s 747us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 898/1000\n",
            "86/86 [==============================] - 0s 769us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 899/1000\n",
            "86/86 [==============================] - 0s 801us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 900/1000\n",
            "86/86 [==============================] - 0s 785us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 901/1000\n",
            "86/86 [==============================] - 0s 855us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 902/1000\n",
            "86/86 [==============================] - 0s 818us/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 903/1000\n",
            "86/86 [==============================] - 0s 773us/step - loss: 0.0573 - val_loss: 0.0540\n",
            "Epoch 904/1000\n",
            "86/86 [==============================] - 0s 793us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 905/1000\n",
            "86/86 [==============================] - 0s 816us/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 906/1000\n",
            "86/86 [==============================] - 0s 958us/step - loss: 0.0574 - val_loss: 0.0546\n",
            "Epoch 907/1000\n",
            "86/86 [==============================] - 0s 813us/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 908/1000\n",
            "86/86 [==============================] - 0s 828us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 909/1000\n",
            "86/86 [==============================] - 0s 782us/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 910/1000\n",
            "86/86 [==============================] - 0s 765us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 911/1000\n",
            "86/86 [==============================] - 0s 778us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 912/1000\n",
            "86/86 [==============================] - 0s 815us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 913/1000\n",
            "86/86 [==============================] - 0s 801us/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 914/1000\n",
            "86/86 [==============================] - 0s 799us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 915/1000\n",
            "86/86 [==============================] - 0s 873us/step - loss: 0.0574 - val_loss: 0.0545\n",
            "Epoch 916/1000\n",
            "86/86 [==============================] - 0s 745us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 917/1000\n",
            "86/86 [==============================] - 0s 818us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 918/1000\n",
            "86/86 [==============================] - 0s 756us/step - loss: 0.0573 - val_loss: 0.0542\n",
            "Epoch 919/1000\n",
            "86/86 [==============================] - 0s 752us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 920/1000\n",
            "86/86 [==============================] - 0s 742us/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 921/1000\n",
            "86/86 [==============================] - 0s 787us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 922/1000\n",
            "86/86 [==============================] - 0s 746us/step - loss: 0.0573 - val_loss: 0.0540\n",
            "Epoch 923/1000\n",
            "86/86 [==============================] - 0s 755us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 924/1000\n",
            "86/86 [==============================] - 0s 764us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 925/1000\n",
            "86/86 [==============================] - 0s 793us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 926/1000\n",
            "86/86 [==============================] - 0s 827us/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 927/1000\n",
            "86/86 [==============================] - 0s 851us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 928/1000\n",
            "86/86 [==============================] - 0s 795us/step - loss: 0.0575 - val_loss: 0.0544\n",
            "Epoch 929/1000\n",
            "86/86 [==============================] - 0s 963us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 930/1000\n",
            "86/86 [==============================] - 0s 795us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 931/1000\n",
            "86/86 [==============================] - 0s 869us/step - loss: 0.0573 - val_loss: 0.0544\n",
            "Epoch 932/1000\n",
            "86/86 [==============================] - 0s 759us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 933/1000\n",
            "86/86 [==============================] - 0s 746us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 934/1000\n",
            "86/86 [==============================] - 0s 895us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 935/1000\n",
            "86/86 [==============================] - 0s 786us/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 936/1000\n",
            "86/86 [==============================] - 0s 777us/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 937/1000\n",
            "86/86 [==============================] - 0s 783us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 938/1000\n",
            "86/86 [==============================] - 0s 809us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 939/1000\n",
            "86/86 [==============================] - 0s 829us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 940/1000\n",
            "86/86 [==============================] - 0s 753us/step - loss: 0.0573 - val_loss: 0.0542\n",
            "Epoch 941/1000\n",
            "86/86 [==============================] - 0s 798us/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 942/1000\n",
            "86/86 [==============================] - 0s 826us/step - loss: 0.0573 - val_loss: 0.0543\n",
            "Epoch 943/1000\n",
            "86/86 [==============================] - 0s 848us/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 944/1000\n",
            "86/86 [==============================] - 0s 764us/step - loss: 0.0573 - val_loss: 0.0540\n",
            "Epoch 945/1000\n",
            "86/86 [==============================] - 0s 762us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 946/1000\n",
            "86/86 [==============================] - 0s 753us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 947/1000\n",
            "86/86 [==============================] - 0s 795us/step - loss: 0.0573 - val_loss: 0.0545\n",
            "Epoch 948/1000\n",
            "86/86 [==============================] - 0s 753us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 949/1000\n",
            "86/86 [==============================] - 0s 926us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 950/1000\n",
            "86/86 [==============================] - 0s 763us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 951/1000\n",
            "86/86 [==============================] - 0s 758us/step - loss: 0.0574 - val_loss: 0.0545\n",
            "Epoch 952/1000\n",
            "86/86 [==============================] - 0s 796us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 953/1000\n",
            "86/86 [==============================] - 0s 769us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 954/1000\n",
            "86/86 [==============================] - 0s 752us/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 955/1000\n",
            "86/86 [==============================] - 0s 752us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 956/1000\n",
            "86/86 [==============================] - 0s 776us/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 957/1000\n",
            "86/86 [==============================] - 0s 812us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 958/1000\n",
            "86/86 [==============================] - 0s 781us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 959/1000\n",
            "86/86 [==============================] - 0s 764us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 960/1000\n",
            "86/86 [==============================] - 0s 902us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 961/1000\n",
            "86/86 [==============================] - 0s 821us/step - loss: 0.0573 - val_loss: 0.0542\n",
            "Epoch 962/1000\n",
            "86/86 [==============================] - 0s 763us/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 963/1000\n",
            "86/86 [==============================] - 0s 759us/step - loss: 0.0575 - val_loss: 0.0544\n",
            "Epoch 964/1000\n",
            "86/86 [==============================] - 0s 771us/step - loss: 0.0573 - val_loss: 0.0541\n",
            "Epoch 965/1000\n",
            "86/86 [==============================] - 0s 753us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 966/1000\n",
            "86/86 [==============================] - 0s 778us/step - loss: 0.0573 - val_loss: 0.0542\n",
            "Epoch 967/1000\n",
            "86/86 [==============================] - 0s 753us/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 968/1000\n",
            "86/86 [==============================] - 0s 791us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 969/1000\n",
            "86/86 [==============================] - 0s 759us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 970/1000\n",
            "86/86 [==============================] - 0s 769us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 971/1000\n",
            "86/86 [==============================] - 0s 810us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 972/1000\n",
            "86/86 [==============================] - 0s 868us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 973/1000\n",
            "86/86 [==============================] - 0s 854us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 974/1000\n",
            "86/86 [==============================] - 0s 803us/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 975/1000\n",
            "86/86 [==============================] - 0s 778us/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 976/1000\n",
            "86/86 [==============================] - 0s 843us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 977/1000\n",
            "86/86 [==============================] - 0s 768us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 978/1000\n",
            "86/86 [==============================] - 0s 780us/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 979/1000\n",
            "86/86 [==============================] - 0s 729us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 980/1000\n",
            "86/86 [==============================] - 0s 826us/step - loss: 0.0573 - val_loss: 0.0541\n",
            "Epoch 981/1000\n",
            "86/86 [==============================] - 0s 772us/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 982/1000\n",
            "86/86 [==============================] - 0s 793us/step - loss: 0.0573 - val_loss: 0.0541\n",
            "Epoch 983/1000\n",
            "86/86 [==============================] - 0s 810us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 984/1000\n",
            "86/86 [==============================] - 0s 817us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 985/1000\n",
            "86/86 [==============================] - 0s 896us/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 986/1000\n",
            "86/86 [==============================] - 0s 782us/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 987/1000\n",
            "86/86 [==============================] - 0s 834us/step - loss: 0.0574 - val_loss: 0.0545\n",
            "Epoch 988/1000\n",
            "86/86 [==============================] - 0s 926us/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 989/1000\n",
            "86/86 [==============================] - 0s 842us/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 990/1000\n",
            "86/86 [==============================] - 0s 788us/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 991/1000\n",
            "86/86 [==============================] - 0s 791us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 992/1000\n",
            "86/86 [==============================] - 0s 799us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 993/1000\n",
            "86/86 [==============================] - 0s 797us/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 994/1000\n",
            "86/86 [==============================] - 0s 751us/step - loss: 0.0573 - val_loss: 0.0541\n",
            "Epoch 995/1000\n",
            "86/86 [==============================] - 0s 814us/step - loss: 0.0573 - val_loss: 0.0544\n",
            "Epoch 996/1000\n",
            "86/86 [==============================] - 0s 762us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 997/1000\n",
            "86/86 [==============================] - 0s 775us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 998/1000\n",
            "86/86 [==============================] - 0s 881us/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 999/1000\n",
            "86/86 [==============================] - 0s 898us/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 1000/1000\n",
            "86/86 [==============================] - 0s 811us/step - loss: 0.0573 - val_loss: 0.0540\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iq9eqig9dHkq",
        "outputId": "52e35da0-fbd8-4a16-c532-bf10cb007ee2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "wider_history_dataframe = pd.DataFrame(wider_model_history.history)\n",
        "wider_history_dataframe['epoch'] = wider_model_history.epoch\n",
        "wider_history_dataframe.sort_values(by='val_loss', ascending=True)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>0.057580</td>\n",
              "      <td>0.053721</td>\n",
              "      <td>251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.058217</td>\n",
              "      <td>0.053726</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.057995</td>\n",
              "      <td>0.053729</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>0.057857</td>\n",
              "      <td>0.053732</td>\n",
              "      <td>86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>0.057969</td>\n",
              "      <td>0.053746</td>\n",
              "      <td>91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>535</th>\n",
              "      <td>0.057463</td>\n",
              "      <td>0.054562</td>\n",
              "      <td>535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>842</th>\n",
              "      <td>0.057382</td>\n",
              "      <td>0.054564</td>\n",
              "      <td>842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>440</th>\n",
              "      <td>0.057584</td>\n",
              "      <td>0.054588</td>\n",
              "      <td>440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>830</th>\n",
              "      <td>0.057471</td>\n",
              "      <td>0.054613</td>\n",
              "      <td>830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>905</th>\n",
              "      <td>0.057373</td>\n",
              "      <td>0.054631</td>\n",
              "      <td>905</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         loss  val_loss  epoch\n",
              "251  0.057580  0.053721    251\n",
              "9    0.058217  0.053726      9\n",
              "11   0.057995  0.053729     11\n",
              "86   0.057857  0.053732     86\n",
              "91   0.057969  0.053746     91\n",
              "..        ...       ...    ...\n",
              "535  0.057463  0.054562    535\n",
              "842  0.057382  0.054564    842\n",
              "440  0.057584  0.054588    440\n",
              "830  0.057471  0.054613    830\n",
              "905  0.057373  0.054631    905\n",
              "\n",
              "[1000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8beOE3EcGH-o",
        "outputId": "fe42f945-8590-4715-c5d7-35184987b646",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "plot_loss(wider_model_history)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiEbtlDGdguk"
      },
      "source": [
        "### LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a25ZoJ9udHe6",
        "outputId": "54dfa774-6cb8-4764-c4f7-8ec9728e661a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epoch = 1000\n",
        "batch_size = 32\n",
        "\n",
        "# Reshape menjadi (jumlah sample, time steps, jumlah feature)\n",
        "# Time steps: jumlah lag, gunakan default 1\n",
        "# https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/\n",
        "feature_train_reshaped = np.reshape(feature_train, (feature_train.shape[0], 1, feature_train.shape[1]))\n",
        "feature_test_reshaped = np.reshape(feature_test, (feature_test.shape[0], 1, feature_test.shape[1]))\n",
        "\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(LSTM(50, activation='relu', input_dim=feature_train.shape[1])) # 50 LSTM Block\n",
        "lstm_model.add(Dense(1))\n",
        "lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "lstm_model_history = lstm_model.fit(feature_train_reshaped, label_train, epochs=epoch, batch_size=batch_size, validation_data=(feature_test_reshaped, label_test))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0655 - val_loss: 0.0550\n",
            "Epoch 2/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0593 - val_loss: 0.0544\n",
            "Epoch 3/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0543\n",
            "Epoch 4/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0539\n",
            "Epoch 5/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0539\n",
            "Epoch 6/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0539\n",
            "Epoch 7/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0585 - val_loss: 0.0539\n",
            "Epoch 8/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0540\n",
            "Epoch 9/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0540\n",
            "Epoch 10/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 11/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 12/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0543\n",
            "Epoch 13/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0585 - val_loss: 0.0539\n",
            "Epoch 14/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 15/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 16/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 17/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 18/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 19/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0540\n",
            "Epoch 20/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 21/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0543\n",
            "Epoch 22/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 23/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 24/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 25/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 26/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 27/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 28/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 29/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 30/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 31/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 32/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0541\n",
            "Epoch 33/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 34/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 35/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 36/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 37/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 38/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 39/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0543\n",
            "Epoch 40/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 41/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 42/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 43/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 44/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0546\n",
            "Epoch 45/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 46/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 47/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 48/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 49/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 50/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 51/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 52/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 53/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 54/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 55/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 56/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 57/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0540\n",
            "Epoch 58/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 59/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 60/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 61/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 62/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 63/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 64/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 65/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 66/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 67/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 68/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 69/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 70/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 71/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 72/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 73/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 74/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 75/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 76/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 77/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 78/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 79/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 80/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 81/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 82/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 83/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 84/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 85/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 86/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 87/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 88/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 89/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 90/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 91/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 92/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 93/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 94/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 95/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 96/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 97/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 98/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0542\n",
            "Epoch 99/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 100/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 101/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 102/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0542\n",
            "Epoch 103/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 104/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 105/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 106/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 107/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 108/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 109/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 110/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 111/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 112/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 113/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 114/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 115/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 116/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0545\n",
            "Epoch 117/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0542\n",
            "Epoch 118/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 119/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 120/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 121/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 122/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 123/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 124/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 125/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 126/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 127/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 128/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 129/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 130/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 131/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 132/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 133/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 134/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 135/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 136/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 137/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 138/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 139/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 140/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 141/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0542\n",
            "Epoch 142/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 143/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0543\n",
            "Epoch 144/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 145/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 146/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 147/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 148/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 149/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 150/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 151/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 152/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 153/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 154/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 155/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 156/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 157/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 158/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 159/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 160/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 161/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 162/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 163/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 164/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 165/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 166/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 167/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 168/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 169/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 170/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 171/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 172/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 173/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 174/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 175/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 176/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 177/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 178/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 179/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 180/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 181/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 182/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 183/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 184/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 185/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 186/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 187/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 188/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 189/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 190/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 191/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 192/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 193/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 194/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 195/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 196/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 197/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 198/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 199/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 200/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 201/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 202/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 203/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 204/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 205/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 206/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 207/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 208/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 209/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 210/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 211/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 212/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 213/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 214/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 215/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 216/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0541\n",
            "Epoch 217/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 218/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 219/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 220/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 221/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 222/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 223/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 224/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 225/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 226/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 227/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 228/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 229/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 230/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 231/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0542\n",
            "Epoch 232/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 233/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0542\n",
            "Epoch 234/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 235/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 236/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 237/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 238/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 239/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 240/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 241/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 242/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 243/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0542\n",
            "Epoch 244/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 245/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 246/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 247/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 248/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 249/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 250/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 251/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 252/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 253/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 254/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 255/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 256/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0544\n",
            "Epoch 257/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 258/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 259/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 260/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 261/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 262/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 263/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 264/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 265/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 266/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 267/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 268/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 269/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 270/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 271/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 272/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 273/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 274/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 275/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 276/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0541\n",
            "Epoch 277/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 278/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 279/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 280/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 281/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 282/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 283/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 284/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 285/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 286/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0541\n",
            "Epoch 287/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 288/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 289/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 290/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 291/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 292/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 293/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 294/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 295/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 296/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 297/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 298/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 299/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 300/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 301/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 302/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 303/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 304/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 305/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 306/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 307/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 308/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 309/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 310/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 311/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 312/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 313/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 314/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 315/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 316/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 317/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0542\n",
            "Epoch 318/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 319/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 320/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 321/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 322/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 323/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 324/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 325/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 326/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 327/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 328/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 329/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 330/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 331/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 332/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 333/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 334/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 335/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 336/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 337/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 338/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 339/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 340/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 341/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 342/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 343/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 344/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 345/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 346/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 347/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 348/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 349/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 350/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 351/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 352/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 353/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 354/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 355/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 356/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 357/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 358/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 359/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 360/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 361/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 362/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 363/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 364/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 365/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 366/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 367/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0541\n",
            "Epoch 368/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 369/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 370/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 371/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 372/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 373/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 374/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 375/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 376/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 377/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 378/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 379/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 380/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 381/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 382/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 383/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 384/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 385/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 386/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 387/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 388/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 389/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 390/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 391/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 392/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 393/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 394/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 395/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 396/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 397/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 398/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 399/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 400/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 401/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 402/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 403/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 404/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 405/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 406/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 407/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 408/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 409/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 410/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 411/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 412/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 413/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 414/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 415/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 416/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 417/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 418/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 419/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0541\n",
            "Epoch 420/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 421/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 422/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 423/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 424/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 425/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 426/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 427/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 428/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 429/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 430/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 431/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 432/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 433/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 434/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 435/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 436/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 437/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 438/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 439/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 440/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 441/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 442/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 443/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 444/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 445/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 446/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 447/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 448/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 449/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 450/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 451/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 452/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 453/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 454/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 455/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 456/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 457/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 458/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 459/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 460/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 461/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 462/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 463/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 464/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 465/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 466/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 467/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 468/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 469/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 470/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 471/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 472/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 473/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 474/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 475/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 476/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 477/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 478/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 479/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 480/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 481/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 482/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 483/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 484/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 485/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 486/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 487/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 488/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 489/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 490/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 491/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 492/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 493/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 494/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 495/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 496/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 497/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0541\n",
            "Epoch 498/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 499/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 500/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 501/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 502/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 503/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 504/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 505/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 506/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 507/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 508/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 509/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 510/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 511/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 512/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 513/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 514/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 515/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 516/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 517/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 518/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 519/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 520/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 521/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 522/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 523/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 524/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 525/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0543\n",
            "Epoch 526/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 527/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 528/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 529/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 530/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 531/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 532/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 533/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 534/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 535/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 536/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 537/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 538/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 539/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 540/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 541/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 542/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 543/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 544/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 545/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 546/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 547/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 548/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 549/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 550/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 551/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 552/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 553/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 554/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 555/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 556/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 557/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 558/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 559/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 560/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 561/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 562/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 563/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 564/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 565/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 566/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 567/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 568/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 569/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 570/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 571/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 572/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 573/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 574/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 575/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 576/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 577/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 578/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 579/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 580/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 581/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 582/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 583/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 584/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0543\n",
            "Epoch 585/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 586/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 587/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 588/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 589/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 590/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 591/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 592/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 593/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 594/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 595/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 596/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 597/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 598/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 599/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 600/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 601/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 602/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 603/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 604/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 605/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 606/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 607/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 608/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 609/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 610/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 611/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 612/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 613/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 614/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 615/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 616/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 617/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 618/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 619/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 620/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 621/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 622/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 623/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 624/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 625/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 626/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 627/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 628/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 629/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 630/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 631/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 632/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 633/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 634/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 635/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 636/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 637/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 638/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 639/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 640/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 641/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 642/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 643/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 644/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 645/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 646/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 647/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 648/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 649/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 650/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 651/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 652/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 653/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 654/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 655/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 656/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 657/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 658/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 659/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 660/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 661/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 662/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 663/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 664/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 665/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 666/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 667/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 668/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0542\n",
            "Epoch 669/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 670/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 671/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 672/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 673/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 674/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 675/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 676/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 677/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 678/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 679/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0541\n",
            "Epoch 680/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 681/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 682/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 683/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 684/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 685/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 686/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 687/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 688/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 689/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 690/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 691/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 692/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 693/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 694/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 695/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 696/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 697/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 698/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 699/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 700/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 701/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 702/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 703/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 704/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 705/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 706/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 707/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 708/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 709/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 710/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 711/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 712/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 713/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 714/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 715/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 716/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 717/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 718/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 719/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 720/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 721/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 722/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 723/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 724/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 725/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 726/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 727/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 728/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 729/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 730/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 731/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 732/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 733/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 734/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 735/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 736/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 737/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 738/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 739/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 740/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 741/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 742/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 743/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 744/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 745/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 746/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 747/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 748/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 749/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 750/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 751/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 752/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 753/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 754/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 755/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 756/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 757/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 758/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 759/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 760/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 761/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 762/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 763/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 764/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 765/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 766/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 767/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 768/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 769/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 770/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 771/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 772/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 773/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 774/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 775/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 776/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 777/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 778/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 779/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 780/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 781/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 782/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 783/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 784/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 785/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 786/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 787/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 788/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 789/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 790/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 791/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 792/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 793/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 794/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 795/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 796/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 797/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 798/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 799/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 800/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 801/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 802/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 803/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 804/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 805/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 806/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 807/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 808/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 809/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 810/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 811/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 812/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 813/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 814/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 815/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 816/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 817/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 818/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 819/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 820/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 821/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 822/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 823/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 824/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 825/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 826/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 827/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 828/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 829/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 830/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 831/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 832/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 833/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 834/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 835/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 836/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 837/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 838/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 839/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 840/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 841/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 842/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 843/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 844/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 845/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 846/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 847/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 848/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 849/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 850/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 851/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 852/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 853/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 854/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 855/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 856/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 857/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 858/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 859/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 860/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 861/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 862/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 863/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 864/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 865/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 866/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 867/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 868/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 869/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 870/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 871/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 872/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 873/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 874/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 875/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 876/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 877/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 878/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 879/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 880/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 881/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 882/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 883/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 884/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 885/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 886/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 887/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 888/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 889/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 890/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 891/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 892/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 893/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 894/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 895/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 896/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 897/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 898/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 899/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 900/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 901/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 902/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 903/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 904/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 905/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 906/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 907/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 908/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 909/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 910/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 911/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 912/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 913/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 914/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 915/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 916/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 917/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 918/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 919/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0543\n",
            "Epoch 920/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 921/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 922/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 923/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 924/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 925/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 926/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 927/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 928/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 929/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 930/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 931/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 932/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 933/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 934/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 935/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 936/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 937/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 938/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 939/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 940/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 941/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 942/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 943/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 944/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 945/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 946/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 947/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 948/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 949/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 950/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 951/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 952/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 953/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 954/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 955/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 956/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 957/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 958/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 959/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 960/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 961/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 962/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 963/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 964/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 965/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 966/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 967/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 968/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 969/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 970/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 971/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 972/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 973/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 974/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 975/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 976/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 977/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 978/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 979/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 980/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 981/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 982/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 983/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 984/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 985/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 986/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 987/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 988/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 989/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 990/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 991/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 992/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 993/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 994/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 995/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 996/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 997/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 998/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 999/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 1000/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuEHUNARcjCb",
        "outputId": "33c5ca2a-fef1-4dcc-a429-3b5afb5c1e02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "lstm_history_dataframe = pd.DataFrame(lstm_model_history.history)\n",
        "lstm_history_dataframe['epoch'] = lstm_model_history.epoch\n",
        "lstm_history_dataframe.sort_values(by='val_loss', ascending=True)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>0.057850</td>\n",
              "      <td>0.053774</td>\n",
              "      <td>393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>472</th>\n",
              "      <td>0.057798</td>\n",
              "      <td>0.053776</td>\n",
              "      <td>472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413</th>\n",
              "      <td>0.057911</td>\n",
              "      <td>0.053778</td>\n",
              "      <td>413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>443</th>\n",
              "      <td>0.057896</td>\n",
              "      <td>0.053779</td>\n",
              "      <td>443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>394</th>\n",
              "      <td>0.057931</td>\n",
              "      <td>0.053782</td>\n",
              "      <td>394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.059304</td>\n",
              "      <td>0.054384</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>255</th>\n",
              "      <td>0.058003</td>\n",
              "      <td>0.054385</td>\n",
              "      <td>255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>0.058043</td>\n",
              "      <td>0.054506</td>\n",
              "      <td>115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0.058030</td>\n",
              "      <td>0.054644</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.065495</td>\n",
              "      <td>0.055001</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         loss  val_loss  epoch\n",
              "393  0.057850  0.053774    393\n",
              "472  0.057798  0.053776    472\n",
              "413  0.057911  0.053778    413\n",
              "443  0.057896  0.053779    443\n",
              "394  0.057931  0.053782    394\n",
              "..        ...       ...    ...\n",
              "1    0.059304  0.054384      1\n",
              "255  0.058003  0.054385    255\n",
              "115  0.058043  0.054506    115\n",
              "43   0.058030  0.054644     43\n",
              "0    0.065495  0.055001      0\n",
              "\n",
              "[1000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWUtyE9jcaNq",
        "outputId": "8344363e-f181-4805-c49f-be31ec055032",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plot_loss(lstm_model_history)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3hLfosI-VNh"
      },
      "source": [
        "# Kesimpulan dataset daily-min-temperature\n",
        "\n",
        "Untuk hasil validation loss pada model-model diatas perbedaannya tidak terlalu signifikan. Akan tetapi validation loss terendah didapatkan dengan model Wider pada epoch ke-251, dimana:\n",
        "\n",
        "Epoch = 251\n",
        "\n",
        "Loss =\t0.057580\n",
        "\n",
        "Val_loss = \t0.053721"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IK141L9rNLr"
      },
      "source": [
        "# Dataset birth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BXhRZgzrYlT"
      },
      "source": [
        "## Parser dan Read dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAXlupjjrYlV"
      },
      "source": [
        "def parser(x):\n",
        "\treturn datetime.strptime(x, '%Y-%m-%d')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1_RXZS1rYlZ",
        "outputId": "26ce3d7f-53b0-48a3-d604-9e8b712f1a7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "dataset2 = pd.read_csv('/content/drive/My Drive/BCML/birth.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n",
        "\n",
        "dataset2.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Date\n",
              "1959-01-01    35\n",
              "1959-01-02    32\n",
              "1959-01-03    30\n",
              "1959-01-04    31\n",
              "1959-01-05    44\n",
              "Name: Births, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-hKNlSirYlc"
      },
      "source": [
        "## Plot dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljqRRJJZrYld",
        "outputId": "6a8f70ce-e952-4b6d-947d-fc1c704bc91d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dataset2.plot()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vA-9QU9ArYlg"
      },
      "source": [
        "## Processing Time series"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fw35MCRrYlg"
      },
      "source": [
        "def timeseries_to_supervised(data, lag=1):\n",
        "\tdf = pd.DataFrame(data)\n",
        "\tcolumns = [df.shift(i) for i in range(1, lag+1)]\n",
        "\tcolumns.append(df)\n",
        "\tdf = pd.concat(columns, axis=1)\n",
        "\treturn df\n",
        "\n",
        "def difference(dataset, interval=1):\n",
        "\tdiff = list()\n",
        "\tfor i in range(interval, len(dataset2)):\n",
        "\t\tvalue = dataset2[i] - dataset2[i - interval]\n",
        "\t\tdiff.append(value)\n",
        "\treturn pd.Series(diff)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R35K4KxprYlj",
        "outputId": "3ba2d012-535b-4d31-b024-df00fcf44083",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "lag = 1\n",
        "\n",
        "raw_values = dataset2.values\n",
        "diff_values = difference(raw_values, 1)\n",
        "\n",
        "diff_values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      -3\n",
              "1      -2\n",
              "2       1\n",
              "3      13\n",
              "4     -15\n",
              "       ..\n",
              "359     3\n",
              "360    15\n",
              "361    -4\n",
              "362     7\n",
              "363    -5\n",
              "Length: 364, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaW7_-SWrYll",
        "outputId": "b3bddb28-e847-4bf8-8093-1073f4d20e19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "supervised = timeseries_to_supervised(diff_values, lag)\n",
        "supervised"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>-3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-3.0</td>\n",
              "      <td>-2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-2.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.0</td>\n",
              "      <td>-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>359</th>\n",
              "      <td>-10.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>360</th>\n",
              "      <td>3.0</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>361</th>\n",
              "      <td>15.0</td>\n",
              "      <td>-4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>362</th>\n",
              "      <td>-4.0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>363</th>\n",
              "      <td>7.0</td>\n",
              "      <td>-5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>364 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0   0\n",
              "0     NaN  -3\n",
              "1    -3.0  -2\n",
              "2    -2.0   1\n",
              "3     1.0  13\n",
              "4    13.0 -15\n",
              "..    ...  ..\n",
              "359 -10.0   3\n",
              "360   3.0  15\n",
              "361  15.0  -4\n",
              "362  -4.0   7\n",
              "363   7.0  -5\n",
              "\n",
              "[364 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lQUUcrtrYlo",
        "outputId": "ca6754a3-773a-4bf0-f95d-9654316a8f85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "supervised_values = supervised.values[lag:,:]\n",
        "supervised_values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ -3.,  -2.],\n",
              "       [ -2.,   1.],\n",
              "       [  1.,  13.],\n",
              "       [ 13., -15.],\n",
              "       [-15.,  16.],\n",
              "       [ 16.,  -2.],\n",
              "       [ -2.,  -5.],\n",
              "       [ -5., -11.],\n",
              "       [-11.,  11.],\n",
              "       [ 11.,  -5.],\n",
              "       [ -5.,  22.],\n",
              "       [ 22.,  -8.],\n",
              "       [ -8.,  -2.],\n",
              "       [ -2.,  -8.],\n",
              "       [ -8.,  13.],\n",
              "       [ 13.,  -7.],\n",
              "       [ -7.,  -2.],\n",
              "       [ -2.,  11.],\n",
              "       [ 11., -18.],\n",
              "       [-18.,  19.],\n",
              "       [ 19., -14.],\n",
              "       [-14.,  -7.],\n",
              "       [ -7.,   5.],\n",
              "       [  5.,   6.],\n",
              "       [  6.,  -4.],\n",
              "       [ -4.,  -4.],\n",
              "       [ -4.,   9.],\n",
              "       [  9.,  -6.],\n",
              "       [ -6., -14.],\n",
              "       [-14.,  -1.],\n",
              "       [ -1.,   8.],\n",
              "       [  8.,  13.],\n",
              "       [ 13.,  -6.],\n",
              "       [ -6.,  12.],\n",
              "       [ 12., -12.],\n",
              "       [-12.,  13.],\n",
              "       [ 13., -20.],\n",
              "       [-20.,   0.],\n",
              "       [  0.,  20.],\n",
              "       [ 20., -15.],\n",
              "       [-15.,   9.],\n",
              "       [  9.,   6.],\n",
              "       [  6., -17.],\n",
              "       [-17.,  18.],\n",
              "       [ 18.,  -5.],\n",
              "       [ -5.,  -2.],\n",
              "       [ -2.,   1.],\n",
              "       [  1.,  -7.],\n",
              "       [ -7.,   9.],\n",
              "       [  9., -11.],\n",
              "       [-11.,  -2.],\n",
              "       [ -2.,  17.],\n",
              "       [ 17., -10.],\n",
              "       [-10.,   3.],\n",
              "       [  3.,  -6.],\n",
              "       [ -6.,  -2.],\n",
              "       [ -2.,  -7.],\n",
              "       [ -7.,   5.],\n",
              "       [  5.,  -7.],\n",
              "       [ -7.,  17.],\n",
              "       [ 17., -11.],\n",
              "       [-11.,   2.],\n",
              "       [  2.,  14.],\n",
              "       [ 14.,  -6.],\n",
              "       [ -6.,  -5.],\n",
              "       [ -5.,  -7.],\n",
              "       [ -7.,   7.],\n",
              "       [  7.,   6.],\n",
              "       [  6.,  -2.],\n",
              "       [ -2.,  -4.],\n",
              "       [ -4.,  -8.],\n",
              "       [ -8.,  -4.],\n",
              "       [ -4.,   3.],\n",
              "       [  3.,  12.],\n",
              "       [ 12.,   4.],\n",
              "       [  4.,  -5.],\n",
              "       [ -5.,  -5.],\n",
              "       [ -5.,   9.],\n",
              "       [  9.,   1.],\n",
              "       [  1.,  -3.],\n",
              "       [ -3.,  -5.],\n",
              "       [ -5.,  -4.],\n",
              "       [ -4.,   1.],\n",
              "       [  1.,  21.],\n",
              "       [ 21., -20.],\n",
              "       [-20.,  -4.],\n",
              "       [ -4.,  18.],\n",
              "       [ 18.,  -9.],\n",
              "       [ -9.,  -2.],\n",
              "       [ -2.,   2.],\n",
              "       [  2.,   6.],\n",
              "       [  6., -13.],\n",
              "       [-13.,   2.],\n",
              "       [  2.,  -3.],\n",
              "       [ -3.,   2.],\n",
              "       [  2.,   3.],\n",
              "       [  3.,   0.],\n",
              "       [  0.,  -4.],\n",
              "       [ -4.,  19.],\n",
              "       [ 19., -19.],\n",
              "       [-19.,   0.],\n",
              "       [  0.,   4.],\n",
              "       [  4.,  -3.],\n",
              "       [ -3.,  -3.],\n",
              "       [ -3.,  10.],\n",
              "       [ 10.,  -8.],\n",
              "       [ -8.,  12.],\n",
              "       [ 12., -16.],\n",
              "       [-16.,  16.],\n",
              "       [ 16.,  -1.],\n",
              "       [ -1.,   9.],\n",
              "       [  9., -20.],\n",
              "       [-20.,   3.],\n",
              "       [  3.,  -2.],\n",
              "       [ -2.,   5.],\n",
              "       [  5.,   2.],\n",
              "       [  2.,  16.],\n",
              "       [ 16.,  -7.],\n",
              "       [ -7., -19.],\n",
              "       [-19.,   3.],\n",
              "       [  3.,   3.],\n",
              "       [  3.,  -5.],\n",
              "       [ -5.,   6.],\n",
              "       [  6.,   8.],\n",
              "       [  8.,  -9.],\n",
              "       [ -9.,  14.],\n",
              "       [ 14., -22.],\n",
              "       [-22.,   4.],\n",
              "       [  4.,   6.],\n",
              "       [  6.,  -5.],\n",
              "       [ -5.,   7.],\n",
              "       [  7.,  -1.],\n",
              "       [ -1.,   1.],\n",
              "       [  1.,  -4.],\n",
              "       [ -4., -14.],\n",
              "       [-14.,  10.],\n",
              "       [ 10.,   9.],\n",
              "       [  9.,  -7.],\n",
              "       [ -7.,  19.],\n",
              "       [ 19., -14.],\n",
              "       [-14.,   4.],\n",
              "       [  4.,  -4.],\n",
              "       [ -4.,  -4.],\n",
              "       [ -4.,   6.],\n",
              "       [  6.,  -4.],\n",
              "       [ -4.,  -6.],\n",
              "       [ -6.,  10.],\n",
              "       [ 10.,  -3.],\n",
              "       [ -3.,  -2.],\n",
              "       [ -2.,   7.],\n",
              "       [  7.,   1.],\n",
              "       [  1., -12.],\n",
              "       [-12.,   1.],\n",
              "       [  1.,  13.],\n",
              "       [ 13.,   3.],\n",
              "       [  3., -15.],\n",
              "       [-15.,  -3.],\n",
              "       [ -3.,  13.],\n",
              "       [ 13.,  -4.],\n",
              "       [ -4.,   6.],\n",
              "       [  6., -14.],\n",
              "       [-14.,   7.],\n",
              "       [  7.,  -6.],\n",
              "       [ -6.,   5.],\n",
              "       [  5.,  -6.],\n",
              "       [ -6.,  -4.],\n",
              "       [ -4.,   6.],\n",
              "       [  6.,   4.],\n",
              "       [  4.,  -1.],\n",
              "       [ -1.,   6.],\n",
              "       [  6.,  -7.],\n",
              "       [ -7.,   9.],\n",
              "       [  9., -14.],\n",
              "       [-14.,  -3.],\n",
              "       [ -3.,  12.],\n",
              "       [ 12.,   1.],\n",
              "       [  1.,  -2.],\n",
              "       [ -2.,   0.],\n",
              "       [  0.,  18.],\n",
              "       [ 18., -16.],\n",
              "       [-16.,   2.],\n",
              "       [  2.,  -7.],\n",
              "       [ -7.,  -1.],\n",
              "       [ -1.,   8.],\n",
              "       [  8.,  -3.],\n",
              "       [ -3.,  15.],\n",
              "       [ 15., -11.],\n",
              "       [-11.,   5.],\n",
              "       [  5., -10.],\n",
              "       [-10.,   6.],\n",
              "       [  6., -21.],\n",
              "       [-21.,   9.],\n",
              "       [  9.,   9.],\n",
              "       [  9.,  -3.],\n",
              "       [ -3.,   1.],\n",
              "       [  1.,  -6.],\n",
              "       [ -6.,   9.],\n",
              "       [  9.,   0.],\n",
              "       [  0.,   0.],\n",
              "       [  0.,   2.],\n",
              "       [  2.,  -9.],\n",
              "       [ -9.,   4.],\n",
              "       [  4.,  -7.],\n",
              "       [ -7.,   1.],\n",
              "       [  1.,   3.],\n",
              "       [  3.,   6.],\n",
              "       [  6.,  -2.],\n",
              "       [ -2.,   4.],\n",
              "       [  4., -11.],\n",
              "       [-11.,   5.],\n",
              "       [  5.,   9.],\n",
              "       [  9., -11.],\n",
              "       [-11.,   2.],\n",
              "       [  2.,   5.],\n",
              "       [  5.,  18.],\n",
              "       [ 18., -19.],\n",
              "       [-19., -11.],\n",
              "       [-11.,   4.],\n",
              "       [  4.,   6.],\n",
              "       [  6.,   4.],\n",
              "       [  4.,  -2.],\n",
              "       [ -2.,  -2.],\n",
              "       [ -2.,  -7.],\n",
              "       [ -7.,   2.],\n",
              "       [  2.,   5.],\n",
              "       [  5.,   1.],\n",
              "       [  1., -12.],\n",
              "       [-12.,  11.],\n",
              "       [ 11.,  -6.],\n",
              "       [ -6.,   8.],\n",
              "       [  8.,   0.],\n",
              "       [  0.,  -6.],\n",
              "       [ -6.,  -1.],\n",
              "       [ -1.,   5.],\n",
              "       [  5.,   4.],\n",
              "       [  4.,   2.],\n",
              "       [  2.,  -9.],\n",
              "       [ -9.,   1.],\n",
              "       [  1.,   9.],\n",
              "       [  9., -10.],\n",
              "       [-10.,   3.],\n",
              "       [  3.,  -6.],\n",
              "       [ -6.,  30.],\n",
              "       [ 30., -28.],\n",
              "       [-28.,   2.],\n",
              "       [  2.,   9.],\n",
              "       [  9.,  -7.],\n",
              "       [ -7.,   1.],\n",
              "       [  1.,  -9.],\n",
              "       [ -9.,  21.],\n",
              "       [ 21., -13.],\n",
              "       [-13.,  -2.],\n",
              "       [ -2.,  11.],\n",
              "       [ 11., -11.],\n",
              "       [-11.,  -8.],\n",
              "       [ -8.,   6.],\n",
              "       [  6.,  16.],\n",
              "       [ 16., -12.],\n",
              "       [-12.,   9.],\n",
              "       [  9.,   2.],\n",
              "       [  2., -16.],\n",
              "       [-16.,  20.],\n",
              "       [ 20.,  -4.],\n",
              "       [ -4.,  18.],\n",
              "       [ 18., -18.],\n",
              "       [-18., -11.],\n",
              "       [-11.,  -1.],\n",
              "       [ -1.,  -3.],\n",
              "       [ -3.,   7.],\n",
              "       [  7.,   4.],\n",
              "       [  4.,   5.],\n",
              "       [  5.,  -7.],\n",
              "       [ -7.,   5.],\n",
              "       [  5.,   2.],\n",
              "       [  2.,  -9.],\n",
              "       [ -9.,  -3.],\n",
              "       [ -3.,  -1.],\n",
              "       [ -1.,  -1.],\n",
              "       [ -1.,   3.],\n",
              "       [  3.,   5.],\n",
              "       [  5.,  -2.],\n",
              "       [ -2.,  -5.],\n",
              "       [ -5.,  -3.],\n",
              "       [ -3.,  19.],\n",
              "       [ 19., -18.],\n",
              "       [-18.,   1.],\n",
              "       [  1.,   9.],\n",
              "       [  9.,  -2.],\n",
              "       [ -2.,  -4.],\n",
              "       [ -4.,  -2.],\n",
              "       [ -2.,  -1.],\n",
              "       [ -1.,  -4.],\n",
              "       [ -4.,   9.],\n",
              "       [  9.,  -9.],\n",
              "       [ -9.,  -2.],\n",
              "       [ -2.,   6.],\n",
              "       [  6.,  -7.],\n",
              "       [ -7.,  -7.],\n",
              "       [ -7.,  16.],\n",
              "       [ 16.,  -8.],\n",
              "       [ -8.,   9.],\n",
              "       [  9.,   1.],\n",
              "       [  1.,   2.],\n",
              "       [  2.,   1.],\n",
              "       [  1.,  -6.],\n",
              "       [ -6.,  -1.],\n",
              "       [ -1.,  17.],\n",
              "       [ 17., -14.],\n",
              "       [-14.,   7.],\n",
              "       [  7.,  -6.],\n",
              "       [ -6.,  -4.],\n",
              "       [ -4.,  -2.],\n",
              "       [ -2.,   0.],\n",
              "       [  0.,   5.],\n",
              "       [  5., -10.],\n",
              "       [-10.,   0.],\n",
              "       [  0.,   5.],\n",
              "       [  5.,  -1.],\n",
              "       [ -1.,  -6.],\n",
              "       [ -6.,   9.],\n",
              "       [  9.,   5.],\n",
              "       [  5.,   4.],\n",
              "       [  4.,  -7.],\n",
              "       [ -7.,  -4.],\n",
              "       [ -4.,  17.],\n",
              "       [ 17.,  -8.],\n",
              "       [ -8.,  -4.],\n",
              "       [ -4.,   4.],\n",
              "       [  4.,   2.],\n",
              "       [  2.,  -5.],\n",
              "       [ -5.,  -2.],\n",
              "       [ -2.,   8.],\n",
              "       [  8.,  -7.],\n",
              "       [ -7., -13.],\n",
              "       [-13.,  14.],\n",
              "       [ 14.,  -5.],\n",
              "       [ -5.,  -7.],\n",
              "       [ -7.,  -1.],\n",
              "       [ -1.,   3.],\n",
              "       [  3.,  13.],\n",
              "       [ 13.,  -6.],\n",
              "       [ -6.,   0.],\n",
              "       [  0.,  -9.],\n",
              "       [ -9.,   5.],\n",
              "       [  5.,  -4.],\n",
              "       [ -4.,  17.],\n",
              "       [ 17.,  -5.],\n",
              "       [ -5.,   5.],\n",
              "       [  5., -13.],\n",
              "       [-13.,   1.],\n",
              "       [  1.,   2.],\n",
              "       [  2.,   0.],\n",
              "       [  0.,  11.],\n",
              "       [ 11., -14.],\n",
              "       [-14.,   1.],\n",
              "       [  1.,  -2.],\n",
              "       [ -2.,   6.],\n",
              "       [  6., -10.],\n",
              "       [-10.,   3.],\n",
              "       [  3.,  15.],\n",
              "       [ 15.,  -4.],\n",
              "       [ -4.,   7.],\n",
              "       [  7.,  -5.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJGGJcierYlr"
      },
      "source": [
        "split_percentage = 0.75\n",
        "\n",
        "train_size = int(split_percentage * len(supervised_values))\n",
        "\n",
        "train, test = supervised_values[0:train_size], supervised_values[train_size:len(supervised_values)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIs6IWuzrYlt"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(-1, 1)) # Range hasil scaling menjadi angka diantara -1 hingga 1\n",
        "scaler = scaler.fit(train)\n",
        "\n",
        "train_scaled = scaler.transform(train)\n",
        "test_scaled = scaler.transform(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QT5je_sNrYlw",
        "outputId": "d0cf1985-cb7d-4c56-9c10-35e1218e935e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_scaled"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.37931034e-01, -1.03448276e-01],\n",
              "       [-1.03448276e-01, -6.93889390e-17],\n",
              "       [-6.93889390e-17,  4.13793103e-01],\n",
              "       [ 4.13793103e-01, -5.51724138e-01],\n",
              "       [-5.51724138e-01,  5.17241379e-01],\n",
              "       [ 5.17241379e-01, -1.03448276e-01],\n",
              "       [-1.03448276e-01, -2.06896552e-01],\n",
              "       [-2.06896552e-01, -4.13793103e-01],\n",
              "       [-4.13793103e-01,  3.44827586e-01],\n",
              "       [ 3.44827586e-01, -2.06896552e-01],\n",
              "       [-2.06896552e-01,  7.24137931e-01],\n",
              "       [ 7.24137931e-01, -3.10344828e-01],\n",
              "       [-3.10344828e-01, -1.03448276e-01],\n",
              "       [-1.03448276e-01, -3.10344828e-01],\n",
              "       [-3.10344828e-01,  4.13793103e-01],\n",
              "       [ 4.13793103e-01, -2.75862069e-01],\n",
              "       [-2.75862069e-01, -1.03448276e-01],\n",
              "       [-1.03448276e-01,  3.44827586e-01],\n",
              "       [ 3.44827586e-01, -6.55172414e-01],\n",
              "       [-6.55172414e-01,  6.20689655e-01],\n",
              "       [ 6.20689655e-01, -5.17241379e-01],\n",
              "       [-5.17241379e-01, -2.75862069e-01],\n",
              "       [-2.75862069e-01,  1.37931034e-01],\n",
              "       [ 1.37931034e-01,  1.72413793e-01],\n",
              "       [ 1.72413793e-01, -1.72413793e-01],\n",
              "       [-1.72413793e-01, -1.72413793e-01],\n",
              "       [-1.72413793e-01,  2.75862069e-01],\n",
              "       [ 2.75862069e-01, -2.41379310e-01],\n",
              "       [-2.41379310e-01, -5.17241379e-01],\n",
              "       [-5.17241379e-01, -6.89655172e-02],\n",
              "       [-6.89655172e-02,  2.41379310e-01],\n",
              "       [ 2.41379310e-01,  4.13793103e-01],\n",
              "       [ 4.13793103e-01, -2.41379310e-01],\n",
              "       [-2.41379310e-01,  3.79310345e-01],\n",
              "       [ 3.79310345e-01, -4.48275862e-01],\n",
              "       [-4.48275862e-01,  4.13793103e-01],\n",
              "       [ 4.13793103e-01, -7.24137931e-01],\n",
              "       [-7.24137931e-01, -3.44827586e-02],\n",
              "       [-3.44827586e-02,  6.55172414e-01],\n",
              "       [ 6.55172414e-01, -5.51724138e-01],\n",
              "       [-5.51724138e-01,  2.75862069e-01],\n",
              "       [ 2.75862069e-01,  1.72413793e-01],\n",
              "       [ 1.72413793e-01, -6.20689655e-01],\n",
              "       [-6.20689655e-01,  5.86206897e-01],\n",
              "       [ 5.86206897e-01, -2.06896552e-01],\n",
              "       [-2.06896552e-01, -1.03448276e-01],\n",
              "       [-1.03448276e-01, -6.93889390e-17],\n",
              "       [-6.93889390e-17, -2.75862069e-01],\n",
              "       [-2.75862069e-01,  2.75862069e-01],\n",
              "       [ 2.75862069e-01, -4.13793103e-01],\n",
              "       [-4.13793103e-01, -1.03448276e-01],\n",
              "       [-1.03448276e-01,  5.51724138e-01],\n",
              "       [ 5.51724138e-01, -3.79310345e-01],\n",
              "       [-3.79310345e-01,  6.89655172e-02],\n",
              "       [ 6.89655172e-02, -2.41379310e-01],\n",
              "       [-2.41379310e-01, -1.03448276e-01],\n",
              "       [-1.03448276e-01, -2.75862069e-01],\n",
              "       [-2.75862069e-01,  1.37931034e-01],\n",
              "       [ 1.37931034e-01, -2.75862069e-01],\n",
              "       [-2.75862069e-01,  5.51724138e-01],\n",
              "       [ 5.51724138e-01, -4.13793103e-01],\n",
              "       [-4.13793103e-01,  3.44827586e-02],\n",
              "       [ 3.44827586e-02,  4.48275862e-01],\n",
              "       [ 4.48275862e-01, -2.41379310e-01],\n",
              "       [-2.41379310e-01, -2.06896552e-01],\n",
              "       [-2.06896552e-01, -2.75862069e-01],\n",
              "       [-2.75862069e-01,  2.06896552e-01],\n",
              "       [ 2.06896552e-01,  1.72413793e-01],\n",
              "       [ 1.72413793e-01, -1.03448276e-01],\n",
              "       [-1.03448276e-01, -1.72413793e-01],\n",
              "       [-1.72413793e-01, -3.10344828e-01],\n",
              "       [-3.10344828e-01, -1.72413793e-01],\n",
              "       [-1.72413793e-01,  6.89655172e-02],\n",
              "       [ 6.89655172e-02,  3.79310345e-01],\n",
              "       [ 3.79310345e-01,  1.03448276e-01],\n",
              "       [ 1.03448276e-01, -2.06896552e-01],\n",
              "       [-2.06896552e-01, -2.06896552e-01],\n",
              "       [-2.06896552e-01,  2.75862069e-01],\n",
              "       [ 2.75862069e-01, -6.93889390e-17],\n",
              "       [-6.93889390e-17, -1.37931034e-01],\n",
              "       [-1.37931034e-01, -2.06896552e-01],\n",
              "       [-2.06896552e-01, -1.72413793e-01],\n",
              "       [-1.72413793e-01, -6.93889390e-17],\n",
              "       [-6.93889390e-17,  6.89655172e-01],\n",
              "       [ 6.89655172e-01, -7.24137931e-01],\n",
              "       [-7.24137931e-01, -1.72413793e-01],\n",
              "       [-1.72413793e-01,  5.86206897e-01],\n",
              "       [ 5.86206897e-01, -3.44827586e-01],\n",
              "       [-3.44827586e-01, -1.03448276e-01],\n",
              "       [-1.03448276e-01,  3.44827586e-02],\n",
              "       [ 3.44827586e-02,  1.72413793e-01],\n",
              "       [ 1.72413793e-01, -4.82758621e-01],\n",
              "       [-4.82758621e-01,  3.44827586e-02],\n",
              "       [ 3.44827586e-02, -1.37931034e-01],\n",
              "       [-1.37931034e-01,  3.44827586e-02],\n",
              "       [ 3.44827586e-02,  6.89655172e-02],\n",
              "       [ 6.89655172e-02, -3.44827586e-02],\n",
              "       [-3.44827586e-02, -1.72413793e-01],\n",
              "       [-1.72413793e-01,  6.20689655e-01],\n",
              "       [ 6.20689655e-01, -6.89655172e-01],\n",
              "       [-6.89655172e-01, -3.44827586e-02],\n",
              "       [-3.44827586e-02,  1.03448276e-01],\n",
              "       [ 1.03448276e-01, -1.37931034e-01],\n",
              "       [-1.37931034e-01, -1.37931034e-01],\n",
              "       [-1.37931034e-01,  3.10344828e-01],\n",
              "       [ 3.10344828e-01, -3.10344828e-01],\n",
              "       [-3.10344828e-01,  3.79310345e-01],\n",
              "       [ 3.79310345e-01, -5.86206897e-01],\n",
              "       [-5.86206897e-01,  5.17241379e-01],\n",
              "       [ 5.17241379e-01, -6.89655172e-02],\n",
              "       [-6.89655172e-02,  2.75862069e-01],\n",
              "       [ 2.75862069e-01, -7.24137931e-01],\n",
              "       [-7.24137931e-01,  6.89655172e-02],\n",
              "       [ 6.89655172e-02, -1.03448276e-01],\n",
              "       [-1.03448276e-01,  1.37931034e-01],\n",
              "       [ 1.37931034e-01,  3.44827586e-02],\n",
              "       [ 3.44827586e-02,  5.17241379e-01],\n",
              "       [ 5.17241379e-01, -2.75862069e-01],\n",
              "       [-2.75862069e-01, -6.89655172e-01],\n",
              "       [-6.89655172e-01,  6.89655172e-02],\n",
              "       [ 6.89655172e-02,  6.89655172e-02],\n",
              "       [ 6.89655172e-02, -2.06896552e-01],\n",
              "       [-2.06896552e-01,  1.72413793e-01],\n",
              "       [ 1.72413793e-01,  2.41379310e-01],\n",
              "       [ 2.41379310e-01, -3.44827586e-01],\n",
              "       [-3.44827586e-01,  4.48275862e-01],\n",
              "       [ 4.48275862e-01, -7.93103448e-01],\n",
              "       [-7.93103448e-01,  1.03448276e-01],\n",
              "       [ 1.03448276e-01,  1.72413793e-01],\n",
              "       [ 1.72413793e-01, -2.06896552e-01],\n",
              "       [-2.06896552e-01,  2.06896552e-01],\n",
              "       [ 2.06896552e-01, -6.89655172e-02],\n",
              "       [-6.89655172e-02, -6.93889390e-17],\n",
              "       [-6.93889390e-17, -1.72413793e-01],\n",
              "       [-1.72413793e-01, -5.17241379e-01],\n",
              "       [-5.17241379e-01,  3.10344828e-01],\n",
              "       [ 3.10344828e-01,  2.75862069e-01],\n",
              "       [ 2.75862069e-01, -2.75862069e-01],\n",
              "       [-2.75862069e-01,  6.20689655e-01],\n",
              "       [ 6.20689655e-01, -5.17241379e-01],\n",
              "       [-5.17241379e-01,  1.03448276e-01],\n",
              "       [ 1.03448276e-01, -1.72413793e-01],\n",
              "       [-1.72413793e-01, -1.72413793e-01],\n",
              "       [-1.72413793e-01,  1.72413793e-01],\n",
              "       [ 1.72413793e-01, -1.72413793e-01],\n",
              "       [-1.72413793e-01, -2.41379310e-01],\n",
              "       [-2.41379310e-01,  3.10344828e-01],\n",
              "       [ 3.10344828e-01, -1.37931034e-01],\n",
              "       [-1.37931034e-01, -1.03448276e-01],\n",
              "       [-1.03448276e-01,  2.06896552e-01],\n",
              "       [ 2.06896552e-01, -6.93889390e-17],\n",
              "       [-6.93889390e-17, -4.48275862e-01],\n",
              "       [-4.48275862e-01, -6.93889390e-17],\n",
              "       [-6.93889390e-17,  4.13793103e-01],\n",
              "       [ 4.13793103e-01,  6.89655172e-02],\n",
              "       [ 6.89655172e-02, -5.51724138e-01],\n",
              "       [-5.51724138e-01, -1.37931034e-01],\n",
              "       [-1.37931034e-01,  4.13793103e-01],\n",
              "       [ 4.13793103e-01, -1.72413793e-01],\n",
              "       [-1.72413793e-01,  1.72413793e-01],\n",
              "       [ 1.72413793e-01, -5.17241379e-01],\n",
              "       [-5.17241379e-01,  2.06896552e-01],\n",
              "       [ 2.06896552e-01, -2.41379310e-01],\n",
              "       [-2.41379310e-01,  1.37931034e-01],\n",
              "       [ 1.37931034e-01, -2.41379310e-01],\n",
              "       [-2.41379310e-01, -1.72413793e-01],\n",
              "       [-1.72413793e-01,  1.72413793e-01],\n",
              "       [ 1.72413793e-01,  1.03448276e-01],\n",
              "       [ 1.03448276e-01, -6.89655172e-02],\n",
              "       [-6.89655172e-02,  1.72413793e-01],\n",
              "       [ 1.72413793e-01, -2.75862069e-01],\n",
              "       [-2.75862069e-01,  2.75862069e-01],\n",
              "       [ 2.75862069e-01, -5.17241379e-01],\n",
              "       [-5.17241379e-01, -1.37931034e-01],\n",
              "       [-1.37931034e-01,  3.79310345e-01],\n",
              "       [ 3.79310345e-01, -6.93889390e-17],\n",
              "       [-6.93889390e-17, -1.03448276e-01],\n",
              "       [-1.03448276e-01, -3.44827586e-02],\n",
              "       [-3.44827586e-02,  5.86206897e-01],\n",
              "       [ 5.86206897e-01, -5.86206897e-01],\n",
              "       [-5.86206897e-01,  3.44827586e-02],\n",
              "       [ 3.44827586e-02, -2.75862069e-01],\n",
              "       [-2.75862069e-01, -6.89655172e-02],\n",
              "       [-6.89655172e-02,  2.41379310e-01],\n",
              "       [ 2.41379310e-01, -1.37931034e-01],\n",
              "       [-1.37931034e-01,  4.82758621e-01],\n",
              "       [ 4.82758621e-01, -4.13793103e-01],\n",
              "       [-4.13793103e-01,  1.37931034e-01],\n",
              "       [ 1.37931034e-01, -3.79310345e-01],\n",
              "       [-3.79310345e-01,  1.72413793e-01],\n",
              "       [ 1.72413793e-01, -7.58620690e-01],\n",
              "       [-7.58620690e-01,  2.75862069e-01],\n",
              "       [ 2.75862069e-01,  2.75862069e-01],\n",
              "       [ 2.75862069e-01, -1.37931034e-01],\n",
              "       [-1.37931034e-01, -6.93889390e-17],\n",
              "       [-6.93889390e-17, -2.41379310e-01],\n",
              "       [-2.41379310e-01,  2.75862069e-01],\n",
              "       [ 2.75862069e-01, -3.44827586e-02],\n",
              "       [-3.44827586e-02, -3.44827586e-02],\n",
              "       [-3.44827586e-02,  3.44827586e-02],\n",
              "       [ 3.44827586e-02, -3.44827586e-01],\n",
              "       [-3.44827586e-01,  1.03448276e-01],\n",
              "       [ 1.03448276e-01, -2.75862069e-01],\n",
              "       [-2.75862069e-01, -6.93889390e-17],\n",
              "       [-6.93889390e-17,  6.89655172e-02],\n",
              "       [ 6.89655172e-02,  1.72413793e-01],\n",
              "       [ 1.72413793e-01, -1.03448276e-01],\n",
              "       [-1.03448276e-01,  1.03448276e-01],\n",
              "       [ 1.03448276e-01, -4.13793103e-01],\n",
              "       [-4.13793103e-01,  1.37931034e-01],\n",
              "       [ 1.37931034e-01,  2.75862069e-01],\n",
              "       [ 2.75862069e-01, -4.13793103e-01],\n",
              "       [-4.13793103e-01,  3.44827586e-02],\n",
              "       [ 3.44827586e-02,  1.37931034e-01],\n",
              "       [ 1.37931034e-01,  5.86206897e-01],\n",
              "       [ 5.86206897e-01, -6.89655172e-01],\n",
              "       [-6.89655172e-01, -4.13793103e-01],\n",
              "       [-4.13793103e-01,  1.03448276e-01],\n",
              "       [ 1.03448276e-01,  1.72413793e-01],\n",
              "       [ 1.72413793e-01,  1.03448276e-01],\n",
              "       [ 1.03448276e-01, -1.03448276e-01],\n",
              "       [-1.03448276e-01, -1.03448276e-01],\n",
              "       [-1.03448276e-01, -2.75862069e-01],\n",
              "       [-2.75862069e-01,  3.44827586e-02],\n",
              "       [ 3.44827586e-02,  1.37931034e-01],\n",
              "       [ 1.37931034e-01, -6.93889390e-17],\n",
              "       [-6.93889390e-17, -4.48275862e-01],\n",
              "       [-4.48275862e-01,  3.44827586e-01],\n",
              "       [ 3.44827586e-01, -2.41379310e-01],\n",
              "       [-2.41379310e-01,  2.41379310e-01],\n",
              "       [ 2.41379310e-01, -3.44827586e-02],\n",
              "       [-3.44827586e-02, -2.41379310e-01],\n",
              "       [-2.41379310e-01, -6.89655172e-02],\n",
              "       [-6.89655172e-02,  1.37931034e-01],\n",
              "       [ 1.37931034e-01,  1.03448276e-01],\n",
              "       [ 1.03448276e-01,  3.44827586e-02],\n",
              "       [ 3.44827586e-02, -3.44827586e-01],\n",
              "       [-3.44827586e-01, -6.93889390e-17],\n",
              "       [-6.93889390e-17,  2.75862069e-01],\n",
              "       [ 2.75862069e-01, -3.79310345e-01],\n",
              "       [-3.79310345e-01,  6.89655172e-02],\n",
              "       [ 6.89655172e-02, -2.41379310e-01],\n",
              "       [-2.41379310e-01,  1.00000000e+00],\n",
              "       [ 1.00000000e+00, -1.00000000e+00],\n",
              "       [-1.00000000e+00,  3.44827586e-02],\n",
              "       [ 3.44827586e-02,  2.75862069e-01],\n",
              "       [ 2.75862069e-01, -2.75862069e-01],\n",
              "       [-2.75862069e-01, -6.93889390e-17],\n",
              "       [-6.93889390e-17, -3.44827586e-01],\n",
              "       [-3.44827586e-01,  6.89655172e-01],\n",
              "       [ 6.89655172e-01, -4.82758621e-01],\n",
              "       [-4.82758621e-01, -1.03448276e-01],\n",
              "       [-1.03448276e-01,  3.44827586e-01],\n",
              "       [ 3.44827586e-01, -4.13793103e-01],\n",
              "       [-4.13793103e-01, -3.10344828e-01],\n",
              "       [-3.10344828e-01,  1.72413793e-01],\n",
              "       [ 1.72413793e-01,  5.17241379e-01],\n",
              "       [ 5.17241379e-01, -4.48275862e-01],\n",
              "       [-4.48275862e-01,  2.75862069e-01],\n",
              "       [ 2.75862069e-01,  3.44827586e-02],\n",
              "       [ 3.44827586e-02, -5.86206897e-01],\n",
              "       [-5.86206897e-01,  6.55172414e-01],\n",
              "       [ 6.55172414e-01, -1.72413793e-01],\n",
              "       [-1.72413793e-01,  5.86206897e-01],\n",
              "       [ 5.86206897e-01, -6.55172414e-01],\n",
              "       [-6.55172414e-01, -4.13793103e-01],\n",
              "       [-4.13793103e-01, -6.89655172e-02],\n",
              "       [-6.89655172e-02, -1.37931034e-01],\n",
              "       [-1.37931034e-01,  2.06896552e-01],\n",
              "       [ 2.06896552e-01,  1.03448276e-01],\n",
              "       [ 1.03448276e-01,  1.37931034e-01],\n",
              "       [ 1.37931034e-01, -2.75862069e-01]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAHQCzVy7sT1"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyf48MmwrYly"
      },
      "source": [
        "### Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBOlM8xdrYlz",
        "outputId": "1e7057ad-fca2-4f96-a8e9-b3b34aaba4b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "neurons = 1\n",
        "epoch = 1000\n",
        "batch_size = 32\n",
        "\n",
        "feature_train, label_train = train_scaled[:, 0:-1], train_scaled[:, -1]\n",
        "feature_test, label_test = test_scaled[:, 0:-1], test_scaled[:, -1]\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(Dense(neurons, activation='relu', input_dim=feature_train.shape[1]))\n",
        "model2.add(Dense(1))\n",
        "model2.compile(loss='mean_squared_error', optimizer='adam')\n",
        "history2 = model2.fit(feature_train, label_train, epochs=epoch, batch_size=batch_size, validation_data=(feature_test, label_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.1643 - val_loss: 0.1065\n",
            "Epoch 2/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1576 - val_loss: 0.1009\n",
            "Epoch 3/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1503 - val_loss: 0.0964\n",
            "Epoch 4/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1453 - val_loss: 0.0921\n",
            "Epoch 5/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1397 - val_loss: 0.0886\n",
            "Epoch 6/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1358 - val_loss: 0.0854\n",
            "Epoch 7/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1316 - val_loss: 0.0829\n",
            "Epoch 8/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1282 - val_loss: 0.0806\n",
            "Epoch 9/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1253 - val_loss: 0.0788\n",
            "Epoch 10/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1229 - val_loss: 0.0772\n",
            "Epoch 11/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1208 - val_loss: 0.0759\n",
            "Epoch 12/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1190 - val_loss: 0.0750\n",
            "Epoch 13/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1174 - val_loss: 0.0741\n",
            "Epoch 14/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1161 - val_loss: 0.0734\n",
            "Epoch 15/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1151 - val_loss: 0.0729\n",
            "Epoch 16/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1140 - val_loss: 0.0725\n",
            "Epoch 17/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1133 - val_loss: 0.0721\n",
            "Epoch 18/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1126 - val_loss: 0.0718\n",
            "Epoch 19/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1120 - val_loss: 0.0716\n",
            "Epoch 20/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1113 - val_loss: 0.0714\n",
            "Epoch 21/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1109 - val_loss: 0.0712\n",
            "Epoch 22/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1105 - val_loss: 0.0711\n",
            "Epoch 23/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1101 - val_loss: 0.0710\n",
            "Epoch 24/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1098 - val_loss: 0.0710\n",
            "Epoch 25/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1096 - val_loss: 0.0709\n",
            "Epoch 26/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1094 - val_loss: 0.0709\n",
            "Epoch 27/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1091 - val_loss: 0.0708\n",
            "Epoch 28/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1089 - val_loss: 0.0707\n",
            "Epoch 29/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1087 - val_loss: 0.0707\n",
            "Epoch 30/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1086 - val_loss: 0.0706\n",
            "Epoch 31/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1084 - val_loss: 0.0706\n",
            "Epoch 32/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1083 - val_loss: 0.0705\n",
            "Epoch 33/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1081 - val_loss: 0.0705\n",
            "Epoch 34/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1080 - val_loss: 0.0705\n",
            "Epoch 35/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1079 - val_loss: 0.0704\n",
            "Epoch 36/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1077 - val_loss: 0.0703\n",
            "Epoch 37/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1076 - val_loss: 0.0702\n",
            "Epoch 38/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1075 - val_loss: 0.0702\n",
            "Epoch 39/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1074 - val_loss: 0.0701\n",
            "Epoch 40/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1072 - val_loss: 0.0700\n",
            "Epoch 41/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1071 - val_loss: 0.0700\n",
            "Epoch 42/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1070 - val_loss: 0.0699\n",
            "Epoch 43/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1069 - val_loss: 0.0699\n",
            "Epoch 44/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1068 - val_loss: 0.0698\n",
            "Epoch 45/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1067 - val_loss: 0.0697\n",
            "Epoch 46/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1065 - val_loss: 0.0696\n",
            "Epoch 47/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1065 - val_loss: 0.0696\n",
            "Epoch 48/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1063 - val_loss: 0.0695\n",
            "Epoch 49/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1062 - val_loss: 0.0694\n",
            "Epoch 50/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1061 - val_loss: 0.0693\n",
            "Epoch 51/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1059 - val_loss: 0.0691\n",
            "Epoch 52/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1058 - val_loss: 0.0691\n",
            "Epoch 53/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1057 - val_loss: 0.0689\n",
            "Epoch 54/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1056 - val_loss: 0.0689\n",
            "Epoch 55/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1054 - val_loss: 0.0688\n",
            "Epoch 56/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1053 - val_loss: 0.0686\n",
            "Epoch 57/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1052 - val_loss: 0.0686\n",
            "Epoch 58/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1051 - val_loss: 0.0685\n",
            "Epoch 59/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1049 - val_loss: 0.0684\n",
            "Epoch 60/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1048 - val_loss: 0.0683\n",
            "Epoch 61/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1047 - val_loss: 0.0682\n",
            "Epoch 62/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1046 - val_loss: 0.0682\n",
            "Epoch 63/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1045 - val_loss: 0.0681\n",
            "Epoch 64/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1044 - val_loss: 0.0680\n",
            "Epoch 65/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1043 - val_loss: 0.0680\n",
            "Epoch 66/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1041 - val_loss: 0.0679\n",
            "Epoch 67/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1040 - val_loss: 0.0678\n",
            "Epoch 68/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1039 - val_loss: 0.0677\n",
            "Epoch 69/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.0676\n",
            "Epoch 70/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1037 - val_loss: 0.0675\n",
            "Epoch 71/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1036 - val_loss: 0.0674\n",
            "Epoch 72/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1034 - val_loss: 0.0673\n",
            "Epoch 73/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1033 - val_loss: 0.0672\n",
            "Epoch 74/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1032 - val_loss: 0.0671\n",
            "Epoch 75/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1031 - val_loss: 0.0670\n",
            "Epoch 76/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1030 - val_loss: 0.0669\n",
            "Epoch 77/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1028 - val_loss: 0.0668\n",
            "Epoch 78/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1027 - val_loss: 0.0667\n",
            "Epoch 79/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1026 - val_loss: 0.0666\n",
            "Epoch 80/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1025 - val_loss: 0.0665\n",
            "Epoch 81/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1023 - val_loss: 0.0664\n",
            "Epoch 82/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1022 - val_loss: 0.0664\n",
            "Epoch 83/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1021 - val_loss: 0.0663\n",
            "Epoch 84/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1020 - val_loss: 0.0662\n",
            "Epoch 85/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1019 - val_loss: 0.0661\n",
            "Epoch 86/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1018 - val_loss: 0.0660\n",
            "Epoch 87/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1016 - val_loss: 0.0658\n",
            "Epoch 88/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1015 - val_loss: 0.0657\n",
            "Epoch 89/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1014 - val_loss: 0.0656\n",
            "Epoch 90/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1013 - val_loss: 0.0655\n",
            "Epoch 91/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1011 - val_loss: 0.0654\n",
            "Epoch 92/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1010 - val_loss: 0.0653\n",
            "Epoch 93/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1009 - val_loss: 0.0652\n",
            "Epoch 94/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1008 - val_loss: 0.0652\n",
            "Epoch 95/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1007 - val_loss: 0.0651\n",
            "Epoch 96/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0650\n",
            "Epoch 97/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1005 - val_loss: 0.0649\n",
            "Epoch 98/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1003 - val_loss: 0.0648\n",
            "Epoch 99/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1002 - val_loss: 0.0647\n",
            "Epoch 100/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1001 - val_loss: 0.0646\n",
            "Epoch 101/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0999 - val_loss: 0.0646\n",
            "Epoch 102/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0998 - val_loss: 0.0645\n",
            "Epoch 103/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0997 - val_loss: 0.0644\n",
            "Epoch 104/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0995 - val_loss: 0.0644\n",
            "Epoch 105/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0994 - val_loss: 0.0643\n",
            "Epoch 106/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0993 - val_loss: 0.0642\n",
            "Epoch 107/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0991 - val_loss: 0.0641\n",
            "Epoch 108/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0990 - val_loss: 0.0640\n",
            "Epoch 109/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0989 - val_loss: 0.0638\n",
            "Epoch 110/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0988 - val_loss: 0.0637\n",
            "Epoch 111/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0987 - val_loss: 0.0636\n",
            "Epoch 112/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0986 - val_loss: 0.0635\n",
            "Epoch 113/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0984 - val_loss: 0.0634\n",
            "Epoch 114/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0633\n",
            "Epoch 115/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0982 - val_loss: 0.0632\n",
            "Epoch 116/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0981 - val_loss: 0.0631\n",
            "Epoch 117/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0980 - val_loss: 0.0629\n",
            "Epoch 118/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0979 - val_loss: 0.0628\n",
            "Epoch 119/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0978 - val_loss: 0.0627\n",
            "Epoch 120/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0976 - val_loss: 0.0626\n",
            "Epoch 121/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0625\n",
            "Epoch 122/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0974 - val_loss: 0.0624\n",
            "Epoch 123/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0973 - val_loss: 0.0623\n",
            "Epoch 124/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0972 - val_loss: 0.0622\n",
            "Epoch 125/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0971 - val_loss: 0.0621\n",
            "Epoch 126/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0970 - val_loss: 0.0620\n",
            "Epoch 127/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0969 - val_loss: 0.0619\n",
            "Epoch 128/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0618\n",
            "Epoch 129/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0967 - val_loss: 0.0617\n",
            "Epoch 130/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0966 - val_loss: 0.0616\n",
            "Epoch 131/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.0615\n",
            "Epoch 132/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0963 - val_loss: 0.0614\n",
            "Epoch 133/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0962 - val_loss: 0.0613\n",
            "Epoch 134/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0960 - val_loss: 0.0612\n",
            "Epoch 135/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0959 - val_loss: 0.0611\n",
            "Epoch 136/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0958 - val_loss: 0.0610\n",
            "Epoch 137/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0957 - val_loss: 0.0609\n",
            "Epoch 138/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0956 - val_loss: 0.0608\n",
            "Epoch 139/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0955 - val_loss: 0.0608\n",
            "Epoch 140/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0953 - val_loss: 0.0607\n",
            "Epoch 141/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0953 - val_loss: 0.0606\n",
            "Epoch 142/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.0605\n",
            "Epoch 143/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0950 - val_loss: 0.0605\n",
            "Epoch 144/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0949 - val_loss: 0.0604\n",
            "Epoch 145/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0948 - val_loss: 0.0604\n",
            "Epoch 146/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0947 - val_loss: 0.0603\n",
            "Epoch 147/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0947 - val_loss: 0.0602\n",
            "Epoch 148/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0946 - val_loss: 0.0602\n",
            "Epoch 149/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0945 - val_loss: 0.0601\n",
            "Epoch 150/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0944 - val_loss: 0.0600\n",
            "Epoch 151/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0942 - val_loss: 0.0600\n",
            "Epoch 152/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0942 - val_loss: 0.0599\n",
            "Epoch 153/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0941 - val_loss: 0.0599\n",
            "Epoch 154/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0940 - val_loss: 0.0598\n",
            "Epoch 155/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0938 - val_loss: 0.0598\n",
            "Epoch 156/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0937 - val_loss: 0.0597\n",
            "Epoch 157/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0936 - val_loss: 0.0597\n",
            "Epoch 158/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0936 - val_loss: 0.0596\n",
            "Epoch 159/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0934 - val_loss: 0.0596\n",
            "Epoch 160/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0933 - val_loss: 0.0596\n",
            "Epoch 161/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0932 - val_loss: 0.0595\n",
            "Epoch 162/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0931 - val_loss: 0.0595\n",
            "Epoch 163/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0930 - val_loss: 0.0594\n",
            "Epoch 164/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0929 - val_loss: 0.0594\n",
            "Epoch 165/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0928 - val_loss: 0.0593\n",
            "Epoch 166/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0927 - val_loss: 0.0593\n",
            "Epoch 167/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0926 - val_loss: 0.0592\n",
            "Epoch 168/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0926 - val_loss: 0.0592\n",
            "Epoch 169/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0924 - val_loss: 0.0591\n",
            "Epoch 170/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0923 - val_loss: 0.0591\n",
            "Epoch 171/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0923 - val_loss: 0.0590\n",
            "Epoch 172/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0922 - val_loss: 0.0590\n",
            "Epoch 173/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0921 - val_loss: 0.0589\n",
            "Epoch 174/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0920 - val_loss: 0.0589\n",
            "Epoch 175/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0919 - val_loss: 0.0588\n",
            "Epoch 176/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0918 - val_loss: 0.0588\n",
            "Epoch 177/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0918 - val_loss: 0.0587\n",
            "Epoch 178/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0917 - val_loss: 0.0587\n",
            "Epoch 179/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0916 - val_loss: 0.0587\n",
            "Epoch 180/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0915 - val_loss: 0.0586\n",
            "Epoch 181/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0914 - val_loss: 0.0586\n",
            "Epoch 182/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0913 - val_loss: 0.0585\n",
            "Epoch 183/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0913 - val_loss: 0.0585\n",
            "Epoch 184/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0912 - val_loss: 0.0584\n",
            "Epoch 185/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0911 - val_loss: 0.0584\n",
            "Epoch 186/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0910 - val_loss: 0.0583\n",
            "Epoch 187/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0909 - val_loss: 0.0583\n",
            "Epoch 188/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0909 - val_loss: 0.0583\n",
            "Epoch 189/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0908 - val_loss: 0.0583\n",
            "Epoch 190/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0908 - val_loss: 0.0582\n",
            "Epoch 191/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0907 - val_loss: 0.0582\n",
            "Epoch 192/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0906 - val_loss: 0.0582\n",
            "Epoch 193/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0905 - val_loss: 0.0582\n",
            "Epoch 194/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0905 - val_loss: 0.0581\n",
            "Epoch 195/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0904 - val_loss: 0.0581\n",
            "Epoch 196/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0904 - val_loss: 0.0581\n",
            "Epoch 197/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0903 - val_loss: 0.0581\n",
            "Epoch 198/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0903 - val_loss: 0.0580\n",
            "Epoch 199/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0902 - val_loss: 0.0580\n",
            "Epoch 200/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0901 - val_loss: 0.0580\n",
            "Epoch 201/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0901 - val_loss: 0.0579\n",
            "Epoch 202/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0900 - val_loss: 0.0579\n",
            "Epoch 203/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0900 - val_loss: 0.0579\n",
            "Epoch 204/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0899 - val_loss: 0.0579\n",
            "Epoch 205/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0898 - val_loss: 0.0578\n",
            "Epoch 206/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0898 - val_loss: 0.0578\n",
            "Epoch 207/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0897 - val_loss: 0.0578\n",
            "Epoch 208/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0897 - val_loss: 0.0578\n",
            "Epoch 209/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0896 - val_loss: 0.0578\n",
            "Epoch 210/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0896 - val_loss: 0.0578\n",
            "Epoch 211/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0896 - val_loss: 0.0577\n",
            "Epoch 212/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0895 - val_loss: 0.0577\n",
            "Epoch 213/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0895 - val_loss: 0.0578\n",
            "Epoch 214/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0894 - val_loss: 0.0577\n",
            "Epoch 215/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0894 - val_loss: 0.0577\n",
            "Epoch 216/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0893 - val_loss: 0.0576\n",
            "Epoch 217/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0893 - val_loss: 0.0576\n",
            "Epoch 218/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0893 - val_loss: 0.0576\n",
            "Epoch 219/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0892 - val_loss: 0.0576\n",
            "Epoch 220/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0892 - val_loss: 0.0576\n",
            "Epoch 221/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0892 - val_loss: 0.0576\n",
            "Epoch 222/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0892 - val_loss: 0.0575\n",
            "Epoch 223/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0891 - val_loss: 0.0575\n",
            "Epoch 224/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0891 - val_loss: 0.0575\n",
            "Epoch 225/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0890 - val_loss: 0.0575\n",
            "Epoch 226/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0890 - val_loss: 0.0575\n",
            "Epoch 227/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0890 - val_loss: 0.0575\n",
            "Epoch 228/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0890 - val_loss: 0.0575\n",
            "Epoch 229/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0889 - val_loss: 0.0574\n",
            "Epoch 230/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0889 - val_loss: 0.0574\n",
            "Epoch 231/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0888 - val_loss: 0.0574\n",
            "Epoch 232/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0888 - val_loss: 0.0574\n",
            "Epoch 233/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0888 - val_loss: 0.0574\n",
            "Epoch 234/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0888 - val_loss: 0.0573\n",
            "Epoch 235/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0887 - val_loss: 0.0573\n",
            "Epoch 236/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0888 - val_loss: 0.0573\n",
            "Epoch 237/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0887 - val_loss: 0.0573\n",
            "Epoch 238/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0886 - val_loss: 0.0573\n",
            "Epoch 239/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0886 - val_loss: 0.0572\n",
            "Epoch 240/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0886 - val_loss: 0.0573\n",
            "Epoch 241/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0886 - val_loss: 0.0573\n",
            "Epoch 242/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0885 - val_loss: 0.0572\n",
            "Epoch 243/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0885 - val_loss: 0.0572\n",
            "Epoch 244/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0885 - val_loss: 0.0572\n",
            "Epoch 245/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0884 - val_loss: 0.0572\n",
            "Epoch 246/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0884 - val_loss: 0.0571\n",
            "Epoch 247/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0884 - val_loss: 0.0571\n",
            "Epoch 248/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0883 - val_loss: 0.0571\n",
            "Epoch 249/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0883 - val_loss: 0.0571\n",
            "Epoch 250/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0883 - val_loss: 0.0571\n",
            "Epoch 251/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0883 - val_loss: 0.0571\n",
            "Epoch 252/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0882 - val_loss: 0.0571\n",
            "Epoch 253/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0882 - val_loss: 0.0570\n",
            "Epoch 254/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0882 - val_loss: 0.0571\n",
            "Epoch 255/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0881 - val_loss: 0.0571\n",
            "Epoch 256/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0881 - val_loss: 0.0571\n",
            "Epoch 257/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0881 - val_loss: 0.0570\n",
            "Epoch 258/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0880 - val_loss: 0.0570\n",
            "Epoch 259/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0880 - val_loss: 0.0570\n",
            "Epoch 260/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0880 - val_loss: 0.0570\n",
            "Epoch 261/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0880 - val_loss: 0.0570\n",
            "Epoch 262/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0880 - val_loss: 0.0570\n",
            "Epoch 263/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0880 - val_loss: 0.0569\n",
            "Epoch 264/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0879 - val_loss: 0.0569\n",
            "Epoch 265/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0879 - val_loss: 0.0569\n",
            "Epoch 266/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0878 - val_loss: 0.0569\n",
            "Epoch 267/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0878 - val_loss: 0.0569\n",
            "Epoch 268/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0878 - val_loss: 0.0569\n",
            "Epoch 269/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0878 - val_loss: 0.0569\n",
            "Epoch 270/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0877 - val_loss: 0.0569\n",
            "Epoch 271/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0877 - val_loss: 0.0569\n",
            "Epoch 272/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0877 - val_loss: 0.0569\n",
            "Epoch 273/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0877 - val_loss: 0.0569\n",
            "Epoch 274/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0876 - val_loss: 0.0569\n",
            "Epoch 275/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0876 - val_loss: 0.0569\n",
            "Epoch 276/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0877 - val_loss: 0.0569\n",
            "Epoch 277/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0876 - val_loss: 0.0569\n",
            "Epoch 278/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0876 - val_loss: 0.0569\n",
            "Epoch 279/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0876 - val_loss: 0.0569\n",
            "Epoch 280/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0876 - val_loss: 0.0569\n",
            "Epoch 281/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0876 - val_loss: 0.0568\n",
            "Epoch 282/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0876 - val_loss: 0.0568\n",
            "Epoch 283/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0876 - val_loss: 0.0568\n",
            "Epoch 284/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0875 - val_loss: 0.0568\n",
            "Epoch 285/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0876 - val_loss: 0.0568\n",
            "Epoch 286/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0875 - val_loss: 0.0568\n",
            "Epoch 287/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0875 - val_loss: 0.0568\n",
            "Epoch 288/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0875 - val_loss: 0.0569\n",
            "Epoch 289/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0875 - val_loss: 0.0569\n",
            "Epoch 290/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0875 - val_loss: 0.0569\n",
            "Epoch 291/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0875 - val_loss: 0.0569\n",
            "Epoch 292/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0874 - val_loss: 0.0569\n",
            "Epoch 293/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0875 - val_loss: 0.0568\n",
            "Epoch 294/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0874 - val_loss: 0.0568\n",
            "Epoch 295/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0874 - val_loss: 0.0568\n",
            "Epoch 296/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0874 - val_loss: 0.0568\n",
            "Epoch 297/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0874 - val_loss: 0.0568\n",
            "Epoch 298/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0874 - val_loss: 0.0568\n",
            "Epoch 299/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0874 - val_loss: 0.0568\n",
            "Epoch 300/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0874 - val_loss: 0.0568\n",
            "Epoch 301/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0874 - val_loss: 0.0568\n",
            "Epoch 302/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0873 - val_loss: 0.0568\n",
            "Epoch 303/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0875 - val_loss: 0.0567\n",
            "Epoch 304/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0873 - val_loss: 0.0567\n",
            "Epoch 305/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0873 - val_loss: 0.0567\n",
            "Epoch 306/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0873 - val_loss: 0.0567\n",
            "Epoch 307/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0873 - val_loss: 0.0567\n",
            "Epoch 308/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0874 - val_loss: 0.0568\n",
            "Epoch 309/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0873 - val_loss: 0.0568\n",
            "Epoch 310/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0873 - val_loss: 0.0567\n",
            "Epoch 311/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0873 - val_loss: 0.0567\n",
            "Epoch 312/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0873 - val_loss: 0.0567\n",
            "Epoch 313/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0873 - val_loss: 0.0567\n",
            "Epoch 314/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0873 - val_loss: 0.0567\n",
            "Epoch 315/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0873 - val_loss: 0.0567\n",
            "Epoch 316/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0873 - val_loss: 0.0567\n",
            "Epoch 317/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0872 - val_loss: 0.0567\n",
            "Epoch 318/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0872 - val_loss: 0.0567\n",
            "Epoch 319/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0872 - val_loss: 0.0567\n",
            "Epoch 320/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0873 - val_loss: 0.0568\n",
            "Epoch 321/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0872 - val_loss: 0.0568\n",
            "Epoch 322/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0872 - val_loss: 0.0568\n",
            "Epoch 323/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0872 - val_loss: 0.0568\n",
            "Epoch 324/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0872 - val_loss: 0.0568\n",
            "Epoch 325/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0872 - val_loss: 0.0568\n",
            "Epoch 326/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0872 - val_loss: 0.0567\n",
            "Epoch 327/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0872 - val_loss: 0.0568\n",
            "Epoch 328/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0873 - val_loss: 0.0567\n",
            "Epoch 329/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0872 - val_loss: 0.0568\n",
            "Epoch 330/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0872 - val_loss: 0.0567\n",
            "Epoch 331/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0872 - val_loss: 0.0567\n",
            "Epoch 332/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0872 - val_loss: 0.0567\n",
            "Epoch 333/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0872 - val_loss: 0.0567\n",
            "Epoch 334/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0872 - val_loss: 0.0568\n",
            "Epoch 335/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0872 - val_loss: 0.0568\n",
            "Epoch 336/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0872 - val_loss: 0.0568\n",
            "Epoch 337/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0872 - val_loss: 0.0568\n",
            "Epoch 338/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0872 - val_loss: 0.0568\n",
            "Epoch 339/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0872 - val_loss: 0.0568\n",
            "Epoch 340/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0871 - val_loss: 0.0568\n",
            "Epoch 341/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0871 - val_loss: 0.0567\n",
            "Epoch 342/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0873 - val_loss: 0.0568\n",
            "Epoch 343/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0871 - val_loss: 0.0568\n",
            "Epoch 344/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0871 - val_loss: 0.0568\n",
            "Epoch 345/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0871 - val_loss: 0.0567\n",
            "Epoch 346/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0871 - val_loss: 0.0567\n",
            "Epoch 347/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0871 - val_loss: 0.0567\n",
            "Epoch 348/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0871 - val_loss: 0.0568\n",
            "Epoch 349/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0871 - val_loss: 0.0568\n",
            "Epoch 350/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0871 - val_loss: 0.0568\n",
            "Epoch 351/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0871 - val_loss: 0.0567\n",
            "Epoch 352/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0871 - val_loss: 0.0568\n",
            "Epoch 353/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0871 - val_loss: 0.0568\n",
            "Epoch 354/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0871 - val_loss: 0.0568\n",
            "Epoch 355/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0871 - val_loss: 0.0568\n",
            "Epoch 356/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0871 - val_loss: 0.0568\n",
            "Epoch 357/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0871 - val_loss: 0.0567\n",
            "Epoch 358/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0871 - val_loss: 0.0567\n",
            "Epoch 359/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0871 - val_loss: 0.0567\n",
            "Epoch 360/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0872 - val_loss: 0.0568\n",
            "Epoch 361/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0871 - val_loss: 0.0568\n",
            "Epoch 362/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0871 - val_loss: 0.0568\n",
            "Epoch 363/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0871 - val_loss: 0.0568\n",
            "Epoch 364/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0871 - val_loss: 0.0568\n",
            "Epoch 365/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0871 - val_loss: 0.0568\n",
            "Epoch 366/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0871 - val_loss: 0.0567\n",
            "Epoch 367/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0871 - val_loss: 0.0568\n",
            "Epoch 368/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0871 - val_loss: 0.0567\n",
            "Epoch 369/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0871 - val_loss: 0.0567\n",
            "Epoch 370/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0871 - val_loss: 0.0568\n",
            "Epoch 371/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0871 - val_loss: 0.0568\n",
            "Epoch 372/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0871 - val_loss: 0.0568\n",
            "Epoch 373/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0870 - val_loss: 0.0568\n",
            "Epoch 374/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0871 - val_loss: 0.0567\n",
            "Epoch 375/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0870 - val_loss: 0.0568\n",
            "Epoch 376/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0870 - val_loss: 0.0568\n",
            "Epoch 377/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0871 - val_loss: 0.0568\n",
            "Epoch 378/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0870 - val_loss: 0.0568\n",
            "Epoch 379/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0870 - val_loss: 0.0568\n",
            "Epoch 380/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0870 - val_loss: 0.0568\n",
            "Epoch 381/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0871 - val_loss: 0.0568\n",
            "Epoch 382/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0870 - val_loss: 0.0568\n",
            "Epoch 383/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0870 - val_loss: 0.0568\n",
            "Epoch 384/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0870 - val_loss: 0.0567\n",
            "Epoch 385/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0870 - val_loss: 0.0567\n",
            "Epoch 386/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0871 - val_loss: 0.0568\n",
            "Epoch 387/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0870 - val_loss: 0.0568\n",
            "Epoch 388/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0870 - val_loss: 0.0567\n",
            "Epoch 389/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0870 - val_loss: 0.0567\n",
            "Epoch 390/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0870 - val_loss: 0.0568\n",
            "Epoch 391/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0871 - val_loss: 0.0568\n",
            "Epoch 392/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0870 - val_loss: 0.0568\n",
            "Epoch 393/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0870 - val_loss: 0.0568\n",
            "Epoch 394/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0870 - val_loss: 0.0568\n",
            "Epoch 395/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0870 - val_loss: 0.0568\n",
            "Epoch 396/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0870 - val_loss: 0.0568\n",
            "Epoch 397/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0870 - val_loss: 0.0568\n",
            "Epoch 398/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0870 - val_loss: 0.0568\n",
            "Epoch 399/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0870 - val_loss: 0.0569\n",
            "Epoch 400/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0870 - val_loss: 0.0569\n",
            "Epoch 401/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0870 - val_loss: 0.0568\n",
            "Epoch 402/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0870 - val_loss: 0.0568\n",
            "Epoch 403/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0870 - val_loss: 0.0568\n",
            "Epoch 404/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0870 - val_loss: 0.0568\n",
            "Epoch 405/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0870 - val_loss: 0.0568\n",
            "Epoch 406/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0871 - val_loss: 0.0568\n",
            "Epoch 407/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 408/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 409/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0870 - val_loss: 0.0568\n",
            "Epoch 410/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 411/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0870 - val_loss: 0.0568\n",
            "Epoch 412/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0870 - val_loss: 0.0568\n",
            "Epoch 413/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 414/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 415/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0871 - val_loss: 0.0568\n",
            "Epoch 416/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 417/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0870 - val_loss: 0.0568\n",
            "Epoch 418/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0870 - val_loss: 0.0568\n",
            "Epoch 419/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 420/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 421/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0870 - val_loss: 0.0568\n",
            "Epoch 422/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 423/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 424/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 425/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 426/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 427/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 428/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 429/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 430/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 431/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0869 - val_loss: 0.0569\n",
            "Epoch 432/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 433/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 434/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 435/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 436/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 437/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 438/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 439/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 440/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 441/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 442/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 443/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 444/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 445/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 446/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 447/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 448/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 449/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 450/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 451/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 452/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 453/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 454/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 455/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 456/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 457/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 458/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 459/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 460/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 461/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 462/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 463/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 464/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 465/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 466/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 467/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 468/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 469/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 470/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 471/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 472/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 473/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0869 - val_loss: 0.0569\n",
            "Epoch 474/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0569\n",
            "Epoch 475/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 476/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 477/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 478/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 479/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 480/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 481/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 482/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 483/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 484/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 485/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 486/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 487/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 488/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 489/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 490/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 491/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0871 - val_loss: 0.0568\n",
            "Epoch 492/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 493/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 494/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 495/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 496/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 497/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 498/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0870 - val_loss: 0.0569\n",
            "Epoch 499/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 500/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 501/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 502/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 503/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 504/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 505/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 506/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 507/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 508/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 509/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 510/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 511/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 512/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 513/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 514/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 515/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 516/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 517/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 518/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 519/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 520/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 521/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 522/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 523/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 524/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 525/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 526/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 527/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 528/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 529/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 530/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 531/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 532/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 533/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 534/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 535/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 536/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 537/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 538/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 539/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 540/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 541/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 542/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 543/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 544/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 545/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 546/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 547/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 548/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 549/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 550/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 551/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 552/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 553/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 554/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 555/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 556/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 557/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 558/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 559/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 560/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 561/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 562/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 563/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 564/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 565/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 566/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 567/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0868 - val_loss: 0.0569\n",
            "Epoch 568/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 569/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 570/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 571/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 572/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 573/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 574/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 575/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 576/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 577/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 578/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 579/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 580/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 581/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 582/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 583/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 584/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 585/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 586/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 587/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 588/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 589/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 590/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 591/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 592/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 593/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 594/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 595/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 596/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 597/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 598/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 599/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 600/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 601/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 602/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 603/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 604/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 605/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 606/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 607/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 608/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 609/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 610/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 611/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 612/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 613/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 614/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 615/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 616/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 617/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 618/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 619/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 620/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 621/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 622/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 623/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 624/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 625/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 626/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 627/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 628/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 629/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 630/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 631/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0569\n",
            "Epoch 632/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0569\n",
            "Epoch 633/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0569\n",
            "Epoch 634/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 635/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 636/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 637/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 638/1000\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 639/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 640/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 641/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 642/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0568\n",
            "Epoch 643/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 644/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 645/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 646/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 647/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 648/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 649/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0569\n",
            "Epoch 650/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 651/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 652/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 653/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 654/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 655/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 656/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 657/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 658/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 659/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 660/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 661/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 662/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 663/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0867 - val_loss: 0.0569\n",
            "Epoch 664/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 665/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 666/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 667/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 668/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 669/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 670/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 671/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 672/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 673/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 674/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 675/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 676/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 677/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 678/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 679/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 680/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 681/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 682/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 683/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 684/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 685/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 686/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 687/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 688/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 689/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 690/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 691/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 692/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 693/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 694/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 695/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 696/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 697/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 698/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 699/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 700/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 701/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 702/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 703/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 704/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 705/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 706/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 707/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 708/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 709/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 710/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 711/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 712/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 713/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 714/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 715/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 716/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 717/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 718/1000\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 719/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 720/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 721/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 722/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 723/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 724/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 725/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 726/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 727/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 728/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 729/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 730/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 731/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 732/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 733/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 734/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 735/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 736/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 737/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 738/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 739/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0569\n",
            "Epoch 740/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 741/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 742/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 743/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 744/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 745/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 746/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 747/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 748/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 749/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 750/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 751/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 752/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 753/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 754/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 755/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 756/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 757/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 758/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 759/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 760/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0568\n",
            "Epoch 761/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 762/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 763/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 764/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 765/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 766/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0569\n",
            "Epoch 767/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 768/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 769/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 770/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 771/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 772/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 773/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 774/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 775/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 776/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 777/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 778/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 779/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 780/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 781/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 782/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 783/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 784/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 785/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 786/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 787/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 788/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 789/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 790/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 791/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 792/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 793/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 794/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 795/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 796/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 797/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 798/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 799/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 800/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 801/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 802/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 803/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 804/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 805/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 806/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 807/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 808/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 809/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 810/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 811/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 812/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 813/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 814/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 815/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 816/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 817/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 818/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 819/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0569\n",
            "Epoch 820/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.0569\n",
            "Epoch 821/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 822/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 823/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 824/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 825/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 826/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 827/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 828/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 829/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0569\n",
            "Epoch 830/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 831/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 832/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 833/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 834/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 835/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 836/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 837/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 838/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 839/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 840/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 841/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 842/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 843/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 844/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 845/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 846/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 847/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 848/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 849/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 850/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 851/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 852/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 853/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 854/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 855/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 856/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 857/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 858/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 859/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 860/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 861/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 862/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 863/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 864/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 865/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 866/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 867/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 868/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 869/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 870/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0568\n",
            "Epoch 871/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 872/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 873/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 874/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 875/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 876/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 877/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 878/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 879/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 880/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 881/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 882/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 883/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 884/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 885/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 886/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 887/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 888/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 889/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 890/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0569\n",
            "Epoch 891/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.0569\n",
            "Epoch 892/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0569\n",
            "Epoch 893/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 894/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 895/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.0569\n",
            "Epoch 896/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 897/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 898/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 899/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 900/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 901/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 902/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 903/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 904/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 905/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 906/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 907/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 908/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 909/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 910/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 911/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 912/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 913/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 914/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 915/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 916/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 917/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 918/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 919/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 920/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 921/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 922/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.0569\n",
            "Epoch 923/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0865 - val_loss: 0.0569\n",
            "Epoch 924/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0569\n",
            "Epoch 925/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 926/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 927/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 928/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 929/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 930/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 931/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 932/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 933/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0568\n",
            "Epoch 934/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 935/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 936/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 937/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 938/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0569\n",
            "Epoch 939/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 940/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 941/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 942/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 943/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 944/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 945/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 946/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 947/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 948/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 949/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 950/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 951/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0569\n",
            "Epoch 952/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 953/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 954/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 955/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 956/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 957/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 958/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 959/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 960/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 961/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 962/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 963/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0569\n",
            "Epoch 964/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0865 - val_loss: 0.0569\n",
            "Epoch 965/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 966/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 967/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 968/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 969/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 970/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 971/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 972/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 973/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0864 - val_loss: 0.0568\n",
            "Epoch 974/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 975/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 976/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 977/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 978/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 979/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 980/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 981/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 982/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 983/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 984/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 985/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 986/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 987/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0864 - val_loss: 0.0568\n",
            "Epoch 988/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 989/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 990/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 991/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 992/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0569\n",
            "Epoch 993/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0569\n",
            "Epoch 994/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 995/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 996/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 997/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 998/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 999/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0865 - val_loss: 0.0568\n",
            "Epoch 1000/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0864 - val_loss: 0.0568\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNnTLW9QrYl1",
        "outputId": "e52115c2-f310-4acd-ff1d-ec15e6e5b403",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "loss2 = model2.evaluate(feature_test, label_test, verbose=2)\n",
        "\n",
        "print(\"Test loss:\", loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3/3 - 0s - loss: 0.0568\n",
            "Test loss: 0.056795503944158554\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9xfQH7nrYl6",
        "outputId": "be2e431d-89a8-4339-a982-02cb0e13fab1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "history_dataframe2 = pd.DataFrame(history2.history)\n",
        "history_dataframe2['epoch'] = history.epoch\n",
        "history_dataframe2.sort_values(by='val_loss', ascending=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>313</th>\n",
              "      <td>0.087268</td>\n",
              "      <td>0.056726</td>\n",
              "      <td>313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>312</th>\n",
              "      <td>0.087256</td>\n",
              "      <td>0.056727</td>\n",
              "      <td>312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>303</th>\n",
              "      <td>0.087348</td>\n",
              "      <td>0.056727</td>\n",
              "      <td>303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>0.087456</td>\n",
              "      <td>0.056730</td>\n",
              "      <td>302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>306</th>\n",
              "      <td>0.087341</td>\n",
              "      <td>0.056733</td>\n",
              "      <td>306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.139735</td>\n",
              "      <td>0.088598</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.145270</td>\n",
              "      <td>0.092092</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.150285</td>\n",
              "      <td>0.096382</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.157564</td>\n",
              "      <td>0.100870</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.164330</td>\n",
              "      <td>0.106535</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         loss  val_loss  epoch\n",
              "313  0.087268  0.056726    313\n",
              "312  0.087256  0.056727    312\n",
              "303  0.087348  0.056727    303\n",
              "302  0.087456  0.056730    302\n",
              "306  0.087341  0.056733    306\n",
              "..        ...       ...    ...\n",
              "4    0.139735  0.088598      4\n",
              "3    0.145270  0.092092      3\n",
              "2    0.150285  0.096382      2\n",
              "1    0.157564  0.100870      1\n",
              "0    0.164330  0.106535      0\n",
              "\n",
              "[1000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5FjC25xrYl8",
        "outputId": "4bf6d54f-2cf7-4667-e746-6ceb36c730a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "plot_loss(history2) # epoch vs loss graph"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcvd-m-UrYl_"
      },
      "source": [
        "### Deeper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72zAF6LwrYl_",
        "outputId": "d7833623-33fd-43e8-96f5-910c2fef821a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "neurons = 1\n",
        "epoch = 1000\n",
        "batch_size = 32\n",
        "\n",
        "deeper_model2 = Sequential()\n",
        "deeper_model2.add(Dense(neurons, activation='relu', input_dim=feature_train.shape[1]))\n",
        "deeper_model2.add(Dense(5, activation='relu'))\n",
        "deeper_model2.add(Dense(1))\n",
        "deeper_model2.compile(loss='mean_squared_error', optimizer='adam')\n",
        "deeper_model_history2 = deeper_model2.fit(feature_train, label_train, epochs=epoch, batch_size=batch_size, validation_data=(feature_test, label_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.1257 - val_loss: 0.0776\n",
            "Epoch 2/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1223 - val_loss: 0.0751\n",
            "Epoch 3/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1192 - val_loss: 0.0734\n",
            "Epoch 4/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1170 - val_loss: 0.0722\n",
            "Epoch 5/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1153 - val_loss: 0.0713\n",
            "Epoch 6/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1141 - val_loss: 0.0707\n",
            "Epoch 7/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1131 - val_loss: 0.0702\n",
            "Epoch 8/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1125 - val_loss: 0.0698\n",
            "Epoch 9/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1119 - val_loss: 0.0697\n",
            "Epoch 10/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1116 - val_loss: 0.0696\n",
            "Epoch 11/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1114 - val_loss: 0.0695\n",
            "Epoch 12/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1113 - val_loss: 0.0695\n",
            "Epoch 13/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1112 - val_loss: 0.0695\n",
            "Epoch 14/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1112 - val_loss: 0.0695\n",
            "Epoch 15/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1111 - val_loss: 0.0695\n",
            "Epoch 16/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1111 - val_loss: 0.0694\n",
            "Epoch 17/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1111 - val_loss: 0.0694\n",
            "Epoch 18/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1110 - val_loss: 0.0694\n",
            "Epoch 19/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1110 - val_loss: 0.0694\n",
            "Epoch 20/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1110 - val_loss: 0.0694\n",
            "Epoch 21/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1110 - val_loss: 0.0694\n",
            "Epoch 22/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1110 - val_loss: 0.0694\n",
            "Epoch 23/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1109 - val_loss: 0.0694\n",
            "Epoch 24/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1109 - val_loss: 0.0694\n",
            "Epoch 25/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1109 - val_loss: 0.0694\n",
            "Epoch 26/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1109 - val_loss: 0.0694\n",
            "Epoch 27/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1109 - val_loss: 0.0694\n",
            "Epoch 28/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1109 - val_loss: 0.0694\n",
            "Epoch 29/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1109 - val_loss: 0.0694\n",
            "Epoch 30/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1109 - val_loss: 0.0694\n",
            "Epoch 31/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1108 - val_loss: 0.0694\n",
            "Epoch 32/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.0694\n",
            "Epoch 33/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.0694\n",
            "Epoch 34/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.0694\n",
            "Epoch 35/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.0694\n",
            "Epoch 36/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.0694\n",
            "Epoch 37/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.0694\n",
            "Epoch 38/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1108 - val_loss: 0.0694\n",
            "Epoch 39/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.0694\n",
            "Epoch 40/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.0694\n",
            "Epoch 41/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1108 - val_loss: 0.0694\n",
            "Epoch 42/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.0694\n",
            "Epoch 43/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.0694\n",
            "Epoch 44/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.0694\n",
            "Epoch 45/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.0694\n",
            "Epoch 46/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.0694\n",
            "Epoch 47/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.0694\n",
            "Epoch 48/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.0694\n",
            "Epoch 49/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.0694\n",
            "Epoch 50/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.0694\n",
            "Epoch 51/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.0694\n",
            "Epoch 52/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1108 - val_loss: 0.0694\n",
            "Epoch 53/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.0694\n",
            "Epoch 54/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1108 - val_loss: 0.0694\n",
            "Epoch 55/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.0694\n",
            "Epoch 56/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1108 - val_loss: 0.0694\n",
            "Epoch 57/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.0694\n",
            "Epoch 58/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.0694\n",
            "Epoch 59/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.0694\n",
            "Epoch 60/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.0694\n",
            "Epoch 61/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.0694\n",
            "Epoch 62/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.0694\n",
            "Epoch 63/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.0694\n",
            "Epoch 64/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.0694\n",
            "Epoch 65/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1108 - val_loss: 0.0694\n",
            "Epoch 66/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.0694\n",
            "Epoch 67/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.0694\n",
            "Epoch 68/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.0694\n",
            "Epoch 69/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1108 - val_loss: 0.0694\n",
            "Epoch 70/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.0694\n",
            "Epoch 71/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1107 - val_loss: 0.0694\n",
            "Epoch 72/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1107 - val_loss: 0.0694\n",
            "Epoch 73/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1107 - val_loss: 0.0694\n",
            "Epoch 74/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1107 - val_loss: 0.0694\n",
            "Epoch 75/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1107 - val_loss: 0.0694\n",
            "Epoch 76/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1107 - val_loss: 0.0694\n",
            "Epoch 77/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1107 - val_loss: 0.0694\n",
            "Epoch 78/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1107 - val_loss: 0.0694\n",
            "Epoch 79/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1107 - val_loss: 0.0694\n",
            "Epoch 80/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1107 - val_loss: 0.0693\n",
            "Epoch 81/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1106 - val_loss: 0.0693\n",
            "Epoch 82/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1106 - val_loss: 0.0693\n",
            "Epoch 83/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1105 - val_loss: 0.0692\n",
            "Epoch 84/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1104 - val_loss: 0.0692\n",
            "Epoch 85/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1103 - val_loss: 0.0691\n",
            "Epoch 86/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1100 - val_loss: 0.0689\n",
            "Epoch 87/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1098 - val_loss: 0.0687\n",
            "Epoch 88/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1094 - val_loss: 0.0686\n",
            "Epoch 89/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1091 - val_loss: 0.0684\n",
            "Epoch 90/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1088 - val_loss: 0.0681\n",
            "Epoch 91/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1083 - val_loss: 0.0678\n",
            "Epoch 92/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1078 - val_loss: 0.0674\n",
            "Epoch 93/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1072 - val_loss: 0.0669\n",
            "Epoch 94/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1063 - val_loss: 0.0663\n",
            "Epoch 95/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1054 - val_loss: 0.0656\n",
            "Epoch 96/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1044 - val_loss: 0.0648\n",
            "Epoch 97/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1030 - val_loss: 0.0641\n",
            "Epoch 98/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1018 - val_loss: 0.0632\n",
            "Epoch 99/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1004 - val_loss: 0.0623\n",
            "Epoch 100/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0990 - val_loss: 0.0616\n",
            "Epoch 101/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.0607\n",
            "Epoch 102/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0962 - val_loss: 0.0599\n",
            "Epoch 103/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0948 - val_loss: 0.0592\n",
            "Epoch 104/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0936 - val_loss: 0.0585\n",
            "Epoch 105/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0924 - val_loss: 0.0578\n",
            "Epoch 106/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0912 - val_loss: 0.0573\n",
            "Epoch 107/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0902 - val_loss: 0.0567\n",
            "Epoch 108/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0892 - val_loss: 0.0562\n",
            "Epoch 109/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0883 - val_loss: 0.0558\n",
            "Epoch 110/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0875 - val_loss: 0.0554\n",
            "Epoch 111/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0550\n",
            "Epoch 112/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0861 - val_loss: 0.0547\n",
            "Epoch 113/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0854 - val_loss: 0.0544\n",
            "Epoch 114/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0848 - val_loss: 0.0542\n",
            "Epoch 115/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0844 - val_loss: 0.0540\n",
            "Epoch 116/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0839 - val_loss: 0.0539\n",
            "Epoch 117/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0835 - val_loss: 0.0537\n",
            "Epoch 118/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0830 - val_loss: 0.0537\n",
            "Epoch 119/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0828 - val_loss: 0.0536\n",
            "Epoch 120/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0826 - val_loss: 0.0536\n",
            "Epoch 121/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0822 - val_loss: 0.0535\n",
            "Epoch 122/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0821 - val_loss: 0.0535\n",
            "Epoch 123/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0818 - val_loss: 0.0535\n",
            "Epoch 124/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0817 - val_loss: 0.0535\n",
            "Epoch 125/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0815 - val_loss: 0.0536\n",
            "Epoch 126/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0814 - val_loss: 0.0536\n",
            "Epoch 127/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0813 - val_loss: 0.0536\n",
            "Epoch 128/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0812 - val_loss: 0.0537\n",
            "Epoch 129/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0811 - val_loss: 0.0537\n",
            "Epoch 130/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0811 - val_loss: 0.0538\n",
            "Epoch 131/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0811 - val_loss: 0.0538\n",
            "Epoch 132/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0810 - val_loss: 0.0538\n",
            "Epoch 133/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0810 - val_loss: 0.0538\n",
            "Epoch 134/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0810 - val_loss: 0.0539\n",
            "Epoch 135/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0808 - val_loss: 0.0539\n",
            "Epoch 136/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0808 - val_loss: 0.0540\n",
            "Epoch 137/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0808 - val_loss: 0.0541\n",
            "Epoch 138/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0808 - val_loss: 0.0540\n",
            "Epoch 139/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0541\n",
            "Epoch 140/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0542\n",
            "Epoch 141/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0542\n",
            "Epoch 142/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0543\n",
            "Epoch 143/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0542\n",
            "Epoch 144/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0543\n",
            "Epoch 145/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0544\n",
            "Epoch 146/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0543\n",
            "Epoch 147/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0544\n",
            "Epoch 148/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0544\n",
            "Epoch 149/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0544\n",
            "Epoch 150/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0543\n",
            "Epoch 151/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0544\n",
            "Epoch 152/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0544\n",
            "Epoch 153/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0544\n",
            "Epoch 154/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0544\n",
            "Epoch 155/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0544\n",
            "Epoch 156/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0544\n",
            "Epoch 157/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0544\n",
            "Epoch 158/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0544\n",
            "Epoch 159/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0545\n",
            "Epoch 160/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 161/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 162/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0545\n",
            "Epoch 163/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0545\n",
            "Epoch 164/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0545\n",
            "Epoch 165/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0545\n",
            "Epoch 166/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 167/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0545\n",
            "Epoch 168/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 169/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 170/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 171/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 172/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 173/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 174/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 175/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 176/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 177/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 178/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 179/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 180/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 181/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 182/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 183/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 184/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 185/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 186/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 187/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 188/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 189/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 190/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0546\n",
            "Epoch 191/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 192/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 193/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 194/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 195/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 196/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 197/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0546\n",
            "Epoch 198/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 199/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 200/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 201/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0548\n",
            "Epoch 202/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 203/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 204/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 205/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 206/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0546\n",
            "Epoch 207/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 208/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 209/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0547\n",
            "Epoch 210/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 211/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 212/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 213/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 214/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 215/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 216/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 217/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 218/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 219/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 220/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0546\n",
            "Epoch 221/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 222/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 223/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 224/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0547\n",
            "Epoch 225/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 226/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 227/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 228/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 229/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0547\n",
            "Epoch 230/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0546\n",
            "Epoch 231/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 232/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 233/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 234/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 235/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 236/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 237/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 238/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 239/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0545\n",
            "Epoch 240/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0807 - val_loss: 0.0545\n",
            "Epoch 241/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 242/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 243/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 244/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 245/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 246/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 247/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 248/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 249/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 250/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 251/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 252/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 253/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0548\n",
            "Epoch 254/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 255/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 256/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0547\n",
            "Epoch 257/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 258/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 259/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 260/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 261/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 262/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 263/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 264/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 265/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 266/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 267/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 268/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 269/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 270/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 271/1000\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0807 - val_loss: 0.0545\n",
            "Epoch 272/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 273/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 274/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 275/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 276/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 277/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 278/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 279/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 280/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 281/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0546\n",
            "Epoch 282/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0546\n",
            "Epoch 283/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0546\n",
            "Epoch 284/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 285/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 286/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 287/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 288/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 289/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 290/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 291/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 292/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 293/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0548\n",
            "Epoch 294/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 295/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 296/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 297/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 298/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0546\n",
            "Epoch 299/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 300/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 301/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 302/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 303/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 304/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 305/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0549\n",
            "Epoch 306/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 307/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 308/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 309/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 310/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 311/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 312/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 313/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 314/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 315/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 316/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 317/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 318/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 319/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 320/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 321/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 322/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 323/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 324/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 325/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 326/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 327/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 328/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 329/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 330/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 331/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 332/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 333/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0547\n",
            "Epoch 334/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 335/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 336/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 337/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 338/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 339/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 340/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0547\n",
            "Epoch 341/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 342/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 343/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 344/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 345/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 346/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 347/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 348/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 349/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 350/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0807 - val_loss: 0.0547\n",
            "Epoch 351/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 352/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 353/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 354/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 355/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 356/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 357/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 358/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 359/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 360/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 361/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 362/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 363/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 364/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 365/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 366/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 367/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 368/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 369/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 370/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 371/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 372/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 373/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 374/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 375/1000\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 376/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 377/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 378/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 379/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0548\n",
            "Epoch 380/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 381/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0546\n",
            "Epoch 382/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 383/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 384/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 385/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 386/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 387/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 388/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 389/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 390/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 391/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 392/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 393/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 394/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 395/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 396/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 397/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 398/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 399/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 400/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 401/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 402/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 403/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 404/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 405/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 406/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 407/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 408/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 409/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 410/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 411/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 412/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 413/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 414/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 415/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 416/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 417/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0546\n",
            "Epoch 418/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 419/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 420/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 421/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 422/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 423/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 424/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0545\n",
            "Epoch 425/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 426/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0545\n",
            "Epoch 427/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0545\n",
            "Epoch 428/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0545\n",
            "Epoch 429/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0545\n",
            "Epoch 430/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0545\n",
            "Epoch 431/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0545\n",
            "Epoch 432/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 433/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 434/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 435/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0545\n",
            "Epoch 436/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 437/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 438/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 439/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 440/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 441/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 442/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 443/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0547\n",
            "Epoch 444/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 445/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 446/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 447/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 448/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 449/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 450/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0549\n",
            "Epoch 451/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0548\n",
            "Epoch 452/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 453/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0807 - val_loss: 0.0546\n",
            "Epoch 454/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 455/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 456/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 457/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 458/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 459/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 460/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0545\n",
            "Epoch 461/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 462/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0547\n",
            "Epoch 463/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 464/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 465/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 466/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0807 - val_loss: 0.0545\n",
            "Epoch 467/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 468/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 469/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 470/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 471/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 472/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 473/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0549\n",
            "Epoch 474/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0549\n",
            "Epoch 475/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 476/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 477/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 478/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 479/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0545\n",
            "Epoch 480/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 481/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 482/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 483/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 484/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 485/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 486/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 487/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 488/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 489/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 490/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 491/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 492/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 493/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0545\n",
            "Epoch 494/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 495/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0547\n",
            "Epoch 496/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 497/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 498/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 499/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 500/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 501/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 502/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 503/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 504/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 505/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 506/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 507/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 508/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0547\n",
            "Epoch 509/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 510/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 511/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 512/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 513/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 514/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 515/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 516/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 517/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 518/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 519/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 520/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 521/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 522/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 523/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 524/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 525/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 526/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 527/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 528/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 529/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 530/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 531/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 532/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 533/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 534/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 535/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 536/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 537/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 538/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 539/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 540/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 541/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 542/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 543/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 544/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 545/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 546/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 547/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 548/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 549/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0547\n",
            "Epoch 550/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 551/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 552/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 553/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 554/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 555/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 556/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 557/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 558/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 559/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 560/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 561/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 562/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 563/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0807 - val_loss: 0.0547\n",
            "Epoch 564/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 565/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 566/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 567/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 568/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0548\n",
            "Epoch 569/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 570/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 571/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 572/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 573/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 574/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 575/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 576/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 577/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 578/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 579/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 580/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0547\n",
            "Epoch 581/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 582/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 583/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 584/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 585/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0547\n",
            "Epoch 586/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0546\n",
            "Epoch 587/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 588/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 589/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 590/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 591/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0547\n",
            "Epoch 592/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 593/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 594/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 595/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 596/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 597/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 598/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 599/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 600/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 601/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 602/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 603/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 604/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0546\n",
            "Epoch 605/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 606/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 607/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 608/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 609/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 610/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0548\n",
            "Epoch 611/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 612/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 613/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 614/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 615/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 616/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 617/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 618/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 619/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0548\n",
            "Epoch 620/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 621/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 622/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 623/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 624/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 625/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 626/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 627/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 628/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 629/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 630/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0547\n",
            "Epoch 631/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 632/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 633/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 634/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 635/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 636/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0546\n",
            "Epoch 637/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 638/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 639/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 640/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 641/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 642/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0549\n",
            "Epoch 643/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0550\n",
            "Epoch 644/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0548\n",
            "Epoch 645/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 646/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 647/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 648/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 649/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 650/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0807 - val_loss: 0.0548\n",
            "Epoch 651/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0807 - val_loss: 0.0547\n",
            "Epoch 652/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 653/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 654/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0549\n",
            "Epoch 655/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0548\n",
            "Epoch 656/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 657/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0548\n",
            "Epoch 658/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 659/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0546\n",
            "Epoch 660/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 661/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 662/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 663/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 664/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 665/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 666/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0546\n",
            "Epoch 667/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 668/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 669/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 670/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 671/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 672/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 673/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0548\n",
            "Epoch 674/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 675/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 676/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 677/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 678/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 679/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 680/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 681/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 682/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 683/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 684/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 685/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 686/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 687/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0547\n",
            "Epoch 688/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 689/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 690/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 691/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 692/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 693/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 694/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 695/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 696/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 697/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0549\n",
            "Epoch 698/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 699/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 700/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 701/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 702/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 703/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 704/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 705/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 706/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 707/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 708/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 709/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 710/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 711/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 712/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 713/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0547\n",
            "Epoch 714/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 715/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0549\n",
            "Epoch 716/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0550\n",
            "Epoch 717/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0549\n",
            "Epoch 718/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 719/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 720/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 721/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 722/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 723/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 724/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 725/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 726/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 727/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 728/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 729/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 730/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 731/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 732/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0545\n",
            "Epoch 733/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0807 - val_loss: 0.0546\n",
            "Epoch 734/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0546\n",
            "Epoch 735/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 736/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0545\n",
            "Epoch 737/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 738/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 739/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0545\n",
            "Epoch 740/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0545\n",
            "Epoch 741/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0545\n",
            "Epoch 742/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 743/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 744/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 745/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 746/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 747/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 748/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 749/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 750/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 751/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 752/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 753/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 754/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0545\n",
            "Epoch 755/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 756/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 757/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 758/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 759/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 760/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 761/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 762/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 763/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 764/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 765/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 766/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 767/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 768/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 769/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 770/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 771/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 772/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 773/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 774/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 775/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 776/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 777/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 778/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0549\n",
            "Epoch 779/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 780/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 781/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 782/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 783/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 784/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 785/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 786/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 787/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 788/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 789/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 790/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 791/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 792/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0807 - val_loss: 0.0546\n",
            "Epoch 793/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 794/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 795/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 796/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 797/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 798/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 799/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 800/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 801/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 802/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 803/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 804/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 805/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 806/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 807/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 808/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 809/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 810/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 811/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 812/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 813/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 814/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 815/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 816/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 817/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0546\n",
            "Epoch 818/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 819/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 820/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 821/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0808 - val_loss: 0.0546\n",
            "Epoch 822/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 823/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 824/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 825/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 826/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 827/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 828/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 829/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0546\n",
            "Epoch 830/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 831/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 832/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 833/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 834/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 835/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 836/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 837/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0547\n",
            "Epoch 838/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 839/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 840/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 841/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0807 - val_loss: 0.0548\n",
            "Epoch 842/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 843/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 844/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 845/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 846/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 847/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 848/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 849/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 850/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 851/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 852/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0547\n",
            "Epoch 853/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 854/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 855/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 856/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0547\n",
            "Epoch 857/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 858/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 859/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 860/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0807 - val_loss: 0.0547\n",
            "Epoch 861/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 862/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 863/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 864/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 865/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 866/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 867/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 868/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 869/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 870/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 871/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0549\n",
            "Epoch 872/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 873/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 874/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 875/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 876/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 877/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 878/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 879/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 880/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 881/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 882/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 883/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 884/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 885/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 886/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 887/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 888/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 889/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 890/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 891/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0547\n",
            "Epoch 892/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 893/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 894/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 895/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 896/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 897/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 898/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 899/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0545\n",
            "Epoch 900/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0545\n",
            "Epoch 901/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0545\n",
            "Epoch 902/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 903/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 904/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 905/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 906/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 907/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 908/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 909/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 910/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 911/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 912/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 913/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 914/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 915/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 916/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 917/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 918/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 919/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 920/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 921/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0547\n",
            "Epoch 922/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 923/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 924/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 925/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 926/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 927/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 928/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 929/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 930/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 931/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 932/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 933/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 934/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 935/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 936/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 937/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 938/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 939/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 940/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 941/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 942/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 943/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 944/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 945/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 946/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0808 - val_loss: 0.0548\n",
            "Epoch 947/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 948/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 949/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 950/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 951/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 952/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 953/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 954/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 955/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 956/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 957/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 958/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 959/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 960/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 961/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 962/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 963/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 964/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 965/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 966/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 967/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0548\n",
            "Epoch 968/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 969/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 970/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0546\n",
            "Epoch 971/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 972/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 973/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 974/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0548\n",
            "Epoch 975/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 976/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0808 - val_loss: 0.0548\n",
            "Epoch 977/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 978/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 979/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 980/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 981/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 982/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0545\n",
            "Epoch 983/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0545\n",
            "Epoch 984/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0545\n",
            "Epoch 985/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 986/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 987/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 988/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 989/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 990/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 991/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 992/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 993/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 994/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 995/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 996/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 997/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 998/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 999/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 1000/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fIAgccbrYmB",
        "outputId": "064b3e91-e57a-4d71-cff1-e85a42e0d156",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "deeper_history_dataframe2 = pd.DataFrame(deeper_model_history2.history)\n",
        "deeper_history_dataframe2['epoch'] = deeper_model_history2.epoch\n",
        "deeper_history_dataframe2.sort_values(by='val_loss', ascending=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>0.081794</td>\n",
              "      <td>0.053497</td>\n",
              "      <td>122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>0.082052</td>\n",
              "      <td>0.053498</td>\n",
              "      <td>121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>0.081659</td>\n",
              "      <td>0.053506</td>\n",
              "      <td>123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>0.082198</td>\n",
              "      <td>0.053537</td>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>0.082590</td>\n",
              "      <td>0.053552</td>\n",
              "      <td>119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.115315</td>\n",
              "      <td>0.071347</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.117031</td>\n",
              "      <td>0.072231</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.119238</td>\n",
              "      <td>0.073425</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.122271</td>\n",
              "      <td>0.075088</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.125722</td>\n",
              "      <td>0.077571</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         loss  val_loss  epoch\n",
              "122  0.081794  0.053497    122\n",
              "121  0.082052  0.053498    121\n",
              "123  0.081659  0.053506    123\n",
              "120  0.082198  0.053537    120\n",
              "119  0.082590  0.053552    119\n",
              "..        ...       ...    ...\n",
              "4    0.115315  0.071347      4\n",
              "3    0.117031  0.072231      3\n",
              "2    0.119238  0.073425      2\n",
              "1    0.122271  0.075088      1\n",
              "0    0.125722  0.077571      0\n",
              "\n",
              "[1000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51ViBoY1rYmE",
        "outputId": "599e033c-7bf1-4f99-c204-a22129b72b77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "plot_loss(deeper_model_history2) # epoch vs loss graph"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsnGgHEHrYmH"
      },
      "source": [
        "### Wider"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zM7S8YqrYmH",
        "outputId": "34ca5f62-b94c-4691-a7db-78f15e042021",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "neurons = 50\n",
        "epoch = 1000\n",
        "batch_size = 32\n",
        "\n",
        "wider_model2 = Sequential()\n",
        "wider_model2.add(Dense(neurons, activation='relu', input_dim=feature_train.shape[1]))\n",
        "wider_model2.add(Dense(1))\n",
        "wider_model2.compile(loss='mean_squared_error', optimizer='adam')\n",
        "wider_model_history2 = wider_model2.fit(feature_train, label_train, epochs=epoch, batch_size=batch_size, validation_data=(feature_test, label_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1052 - val_loss: 0.0642\n",
            "Epoch 2/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0964 - val_loss: 0.0599\n",
            "Epoch 3/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0907 - val_loss: 0.0576\n",
            "Epoch 4/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0879 - val_loss: 0.0567\n",
            "Epoch 5/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0862 - val_loss: 0.0563\n",
            "Epoch 6/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0853 - val_loss: 0.0558\n",
            "Epoch 7/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0846 - val_loss: 0.0557\n",
            "Epoch 8/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0839 - val_loss: 0.0553\n",
            "Epoch 9/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0833 - val_loss: 0.0552\n",
            "Epoch 10/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0830 - val_loss: 0.0549\n",
            "Epoch 11/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0825 - val_loss: 0.0549\n",
            "Epoch 12/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0824 - val_loss: 0.0545\n",
            "Epoch 13/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0820 - val_loss: 0.0549\n",
            "Epoch 14/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0819 - val_loss: 0.0550\n",
            "Epoch 15/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0819 - val_loss: 0.0547\n",
            "Epoch 16/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0816 - val_loss: 0.0547\n",
            "Epoch 17/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0816 - val_loss: 0.0544\n",
            "Epoch 18/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0814 - val_loss: 0.0545\n",
            "Epoch 19/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0814 - val_loss: 0.0541\n",
            "Epoch 20/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0812 - val_loss: 0.0541\n",
            "Epoch 21/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0811 - val_loss: 0.0546\n",
            "Epoch 22/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0811 - val_loss: 0.0549\n",
            "Epoch 23/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0809 - val_loss: 0.0544\n",
            "Epoch 24/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0810 - val_loss: 0.0542\n",
            "Epoch 25/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0810 - val_loss: 0.0543\n",
            "Epoch 26/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0809 - val_loss: 0.0545\n",
            "Epoch 27/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0808 - val_loss: 0.0546\n",
            "Epoch 28/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0809 - val_loss: 0.0545\n",
            "Epoch 29/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0808 - val_loss: 0.0549\n",
            "Epoch 30/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0809 - val_loss: 0.0545\n",
            "Epoch 31/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0808 - val_loss: 0.0549\n",
            "Epoch 32/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0808 - val_loss: 0.0546\n",
            "Epoch 33/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0808 - val_loss: 0.0550\n",
            "Epoch 34/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0808 - val_loss: 0.0547\n",
            "Epoch 35/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0550\n",
            "Epoch 36/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0547\n",
            "Epoch 37/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0545\n",
            "Epoch 38/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0544\n",
            "Epoch 39/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0808 - val_loss: 0.0549\n",
            "Epoch 40/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 41/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0809 - val_loss: 0.0540\n",
            "Epoch 42/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0809 - val_loss: 0.0547\n",
            "Epoch 43/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0547\n",
            "Epoch 44/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 45/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0547\n",
            "Epoch 46/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 47/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0544\n",
            "Epoch 48/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0544\n",
            "Epoch 49/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0547\n",
            "Epoch 50/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0549\n",
            "Epoch 51/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 52/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 53/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0551\n",
            "Epoch 54/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0807 - val_loss: 0.0547\n",
            "Epoch 55/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 56/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0547\n",
            "Epoch 57/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0548\n",
            "Epoch 58/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0546\n",
            "Epoch 59/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0542\n",
            "Epoch 60/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0545\n",
            "Epoch 61/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 62/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0549\n",
            "Epoch 63/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0543\n",
            "Epoch 64/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0543\n",
            "Epoch 65/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0545\n",
            "Epoch 66/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0807 - val_loss: 0.0548\n",
            "Epoch 67/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0543\n",
            "Epoch 68/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0544\n",
            "Epoch 69/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0808 - val_loss: 0.0549\n",
            "Epoch 70/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0545\n",
            "Epoch 71/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0545\n",
            "Epoch 72/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0546\n",
            "Epoch 73/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0547\n",
            "Epoch 74/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0545\n",
            "Epoch 75/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0545\n",
            "Epoch 76/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0543\n",
            "Epoch 77/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0542\n",
            "Epoch 78/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0547\n",
            "Epoch 79/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0551\n",
            "Epoch 80/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0545\n",
            "Epoch 81/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0544\n",
            "Epoch 82/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0545\n",
            "Epoch 83/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0546\n",
            "Epoch 84/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0551\n",
            "Epoch 85/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0552\n",
            "Epoch 86/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0547\n",
            "Epoch 87/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 88/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0544\n",
            "Epoch 89/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 90/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0551\n",
            "Epoch 91/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0553\n",
            "Epoch 92/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0549\n",
            "Epoch 93/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0543\n",
            "Epoch 94/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0544\n",
            "Epoch 95/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0543\n",
            "Epoch 96/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 97/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0551\n",
            "Epoch 98/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0554\n",
            "Epoch 99/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0552\n",
            "Epoch 100/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0545\n",
            "Epoch 101/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0548\n",
            "Epoch 102/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0544\n",
            "Epoch 103/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0544\n",
            "Epoch 104/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0544\n",
            "Epoch 105/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 106/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0552\n",
            "Epoch 107/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0551\n",
            "Epoch 108/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0546\n",
            "Epoch 109/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 110/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0552\n",
            "Epoch 111/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 112/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 113/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0551\n",
            "Epoch 114/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0544\n",
            "Epoch 115/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0545\n",
            "Epoch 116/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0545\n",
            "Epoch 117/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 118/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 119/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0552\n",
            "Epoch 120/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0552\n",
            "Epoch 121/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0546\n",
            "Epoch 122/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0545\n",
            "Epoch 123/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0543\n",
            "Epoch 124/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0548\n",
            "Epoch 125/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0546\n",
            "Epoch 126/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0547\n",
            "Epoch 127/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0550\n",
            "Epoch 128/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0545\n",
            "Epoch 129/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 130/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 131/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0552\n",
            "Epoch 132/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 133/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0550\n",
            "Epoch 134/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 135/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0545\n",
            "Epoch 136/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0548\n",
            "Epoch 137/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0551\n",
            "Epoch 138/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 139/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 140/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 141/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0549\n",
            "Epoch 142/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 143/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0545\n",
            "Epoch 144/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 145/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 146/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 147/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 148/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 149/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0551\n",
            "Epoch 150/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 151/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 152/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0552\n",
            "Epoch 153/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 154/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 155/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0547\n",
            "Epoch 156/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 157/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0545\n",
            "Epoch 158/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0548\n",
            "Epoch 159/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0552\n",
            "Epoch 160/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0548\n",
            "Epoch 161/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0550\n",
            "Epoch 162/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0811 - val_loss: 0.0542\n",
            "Epoch 163/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0810 - val_loss: 0.0556\n",
            "Epoch 164/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0550\n",
            "Epoch 165/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 166/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0544\n",
            "Epoch 167/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0545\n",
            "Epoch 168/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 169/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 170/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0552\n",
            "Epoch 171/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 172/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0545\n",
            "Epoch 173/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0545\n",
            "Epoch 174/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 175/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0552\n",
            "Epoch 176/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0552\n",
            "Epoch 177/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0553\n",
            "Epoch 178/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0552\n",
            "Epoch 179/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0552\n",
            "Epoch 180/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 181/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 182/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 183/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 184/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0551\n",
            "Epoch 185/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 186/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0553\n",
            "Epoch 187/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 188/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 189/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0544\n",
            "Epoch 190/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0549\n",
            "Epoch 191/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 192/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 193/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 194/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0545\n",
            "Epoch 195/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 196/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 197/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 198/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 199/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 200/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 201/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 202/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0551\n",
            "Epoch 203/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0547\n",
            "Epoch 204/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 205/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0550\n",
            "Epoch 206/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 207/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0545\n",
            "Epoch 208/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 209/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 210/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0551\n",
            "Epoch 211/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0554\n",
            "Epoch 212/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 213/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 214/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 215/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0544\n",
            "Epoch 216/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 217/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0544\n",
            "Epoch 218/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0555\n",
            "Epoch 219/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0554\n",
            "Epoch 220/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 221/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 222/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0544\n",
            "Epoch 223/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 224/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0549\n",
            "Epoch 225/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 226/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 227/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 228/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 229/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 230/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0546\n",
            "Epoch 231/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 232/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0551\n",
            "Epoch 233/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0551\n",
            "Epoch 234/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0551\n",
            "Epoch 235/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 236/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 237/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 238/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 239/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 240/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0545\n",
            "Epoch 241/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0542\n",
            "Epoch 242/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0547\n",
            "Epoch 243/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 244/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 245/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 246/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0550\n",
            "Epoch 247/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 248/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 249/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0549\n",
            "Epoch 250/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 251/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 252/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 253/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0554\n",
            "Epoch 254/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0554\n",
            "Epoch 255/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0555\n",
            "Epoch 256/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 257/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 258/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 259/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 260/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 261/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 262/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 263/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 264/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 265/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 266/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0553\n",
            "Epoch 267/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0549\n",
            "Epoch 268/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 269/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0551\n",
            "Epoch 270/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 271/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0550\n",
            "Epoch 272/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0545\n",
            "Epoch 273/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 274/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0551\n",
            "Epoch 275/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 276/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0553\n",
            "Epoch 277/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0554\n",
            "Epoch 278/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 279/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 280/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0545\n",
            "Epoch 281/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0556\n",
            "Epoch 282/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0550\n",
            "Epoch 283/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0552\n",
            "Epoch 284/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 285/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 286/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0547\n",
            "Epoch 287/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 288/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 289/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 290/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0545\n",
            "Epoch 291/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0551\n",
            "Epoch 292/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0552\n",
            "Epoch 293/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 294/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 295/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 296/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 297/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0547\n",
            "Epoch 298/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 299/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0553\n",
            "Epoch 300/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 301/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0553\n",
            "Epoch 302/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 303/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 304/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0550\n",
            "Epoch 305/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0554\n",
            "Epoch 306/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0557\n",
            "Epoch 307/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 308/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 309/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0551\n",
            "Epoch 310/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 311/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0802 - val_loss: 0.0548\n",
            "Epoch 312/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0551\n",
            "Epoch 313/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 314/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0551\n",
            "Epoch 315/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 316/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 317/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0552\n",
            "Epoch 318/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0553\n",
            "Epoch 319/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0552\n",
            "Epoch 320/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 321/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0551\n",
            "Epoch 322/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0551\n",
            "Epoch 323/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 324/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0551\n",
            "Epoch 325/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0544\n",
            "Epoch 326/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 327/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 328/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0552\n",
            "Epoch 329/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 330/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 331/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0550\n",
            "Epoch 332/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 333/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0551\n",
            "Epoch 334/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 335/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 336/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 337/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0550\n",
            "Epoch 338/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0802 - val_loss: 0.0551\n",
            "Epoch 339/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 340/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 341/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 342/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 343/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0553\n",
            "Epoch 344/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0553\n",
            "Epoch 345/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0555\n",
            "Epoch 346/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0548\n",
            "Epoch 347/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0546\n",
            "Epoch 348/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 349/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0551\n",
            "Epoch 350/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 351/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0551\n",
            "Epoch 352/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 353/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 354/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0552\n",
            "Epoch 355/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0549\n",
            "Epoch 356/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0544\n",
            "Epoch 357/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 358/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 359/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0554\n",
            "Epoch 360/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0555\n",
            "Epoch 361/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0552\n",
            "Epoch 362/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 363/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 364/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0553\n",
            "Epoch 365/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0547\n",
            "Epoch 366/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 367/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0550\n",
            "Epoch 368/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0551\n",
            "Epoch 369/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0548\n",
            "Epoch 370/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 371/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0552\n",
            "Epoch 372/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0554\n",
            "Epoch 373/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0551\n",
            "Epoch 374/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 375/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0553\n",
            "Epoch 376/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 377/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0553\n",
            "Epoch 378/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0548\n",
            "Epoch 379/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 380/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0553\n",
            "Epoch 381/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 382/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 383/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0552\n",
            "Epoch 384/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0554\n",
            "Epoch 385/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0551\n",
            "Epoch 386/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0556\n",
            "Epoch 387/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0553\n",
            "Epoch 388/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0549\n",
            "Epoch 389/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 390/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 391/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0554\n",
            "Epoch 392/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0553\n",
            "Epoch 393/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0552\n",
            "Epoch 394/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0556\n",
            "Epoch 395/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0552\n",
            "Epoch 396/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 397/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0551\n",
            "Epoch 398/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0557\n",
            "Epoch 399/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0552\n",
            "Epoch 400/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0555\n",
            "Epoch 401/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0554\n",
            "Epoch 402/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 403/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 404/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 405/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0555\n",
            "Epoch 406/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 407/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0802 - val_loss: 0.0548\n",
            "Epoch 408/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0550\n",
            "Epoch 409/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0554\n",
            "Epoch 410/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0553\n",
            "Epoch 411/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0550\n",
            "Epoch 412/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0551\n",
            "Epoch 413/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0548\n",
            "Epoch 414/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0550\n",
            "Epoch 415/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0550\n",
            "Epoch 416/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 417/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0551\n",
            "Epoch 418/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 419/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0550\n",
            "Epoch 420/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0550\n",
            "Epoch 421/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 422/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0551\n",
            "Epoch 423/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0552\n",
            "Epoch 424/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0553\n",
            "Epoch 425/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0552\n",
            "Epoch 426/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 427/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0551\n",
            "Epoch 428/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 429/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0548\n",
            "Epoch 430/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0549\n",
            "Epoch 431/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0547\n",
            "Epoch 432/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 433/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0549\n",
            "Epoch 434/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0551\n",
            "Epoch 435/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0557\n",
            "Epoch 436/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 437/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 438/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 439/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0553\n",
            "Epoch 440/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 441/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0549\n",
            "Epoch 442/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 443/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 444/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 445/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 446/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 447/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 448/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0551\n",
            "Epoch 449/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0552\n",
            "Epoch 450/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0548\n",
            "Epoch 451/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 452/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 453/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 454/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0802 - val_loss: 0.0551\n",
            "Epoch 455/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 456/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0554\n",
            "Epoch 457/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0555\n",
            "Epoch 458/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0557\n",
            "Epoch 459/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0552\n",
            "Epoch 460/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 461/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0547\n",
            "Epoch 462/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0553\n",
            "Epoch 463/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 464/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0551\n",
            "Epoch 465/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 466/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0553\n",
            "Epoch 467/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0551\n",
            "Epoch 468/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0551\n",
            "Epoch 469/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0545\n",
            "Epoch 470/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 471/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0552\n",
            "Epoch 472/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0552\n",
            "Epoch 473/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0557\n",
            "Epoch 474/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0555\n",
            "Epoch 475/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 476/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 477/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 478/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0801 - val_loss: 0.0555\n",
            "Epoch 479/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0556\n",
            "Epoch 480/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0553\n",
            "Epoch 481/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0552\n",
            "Epoch 482/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0553\n",
            "Epoch 483/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0555\n",
            "Epoch 484/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0555\n",
            "Epoch 485/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 486/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 487/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0554\n",
            "Epoch 488/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0550\n",
            "Epoch 489/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0551\n",
            "Epoch 490/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 491/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0552\n",
            "Epoch 492/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0555\n",
            "Epoch 493/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0552\n",
            "Epoch 494/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0556\n",
            "Epoch 495/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0802 - val_loss: 0.0554\n",
            "Epoch 496/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 497/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0554\n",
            "Epoch 498/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0555\n",
            "Epoch 499/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0556\n",
            "Epoch 500/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 501/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0808 - val_loss: 0.0546\n",
            "Epoch 502/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0553\n",
            "Epoch 503/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 504/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0555\n",
            "Epoch 505/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0556\n",
            "Epoch 506/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0552\n",
            "Epoch 507/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0552\n",
            "Epoch 508/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 509/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0551\n",
            "Epoch 510/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0550\n",
            "Epoch 511/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0551\n",
            "Epoch 512/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 513/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0556\n",
            "Epoch 514/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 515/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 516/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 517/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 518/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0551\n",
            "Epoch 519/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 520/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0552\n",
            "Epoch 521/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 522/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0553\n",
            "Epoch 523/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 524/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0549\n",
            "Epoch 525/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 526/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0802 - val_loss: 0.0554\n",
            "Epoch 527/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 528/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0554\n",
            "Epoch 529/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 530/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0551\n",
            "Epoch 531/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0802 - val_loss: 0.0549\n",
            "Epoch 532/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 533/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 534/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0552\n",
            "Epoch 535/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 536/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0549\n",
            "Epoch 537/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0552\n",
            "Epoch 538/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 539/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 540/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0549\n",
            "Epoch 541/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0550\n",
            "Epoch 542/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0551\n",
            "Epoch 543/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0550\n",
            "Epoch 544/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 545/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0556\n",
            "Epoch 546/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0555\n",
            "Epoch 547/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 548/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0555\n",
            "Epoch 549/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0551\n",
            "Epoch 550/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0802 - val_loss: 0.0551\n",
            "Epoch 551/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 552/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0553\n",
            "Epoch 553/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0550\n",
            "Epoch 554/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0549\n",
            "Epoch 555/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0551\n",
            "Epoch 556/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 557/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0552\n",
            "Epoch 558/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 559/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0554\n",
            "Epoch 560/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0554\n",
            "Epoch 561/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 562/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 563/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 564/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0552\n",
            "Epoch 565/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0558\n",
            "Epoch 566/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0557\n",
            "Epoch 567/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0550\n",
            "Epoch 568/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0547\n",
            "Epoch 569/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0551\n",
            "Epoch 570/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0802 - val_loss: 0.0555\n",
            "Epoch 571/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0558\n",
            "Epoch 572/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0555\n",
            "Epoch 573/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0554\n",
            "Epoch 574/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0554\n",
            "Epoch 575/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0553\n",
            "Epoch 576/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0554\n",
            "Epoch 577/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 578/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 579/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 580/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0556\n",
            "Epoch 581/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0558\n",
            "Epoch 582/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 583/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0549\n",
            "Epoch 584/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0550\n",
            "Epoch 585/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0554\n",
            "Epoch 586/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0561\n",
            "Epoch 587/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 588/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 589/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0549\n",
            "Epoch 590/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0552\n",
            "Epoch 591/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 592/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0555\n",
            "Epoch 593/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0560\n",
            "Epoch 594/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0554\n",
            "Epoch 595/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0552\n",
            "Epoch 596/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0557\n",
            "Epoch 597/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0563\n",
            "Epoch 598/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0562\n",
            "Epoch 599/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 600/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 601/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 602/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 603/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0552\n",
            "Epoch 604/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0554\n",
            "Epoch 605/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0554\n",
            "Epoch 606/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 607/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0554\n",
            "Epoch 608/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 609/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 610/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 611/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0555\n",
            "Epoch 612/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0554\n",
            "Epoch 613/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0551\n",
            "Epoch 614/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 615/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0551\n",
            "Epoch 616/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0554\n",
            "Epoch 617/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 618/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0552\n",
            "Epoch 619/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 620/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0550\n",
            "Epoch 621/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0802 - val_loss: 0.0551\n",
            "Epoch 622/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 623/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0554\n",
            "Epoch 624/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0555\n",
            "Epoch 625/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 626/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0555\n",
            "Epoch 627/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0555\n",
            "Epoch 628/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0551\n",
            "Epoch 629/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 630/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0551\n",
            "Epoch 631/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 632/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 633/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0552\n",
            "Epoch 634/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 635/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0554\n",
            "Epoch 636/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0556\n",
            "Epoch 637/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0551\n",
            "Epoch 638/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0550\n",
            "Epoch 639/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0554\n",
            "Epoch 640/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 641/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0557\n",
            "Epoch 642/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0554\n",
            "Epoch 643/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0556\n",
            "Epoch 644/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0553\n",
            "Epoch 645/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0802 - val_loss: 0.0556\n",
            "Epoch 646/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 647/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0802 - val_loss: 0.0551\n",
            "Epoch 648/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0555\n",
            "Epoch 649/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 650/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0802 - val_loss: 0.0550\n",
            "Epoch 651/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0554\n",
            "Epoch 652/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0550\n",
            "Epoch 653/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 654/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0554\n",
            "Epoch 655/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0551\n",
            "Epoch 656/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 657/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0555\n",
            "Epoch 658/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0555\n",
            "Epoch 659/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 660/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 661/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0555\n",
            "Epoch 662/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 663/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 664/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 665/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 666/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0557\n",
            "Epoch 667/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0553\n",
            "Epoch 668/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 669/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0551\n",
            "Epoch 670/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 671/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0801 - val_loss: 0.0557\n",
            "Epoch 672/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0557\n",
            "Epoch 673/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0556\n",
            "Epoch 674/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0558\n",
            "Epoch 675/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0549\n",
            "Epoch 676/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0552\n",
            "Epoch 677/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0551\n",
            "Epoch 678/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0554\n",
            "Epoch 679/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0556\n",
            "Epoch 680/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0802 - val_loss: 0.0554\n",
            "Epoch 681/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 682/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 683/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0553\n",
            "Epoch 684/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0552\n",
            "Epoch 685/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0553\n",
            "Epoch 686/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0554\n",
            "Epoch 687/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 688/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0551\n",
            "Epoch 689/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 690/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0549\n",
            "Epoch 691/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0558\n",
            "Epoch 692/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0561\n",
            "Epoch 693/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0560\n",
            "Epoch 694/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0556\n",
            "Epoch 695/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 696/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 697/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0555\n",
            "Epoch 698/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0554\n",
            "Epoch 699/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0552\n",
            "Epoch 700/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 701/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0551\n",
            "Epoch 702/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 703/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0553\n",
            "Epoch 704/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0551\n",
            "Epoch 705/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 706/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0560\n",
            "Epoch 707/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 708/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 709/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0550\n",
            "Epoch 710/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 711/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0558\n",
            "Epoch 712/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0555\n",
            "Epoch 713/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0551\n",
            "Epoch 714/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 715/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0550\n",
            "Epoch 716/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0560\n",
            "Epoch 717/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0559\n",
            "Epoch 718/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0551\n",
            "Epoch 719/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0548\n",
            "Epoch 720/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 721/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0559\n",
            "Epoch 722/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0556\n",
            "Epoch 723/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0554\n",
            "Epoch 724/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 725/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 726/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 727/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0556\n",
            "Epoch 728/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0555\n",
            "Epoch 729/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 730/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 731/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0558\n",
            "Epoch 732/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 733/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 734/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0553\n",
            "Epoch 735/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0554\n",
            "Epoch 736/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0551\n",
            "Epoch 737/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0550\n",
            "Epoch 738/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0557\n",
            "Epoch 739/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0554\n",
            "Epoch 740/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 741/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0551\n",
            "Epoch 742/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 743/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0552\n",
            "Epoch 744/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0553\n",
            "Epoch 745/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0554\n",
            "Epoch 746/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0552\n",
            "Epoch 747/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0551\n",
            "Epoch 748/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0549\n",
            "Epoch 749/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0800 - val_loss: 0.0556\n",
            "Epoch 750/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0563\n",
            "Epoch 751/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0554\n",
            "Epoch 752/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0555\n",
            "Epoch 753/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0554\n",
            "Epoch 754/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0556\n",
            "Epoch 755/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0551\n",
            "Epoch 756/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 757/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0557\n",
            "Epoch 758/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0554\n",
            "Epoch 759/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 760/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0551\n",
            "Epoch 761/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0550\n",
            "Epoch 762/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0551\n",
            "Epoch 763/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0549\n",
            "Epoch 764/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0551\n",
            "Epoch 765/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0555\n",
            "Epoch 766/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0553\n",
            "Epoch 767/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0551\n",
            "Epoch 768/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 769/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0554\n",
            "Epoch 770/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 771/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 772/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0552\n",
            "Epoch 773/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0555\n",
            "Epoch 774/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0554\n",
            "Epoch 775/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0554\n",
            "Epoch 776/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0555\n",
            "Epoch 777/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0553\n",
            "Epoch 778/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0553\n",
            "Epoch 779/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0801 - val_loss: 0.0553\n",
            "Epoch 780/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0551\n",
            "Epoch 781/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 782/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0556\n",
            "Epoch 783/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0556\n",
            "Epoch 784/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0552\n",
            "Epoch 785/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0554\n",
            "Epoch 786/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0556\n",
            "Epoch 787/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0551\n",
            "Epoch 788/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0555\n",
            "Epoch 789/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0558\n",
            "Epoch 790/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0557\n",
            "Epoch 791/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0549\n",
            "Epoch 792/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0551\n",
            "Epoch 793/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 794/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0555\n",
            "Epoch 795/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0556\n",
            "Epoch 796/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0555\n",
            "Epoch 797/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0560\n",
            "Epoch 798/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0555\n",
            "Epoch 799/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 800/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0553\n",
            "Epoch 801/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 802/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0547\n",
            "Epoch 803/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 804/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0553\n",
            "Epoch 805/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 806/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0553\n",
            "Epoch 807/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0554\n",
            "Epoch 808/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0552\n",
            "Epoch 809/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 810/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0551\n",
            "Epoch 811/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0555\n",
            "Epoch 812/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0556\n",
            "Epoch 813/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0556\n",
            "Epoch 814/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0551\n",
            "Epoch 815/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 816/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0801 - val_loss: 0.0554\n",
            "Epoch 817/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0556\n",
            "Epoch 818/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0559\n",
            "Epoch 819/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0560\n",
            "Epoch 820/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0552\n",
            "Epoch 821/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 822/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0553\n",
            "Epoch 823/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0554\n",
            "Epoch 824/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 825/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 826/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 827/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0552\n",
            "Epoch 828/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0555\n",
            "Epoch 829/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0557\n",
            "Epoch 830/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0555\n",
            "Epoch 831/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0555\n",
            "Epoch 832/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 833/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0555\n",
            "Epoch 834/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0802 - val_loss: 0.0557\n",
            "Epoch 835/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0557\n",
            "Epoch 836/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 837/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0551\n",
            "Epoch 838/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0554\n",
            "Epoch 839/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0554\n",
            "Epoch 840/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0561\n",
            "Epoch 841/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 842/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0801 - val_loss: 0.0553\n",
            "Epoch 843/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0551\n",
            "Epoch 844/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 845/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 846/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 847/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0558\n",
            "Epoch 848/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0556\n",
            "Epoch 849/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0554\n",
            "Epoch 850/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0554\n",
            "Epoch 851/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0551\n",
            "Epoch 852/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0551\n",
            "Epoch 853/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0557\n",
            "Epoch 854/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0554\n",
            "Epoch 855/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0558\n",
            "Epoch 856/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0802 - val_loss: 0.0555\n",
            "Epoch 857/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 858/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0553\n",
            "Epoch 859/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0555\n",
            "Epoch 860/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 861/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0552\n",
            "Epoch 862/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 863/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0556\n",
            "Epoch 864/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0554\n",
            "Epoch 865/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0558\n",
            "Epoch 866/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 867/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0551\n",
            "Epoch 868/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0551\n",
            "Epoch 869/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0551\n",
            "Epoch 870/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0553\n",
            "Epoch 871/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0555\n",
            "Epoch 872/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0555\n",
            "Epoch 873/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0551\n",
            "Epoch 874/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0557\n",
            "Epoch 875/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0802 - val_loss: 0.0556\n",
            "Epoch 876/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0559\n",
            "Epoch 877/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0554\n",
            "Epoch 878/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0559\n",
            "Epoch 879/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0556\n",
            "Epoch 880/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0554\n",
            "Epoch 881/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 882/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 883/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0551\n",
            "Epoch 884/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0557\n",
            "Epoch 885/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0556\n",
            "Epoch 886/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0556\n",
            "Epoch 887/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0555\n",
            "Epoch 888/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0554\n",
            "Epoch 889/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0558\n",
            "Epoch 890/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0553\n",
            "Epoch 891/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0556\n",
            "Epoch 892/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0554\n",
            "Epoch 893/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0553\n",
            "Epoch 894/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0554\n",
            "Epoch 895/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0552\n",
            "Epoch 896/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0553\n",
            "Epoch 897/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0554\n",
            "Epoch 898/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 899/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0557\n",
            "Epoch 900/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0555\n",
            "Epoch 901/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0552\n",
            "Epoch 902/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0551\n",
            "Epoch 903/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0553\n",
            "Epoch 904/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0556\n",
            "Epoch 905/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0555\n",
            "Epoch 906/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0554\n",
            "Epoch 907/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0551\n",
            "Epoch 908/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 909/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0553\n",
            "Epoch 910/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0554\n",
            "Epoch 911/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0551\n",
            "Epoch 912/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 913/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0551\n",
            "Epoch 914/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0554\n",
            "Epoch 915/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0556\n",
            "Epoch 916/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0551\n",
            "Epoch 917/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 918/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0553\n",
            "Epoch 919/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 920/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 921/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0556\n",
            "Epoch 922/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0557\n",
            "Epoch 923/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0559\n",
            "Epoch 924/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0556\n",
            "Epoch 925/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 926/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0551\n",
            "Epoch 927/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0555\n",
            "Epoch 928/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0557\n",
            "Epoch 929/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0559\n",
            "Epoch 930/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0554\n",
            "Epoch 931/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0555\n",
            "Epoch 932/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0551\n",
            "Epoch 933/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0555\n",
            "Epoch 934/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0559\n",
            "Epoch 935/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0558\n",
            "Epoch 936/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0555\n",
            "Epoch 937/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0555\n",
            "Epoch 938/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 939/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0554\n",
            "Epoch 940/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 941/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0801 - val_loss: 0.0556\n",
            "Epoch 942/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0802 - val_loss: 0.0555\n",
            "Epoch 943/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0802 - val_loss: 0.0556\n",
            "Epoch 944/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 945/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0552\n",
            "Epoch 946/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 947/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 948/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0558\n",
            "Epoch 949/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0554\n",
            "Epoch 950/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 951/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0552\n",
            "Epoch 952/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0553\n",
            "Epoch 953/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 954/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0554\n",
            "Epoch 955/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0556\n",
            "Epoch 956/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0554\n",
            "Epoch 957/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0554\n",
            "Epoch 958/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0556\n",
            "Epoch 959/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0557\n",
            "Epoch 960/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 961/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0551\n",
            "Epoch 962/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 963/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0555\n",
            "Epoch 964/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0549\n",
            "Epoch 965/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0552\n",
            "Epoch 966/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0552\n",
            "Epoch 967/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 968/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0554\n",
            "Epoch 969/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0555\n",
            "Epoch 970/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 971/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 972/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0551\n",
            "Epoch 973/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0552\n",
            "Epoch 974/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0562\n",
            "Epoch 975/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0558\n",
            "Epoch 976/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0554\n",
            "Epoch 977/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 978/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0557\n",
            "Epoch 979/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 980/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 981/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0557\n",
            "Epoch 982/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 983/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0802 - val_loss: 0.0549\n",
            "Epoch 984/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0802 - val_loss: 0.0551\n",
            "Epoch 985/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0555\n",
            "Epoch 986/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0556\n",
            "Epoch 987/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0558\n",
            "Epoch 988/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0555\n",
            "Epoch 989/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0553\n",
            "Epoch 990/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0557\n",
            "Epoch 991/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0556\n",
            "Epoch 992/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 993/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0551\n",
            "Epoch 994/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0800 - val_loss: 0.0560\n",
            "Epoch 995/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0560\n",
            "Epoch 996/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0557\n",
            "Epoch 997/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0801 - val_loss: 0.0556\n",
            "Epoch 998/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0555\n",
            "Epoch 999/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0557\n",
            "Epoch 1000/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0555\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCvtGDXrrYmJ",
        "outputId": "e090410f-4576-46cb-8c23-4b4e1a49b2c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "wider_history_dataframe2 = pd.DataFrame(wider_model_history2.history)\n",
        "wider_history_dataframe2['epoch'] = wider_model_history2.epoch\n",
        "wider_history_dataframe2.sort_values(by='val_loss', ascending=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.080864</td>\n",
              "      <td>0.054021</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.081218</td>\n",
              "      <td>0.054137</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.081393</td>\n",
              "      <td>0.054145</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>240</th>\n",
              "      <td>0.080472</td>\n",
              "      <td>0.054203</td>\n",
              "      <td>240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>0.081138</td>\n",
              "      <td>0.054208</td>\n",
              "      <td>161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>596</th>\n",
              "      <td>0.080470</td>\n",
              "      <td>0.056347</td>\n",
              "      <td>596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.087872</td>\n",
              "      <td>0.056670</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.090694</td>\n",
              "      <td>0.057574</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.096373</td>\n",
              "      <td>0.059862</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.105209</td>\n",
              "      <td>0.064159</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         loss  val_loss  epoch\n",
              "40   0.080864  0.054021     40\n",
              "19   0.081218  0.054137     19\n",
              "18   0.081393  0.054145     18\n",
              "240  0.080472  0.054203    240\n",
              "161  0.081138  0.054208    161\n",
              "..        ...       ...    ...\n",
              "596  0.080470  0.056347    596\n",
              "3    0.087872  0.056670      3\n",
              "2    0.090694  0.057574      2\n",
              "1    0.096373  0.059862      1\n",
              "0    0.105209  0.064159      0\n",
              "\n",
              "[1000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbwNy7vhFz-I",
        "outputId": "6b517042-cb23-4a61-ad6a-f385dbd60ef9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "plot_loss(wider_model_history2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXhU5fXA8e/JZJKQlRAgIKCAqKyKGnDHuFSxVtG6IFqLu7W1alv9lWrr0lq72GqrtS6te13rUqlS0SpxpQrIvu+QkAgJISQh68z5/fHeJEOYkIUMk+V8nmeezF3nvHMn99z3fe8iqooxxhjTWEy0AzDGGNMxWYIwxhgTliUIY4wxYVmCMMYYE5YlCGOMMWHFRjuA9tK7d28dPHhwm5cvLy8nKSmp/QLq4LpbecHK3F1YmVtn3rx5haraJ9y0LpMgBg8ezNy5c9u8fE5ODtnZ2e0XUAfX3coLVubuwsrcOiKysalp1sRkjDEmLEsQxhhjwrIEYYwxJqwu0wdhjOmeampqyM3NpbKyEoC0tDSWL18e5aj2r5aUOSEhgYEDB+L3+1u8XksQxphOLTc3l5SUFAYPHoyIUFpaSkpKSrTD2q+aK7OqUlRURG5uLkOGDGnxeq2JyRjTqVVWVpKRkYGIRDuUDktEyMjIqK9ltZQlCGNMp2fJoXlt+Y66fRNTfkkFL36xiQE1wWiHYowxHUq3r0Fs3VnFwx+uoaDcEoQxpm2Sk5OjHUJEdPsE4Ytx1S57bJIxxuyu2yeIuma5oGUIY8w+UlVuu+02Ro8ezZgxY3jllVcAyM/PZ8KECYwdO5bRo0fzySefEAgEuOKKK+rnffDBB6Mc/Z66fR9EXQ3CEoQxnd89/17K4s3F+Hy+dlvnyANSueucUS2a94033mDBggUsXLiQwsJCxo0bx4QJE3jxxRc588wzueOOOwgEAuzatYsFCxaQl5fHkiVLANixY0e7xdxeun0NwieWIIwx7ePTTz9lypQp+Hw+MjMzOfnkk5kzZw7jxo3j6aef5u6772bx4sWkpKQwdOhQ1q1bxw9/+EPeffddUlNTox3+Hrp9DSLGahDGdBl3nTOqQ14oN2HCBD7++GPeeecdrrjiCn784x/z3e9+l4ULFzJz5kwee+wxXn31VZ566qloh7obq0GIdVIbY9rHSSedxCuvvEIgEGDbtm18/PHHjB8/no0bN5KZmcm1117LNddcw1dffUVhYSHBYJALLriAe++9l6+++ira4e/BahD1TUyWIowx++b8889n9uzZHHHEEYgIv//97+nXrx/PPvss999/P36/n+TkZJ577jny8vK48sorCQbdKfa/+c1vohz9nixBeHUoa2IyxrRVWVkZ4K5Wvv/++7n//vt3mz516lSmTp26x3IdsdYQypqYrA/CGGPCsgRhZzEZY0xY3T5BiHVSG2NMWN0+QVgTkzHGhGcJwpqYjDEmrG6fIOwsJmOMCa/bJ4iGu7lahjDGmFDdPkHEWBOTMWY/2tuzIzZs2MDo0aP3YzR7F9EEISITRWSliKwRkWlhpk8Qka9EpFZELmw0baqIrPZee15h0k4sQRhjTHgRu5JaRHzAI8A3gFxgjohMV9VlIbNtAq4Abm20bC/gLiALdwbqPG/Z4vaOs76JyRKEMZ3ff6bRI28++Npx19ZvDJz12yYnT5s2jUGDBvGDH/wAgLvvvpvY2FhmzZpFcXExNTU13HvvvUyaNKlVH1tZWckNN9zA3LlziY2N5YEHHuCUU05h6dKlXHnllVRXVxMMBnn99ddJSUnhkksuITc3l0AgwC9+8QsmT568T8WGyN5qYzywRlXXAYjIy8AkoD5BqOoGb1rj532eCbyvqtu96e8DE4GX2jvIGHtgkDFmH0yePJlbbrmlPkG8+uqrzJw5k5tuuonU1FQKCws59thjOffcc+uvu2qJRx55BBFh8eLFrFixgjPOOINVq1bx2GOPcfPNN3PZZZdRXV1NIBDg9ddf54ADDuCdd94BoKSkpF3KFskEMQDYHDKcCxyzD8sOaDyTiFwHXAeQmZlJTk5OmwIVoKq6us3Ld0ZlZWXdqrxgZe6q0tLSKC0tdQMnugfytOcDgwCoW38Yw4YNo6CggFWrVlFYWEhqaipJSUnceuutfP7558TExJCXl8fatWvJzMz0Vhd+fWVlZQSDQUpLS8nJyeH666+ntLSUAQMGMHDgQObPn8/YsWO59957Wbt2Leeccw7Dhg1j+PDh3HHHHfzoRz9i4sSJHH/88WE/o7KyslW/h059sz5VfQJ4AiArK0uzs7PbtB7fezOI9ftp6/KdUU5OTrcqL1iZu6rly5fv9vyHaDwPYvLkybz77rsUFBRw6aWXMn36dEpKSpg/fz5+v5/BgwcTGxtbH1dT8SUnJxMTE0NKSgqxsbEkJibWz+vz+UhKSuLqq68mOzubd955h4svvpjHH3+ccePGMX/+fGbMmMF9993Haaedxp133rnH+hMSEjjyyCNbXK5IdlLnAYNChgd64yK9bKvFxIg1MRlj2mzy5Mm8/PLLvPbaa1x00UWUlJTQt29f/H4/s2bNYuPGja1e50knncQLL7wAwKpVq9i0aROHHXYY69atY+jQodx0001MmjSJRYsWkZ+fT2JiIt/5zne47bbb2u0usZGsQcwBDhGRIbid+yXApS1cdiZwn4ike8NnAD9r/xAdn4g9D8IY02ajRo2qbwrq378/l112Geeccw5jxowhKyuL4cOHt3qd3//+97nhhhsYM2YMsbGxPPPMM8THx/Pqq6/y/PPP4/f76devH7fffjsfffQRF154ITExMfj9fh599NF2KVfEEoSq1orIjbidvQ94SlWXisgvgbmqOl1ExgFvAunAOSJyj6qOUtXtIvIrXJIB+GVdh3Uk+GLEzmIyxuyTxYsX17/v3bs3s2fPDjtf3bMjwhk8eDBLliwBXHPQ008/vcc806ZNY9q03a8aOP300zn//PPbEvZeRbQPQlVnADMajbsz5P0cXPNRuGWfAvbLA1pFoPFpVMYY09116k7q9uKLsSYmY8z+s3jxYi6//PLdxsXHx/PFF19EKaLwLEFgfRDGdHaq2qprDKJtzJgxLFiwYL9+prZhH9ft78UEdhaTMZ1ZQkICRUVFbdoBdheqSlFREQkJCa1azmoQuBqE/bSM6ZwGDhxIbm4u27ZtA9zFYK3dEXZ2LSlzQkICAweG7fJtkiUI3O02rAZhTOfk9/sZMmRI/XBOTk6rLgbrCiJVZmtiwpqYjDEmHEsQ2FlMxhgTjiUI6s5iinYUxhjTsViCwF0oZ/nBGGN2ZwmCuiamaEdhjDEdiyUI3GNHLUEYY8zuLEFgNQhjjAnHEgTe3VyjHYQxxnQwliAAsSYmY4zZgyUIwCdtu5GVMcZ0ZZYgsD4IY4wJxxIEdhaTMcaEYwkClyAsPxhjzO4sQWBNTMYYE44lCOxursYYE44lCNxZTJYgjDFmd5YgsAvljDEmHEsQ2IVyxhgTjiUI6p4HYRnCGGNCWYLAzmIyxphwLEFgZzEZY0w4liDw7sUU7SCMMaaDsQSB3WrDGGPCsQSBNTEZY0w4liCoO4sp2lEYY0zHEtEEISITRWSliKwRkWlhpseLyCve9C9EZLA3Pk5EnhaRxSKyUESyIxmnz2enuRpjTGMRSxAi4gMeAc4CRgJTRGRko9muBopVdRjwIPA7b/y1AKo6BvgG8EcRiViscb4YaoKRWrsxxnROkaxBjAfWqOo6Va0GXgYmNZpnEvCs9/414DQREVxC+RBAVbcCO4CsSAUaHxtDrSUIY4zZTWwE1z0A2BwynAsc09Q8qlorIiVABrAQOFdEXgIGAUd7f78MXVhErgOuA8jMzCQnJ6dNgW7Jq6Y2qMyaNQuXn7q+srKyNn9fnZWVuXuwMrefSCaIffEUMAKYC2wEPgcCjWdS1SeAJwCysrI0Ozu7TR+2OLAaXbuKEyecjN/XPfrtc3JyaOv31VlZmbsHK3P7iWSCyMMd9dcZ6I0LN0+uiMQCaUCRqirwo7qZRORzYFWkAo2LdUmhujbYbRKEMcY0J5J7wznAISIyRETigEuA6Y3mmQ5M9d5fCHyoqioiiSKSBCAi3wBqVXVZpAINTRDGGGOciNUgvD6FG4GZgA94SlWXisgvgbmqOh14EnheRNYA23FJBKAvMFNEgrhaxuWRihMaEkSVJQhjjKkX0T4IVZ0BzGg07s6Q95XARWGW2wAcFsnYQsXH+gCrQRhjTChrcCekiSmwRz+4McZ0W5YgcBfKgTUxGWNMKEsQQILffQ2Vdjm1McbUswQBJMa5rpiKamtiMsaYOpYggMQ410ldXl0b5UiMMabjsAQBJMW7GsQuSxDGGFPPEgSQVFeDqLImJmOMqWMJAujhJQirQRhjTANLEDR0UpdZDcIYY+q1KkGISJL3IKAuxRcjJPmhqKwq2qEYY0yHsdcEISIxInKpiLwjIluBFUC+iCwTkftFZNj+CTPy0uOFr3dagjDGmDrN1SBmAQcDPwP6qeogVe0LnAj8D/idiHwnwjHuFz0TYvh6Z2W0wzDGmA6juZv1na6qNY1Hqup24HXgdRHxRySy/Sw9XlhpCcIYY+o1V4M4qe6NiAwJnSAi3wYIl0A6o54JQmFZFbUBu92GMcZA8wniDyHvX2807eftHEtUpccLQYXCsupoh2KMMR1CcwlCmngfbrhTS09wxbF+CGOMcZpLENrE+3DDnVp6vEsQBZYgjDEGaL6TeqiITMfVFure4w0PaXqxzqdnvNUgjDEmVHMJYlLI+z80mtZ4uFNLjRfiYmPILa6IdijGGNMh7DVBqOpHocPeKa2jgTxV3RrJwPa3GBEO7JXIhsLyaIdijDEdQnNXUj8mIqO892nAQuA5YL6ITNkP8e1XI/unMm9jMcFgl+peMcaYNmn2OghVXeq9vxJYpapjgKOB/4toZFFwzNBeFJVXk7fDmpmMMaa5BBF6UcA3gH8BqGpBxCKKosMyUwBYlFsS5UiMMSb6mksQO0TkWyJyJHAC8C6AiMQCPSId3P42ZmAamanxvLUgL9qhGGNM1DV3FtP1wENAP+CWkJrDacA7kQwsGuJjfRw7NINZK7by9c5KMlMToh2SMcZEzV5rEKq6SlUnqupYVX0mZPxMVf1JxKOLgkvHH8jOylp++vqiaIdijDFRtdcahIg8tLfpqnpT+4YTfccMzeDak4bwt0/W88isNfzglC7zyAtjjGmV5vogvod79sMWYC4wr9GrS7rl9EMBuH/mSmYszu/wp70Gg8qTn66nuNxuNGiMaT/NJYj+wBPAmcDlgB94S1WfVdVnIx1ctCTFx/LBT04G4PsvfMXQ22dw7XNzWbO1jJpAkGc+W887i/KbXF5V92tSWbKlhF+9vYzrn++yObtTW7O1jG2l9rRC0/k0dyV1EfAY8JiIDAQuAZaJyE9V9fnmVi4iE4E/Az7g76r620bT43EX3h0NFAGTVXWDd8X234GjvBifU9XftLp0++DgPsk8e9V4pj71JQDvL/ua95d9vds8j8xKZVn+TpLifJx9eH9enZuLCKiXG644fnB9p/fF4waRX1LBpu27GJSeyJgBaZRU1FBUXsVd05dyzuEHUF5Vy5mj+rG8oJTjhmZQVlVLbTDIn/+7mqtOHMKZo/rVf3bejgrmrN9O9mF9WFFQCsCXG7ajqojseaPd7eXVJMfH4vcJIkJFrbIkr4RFuSVMGT+IwrJq3l60hYKSStKT4vjeyQfvsY6q2gDrC8tJTfDTPy2BuRuLOfrAdGJihJpAkIKSSnonx9Mjzsfy/J1U1gQY0T+Ve/69lO9nD2NQr8T6dQWDSkzM7nEGgkqMEDZ+VUXV3SHyp68v4vJjD6K0spYVBTu55qShe8xfWRPA74vBF9P8TYfr1h0TI9QGgsT6Yqiudc8FiYvd8xjq87WFCMJxB2c0u+6NReWc/sBHpCTEsvjuM5udP5yK6gA94hoeBa+q1AR0j9gembWG3OJd/Pq8MXt8t5EWDCqfry3ihGEZ9duvNhBk0/ZdDO2TTFVtgEBQKa8KkBjnIyk+/K6nsiZAeVUtPRPjWrTtwP0u42N9e52nuLya6kBwjxNPNhaVs3l7BSce0nuvy4f+RtqiujYY9rfUlPKqWnwxQoJ/7+UC992rRuaAVFqyYhE5CpiCuxZiHvBHVV3WzDI+YJW3TC4wB5gSupyIfB84XFW/JyKXAOer6mQRuRQ4V1UvEZFEYBmQraobmvq8rKwsnTt3brNlaUpOTg7Z2dl7jA8ElXeXFFBVG2DdtnL+MmtNmz9jf4qNETJTEzhhWAafrSkib0cFvhghENT6cS1x5qhMDs1M4eEPmy73gJ49Wnxx4bC+yazZWga4K9enHn8Q6YlxvDxnMx+u2MpxQzOYOLofq7eW8o//bWJonyRiROqXCeeXk0aRGBfLrf9cCMD4Ib34cv32+s84c1Q/3ltWQFKwnG+OO4xeyfHc9s+FjB3Uk599cwT/mp/Hu0sKOOqgnsxY3HCJz0EZifzkjMPIWbmVc444gK07K3l7UT6frC4E4NThfVmUu4Oq2iA/PHUYxw3tzYLNxTz9+QaOPziDrTureC/koGLqcQdx+shM5m4oJq2Hn/8u/5oR/VO57czDAJixOJ/SylpGHZBKUOGT1dso3lXNP/63iWevGs/bC7cwrG8yv/nPCgCuOXEIX20q5qtNOxiY3qP+PmLXTxjKP/63kUMyUxibuosfnDeBPinxzN9UTN6OCgJB5YyR/bj55flMGX8gxbuqSYzzMeqANFJ7+PlqYzFjBqbx6tzN1NQqS7aUcNUJQ3h17mbenJ/HtLOG89znGzhtRCZ3njOS+2Ys5+nPNgBwxshM7jh7BPGxPp75fAOPfbSWd285ie/8/QsKy6qJjRFqg8rpI/pycJ9k+qcl8O9F+az6upTvHncQr8zZTGFZNQdlJHLbmYdx6vC+vPjFJtZuK+ekQ3qzKLeE6togh2Ym079nD/4wcyWL80o4uE8ST04dR1F5Nf/9fB6XnHEcH67YSlJcLMkJsfz09UWUVtay5J4zKS6vZln+TmJEuPY5t8+YdWs25z78KRnJcYwakMbvLjictxbk8ciHa7jznFF8uX47z87ewC/OHsEZo/pRsLOS2oCyemspE0f1I7WHn13VAZLjY5m9toiHP1zNby84nFkrtlIdCPLb/6zg4SlHMnF0P7bsqKB3cnx9klxZUMqMxflMGX8gCzbvYHt5NT//12ImHNqH+84fw3+WFJAY56O8qpZtZVVMmzic6kCQtxZsYWjvJJ75fANxFYU8cPUZLfofbExE5qlqVthpe0sQIvJL4GxgOfAy8K6q1rbwQ48D7lbVM73hnwGE1gREZKY3z2zv2ooCoA+upnIpcD6QBswGjvUedRpWpBJEOJU17kg6KS6WnZU1JPh9zF5XxLjB6QxMT2RpXgl/fG8VPRP9HH9wBscP681jOWtZmLuDkopaisqrUIWU+FhKq/b8OvumxHNYvxQGZyTx3rICvt5ZVT9+a2kVKQmxlFbW4vcJNQFl7KCeTBzdj996O446oweksiRvZ7PlifPFUG1P0uvS0nr4KanoEg9/3C8S43zsqg60eP6eiX527No/329cbEMNt85Fh/q5/6r2TxDNXQfxc2A9cIT3us+rPgqgqnr4XpYdAGwOGc4FjmlqHlWtFZESIAN4DXcn2XwgEfjR3pLD/pbg9zGif+pu44b1Ta5/f8zQDF793nG7TX9g8tgm1xcIapPV6V+dN3qPccGgIl5TTOj7umahbaVV9E6OQ0QoqaghNSF2j2abWbNmMeyIY0hN8JPaI5ZtpVX0TU2or64XlFSSW7yLIwb1pHhXNfk7KjliUE8qqgNsK63CHyv0TUmgtLKG2qBSWRNgx64aeiXFsbW0igN6JuATwRcjbCutYmdlLau+LuUbIzP5z5IC0hP9DOubzNqt5WQkx5Hg93FAzwTifDEszy8lrYef/JIKyqpqGdE/lZUFpRx1UDrLt+wkb0cFFxw9kOT4WOZt3M5na4oorayhsibIMUN7cfRB6WzZUcljH63lknGDAMgvqeTzhStJyehHZW2Anj38jOifyqqvy6gOBDj6oHQKSqoYPSCVf83fwvB+KRTvqiYjOZ5tpVUEgkFGD0ijT3I828qqWLu1jNziCq6dMJTKmgC3v7mEY4b0orCsih5+H+8v/5pvHzmQs8b0czUOVVZvLSMpPpYhvZMoqaghwbt7sN8XQ7w/hj7J8fRM9LO9vIbK2gCHZiazvnAXCzfvYPbaIsYe2JMxA9Ioq6wld8cuDu6TzGkjMlmRv5OlW3ayJK+EjOQ4+qYk8M7ifK4/eSir12+iJr4nA9N7UFRWTSCo1ASVnj389c15Rx+Uzubtu1i9tQy/T6isCZLaw8+8DdtJ8PtYV+iO3vumJDBr5Va2l1cz9biD6BEXy8qCnZwwrDdrtpYxe10RE0f3Y0NhOTkrt1FVG+S4oRnM2bCdWq9P7qRDerNlRwUD0xOZv6mYIwb15IC0HizM3VHfVApw4rDebCmpYEDPHqzbVk7ejgrGD+7Flxt23w1kpsZzx9kjefiD1aT18BNUZZC/nIr4XgTV1Wge+2gt/dISKPV+g1W1QWIEjjs4g6KyatYXlnPs0AwO6NmDIwf1JDMtgcc/Wsvg3klUVgco2FnJ6q1lVNYEOPnQPmzevouFuSVkHZROXGwMn68tYnBGEiWJNawPudnnoZnJDEpP5IMVDfc1Hd4vhZ6JforKqlm9tYz0RD/FXmKJEQgqHNgrkZMP7cOMxfkUlVdzSN9kgqokx8dSUuF+58kJsfW16lvPOJTRMZG5uLe5GsRBe1tYVTfuZdkLgYmqeo03fDlwjKreGDLPEm+eXG94LS6JHAZ8H7gCSAc+Ac5S1XWNPuM64DqAzMzMo19++eW9hbtXZWVlJCcnNz9jF9HdygtW5vYSVCUmTD9ReymvUZL8bV9/Z9nO1QElztf2chZXBqkKQL+kmH0q8ymnnNLmGsQmbaaTQkSkiXnygEEhwwO9ceHmyfWamNJwndWX4pqzaoCtIvIZkAXsliBU9QncWVZkZWVpS5uIwmlNE1NX0N3KC1bm7sLK3H6a61afJSI/FJEDQ0eKSJyInCoizwJTm1h2DnCIiAwRkThcv8L0RvNMD1n+QuBDL9lsAk71PisJOBZYgTHGmP2muRrEROAq4CURGQLsABJwp62+B/xJVeeHW9DrU7gRmOnN/5SqLvU6vueq6nTgSeB5EVkDbMclEYBHgKdFZCmuv+NpVbV7XxhjzH7U3HUQlcBfgb961yb0BipUdUdLVq6qM4AZjcbd2Wj9F4VZrizceGOMMftPczWIel5/QNOXDxtjjOlSWn5pnzHGmG7FEoQxxpiwWpQgRCRJRGK894eKyLlen4QxxpguqqU1iI+BBBEZgDt76XLgmUgFZYwxJvpamiBEVXcB3wb+qqoXAaMiF5Yxxphoa3GC8G6+dxkNz6Ju/j60xhhjOq2WJohbgJ8Bb3oXuw0FZkUuLGOMMdHWousgVPUj4CMAr7O6sCs+j9oYY0yDlp7F9KKIpHr3RVqCe6rcbZENzRhjTDS1tIlppKruBM4D/gMMwZ3JZIwxpotqaYLwe9c9nAdM9267EZmHoBpjjOkQWpogHgc2AEnAx96DhJp/lqUxxphOq6Wd1A8BD4WM2igip0QmJGOMMR1BSzup00TkARGZ673+iKtNGGOM6aJa2sT0FFAKXOy9dgJPRyooY4wx0dfS50EcrKoXhAzfIyILIhGQMcaYjqGlNYgKETmxbkBETgAqIhOSMcaYjqClNYjvAc+JSJo3XAxMjUxIxhhjOoKWnsW0EDhCRFK94Z0icguwKJLBGWOMiZ5WPVFOVXd6V1QD/DgC8RhjjOkg9uWRo9JuURhjjOlw9iVB2K02jDGmC9trH4SIlBI+EQjQIyIRGWOM6RD2miBUNWV/BWKMMaZj2ZcmJmOMMV2YJQhjjDFhWYIwxhgTliUIY4wxYVmCMMYYE1ZEE4SITBSRlSKyRkSmhZkeLyKveNO/EJHB3vjLRGRByCsoImMjGasxxpjdRSxBiIgPeAQ4CxgJTBGRkY1muxooVtVhwIPA7wBU9QVVHauqY4HLgfWqarcXN8aY/SiSNYjxwBpVXaeq1cDLwKRG80wCnvXevwacJiKNb+ExxVvWGGPMftTS2323xQBgc8hwLnBMU/Ooaq2IlAAZQGHIPJPZM7EAICLXAdcBZGZmkpOT0+Zgy8rK9mn5zqa7lReszN2Flbn9RDJB7DMROQbYpapLwk1X1SeAJwCysrI0Ozu7zZ+Vk5PDvizf2XS38oKVubuwMrefSDYx5QGDQoYHeuPCziMisUAaUBQy/RLgpQjGaIwxpgmRTBBzgENEZIiIxOF29tMbzTOdhifTXQh8qKoKICIxwMVY/4MxxkRFxJqYvD6FG4GZgA94SlWXisgvgbmqOh14EnheRNYA23FJpM4EYLOqrotUjMYYY5oW0T4IVZ0BzGg07s6Q95XARU0smwMcG8n4jDHGNM2upDbGGBOWJQhjjDFhWYIwxhgTliUIY4wxYVmCMMYYE5YlCGOMMWFZgjDGGBOWJQhjjDFhWYIwxhgTliUIY4wxYVmCMMYYE5YlCGOMMWFZgjDGGBOWJQhjjDFhWYIwxhgTliUIY4wxYVmCyJsH96TTq2hetCMxxpgOxRKE+ECDiNZGOxJjjOlQLEH4/ACIBqIciDHGdCyWIGLcY7ktQRhjzO4sQXgJIiZoCcIYY0JZgqhvYrI+CGOMCWUJwpqYjDEmLEsQMdZJbYwx4ViC8FkNwhhjwrEEUd9JbX0QxhgTyhKENTEZY0xYliDsQjljjAnLEoS4r8BOczXGmN1ZghCBGL/VIIwxppGIJggRmSgiK0VkjYhMCzM9XkRe8aZ/ISKDQ6YdLiKzRWSpiCwWkYSIBeqzBGGMMY1FLEGIiA94BDgLGAlMEZGRjWa7GihW1WHAg8DvvGVjgX8A31PVUUA2UBOpWImJtVttGGNMI5GsQYwH1qjqOlWtBl4GJjWaZxLwrPf+NeA0ERHgDGCRqi4EUNUi1Qge4sfEWjUV0mcAABPTSURBVB+EMcY0EhvBdQ8ANocM5wLHNDWPqtaKSAmQARwKqIjMBPoAL6vq7xt/gIhcB1wHkJmZSU5OTpsCPS6gBKor2rx8Z1RWVtatygtW5u7Cytx+Ipkg9kUscCIwDtgFfCAi81T1g9CZVPUJ4AmArKwszc7ObtunLUglzgdtXr4TysnJ6VblBStzd2Flbj+RbGLKAwaFDA/0xoWdx+t3SAOKcLWNj1W1UFV3ATOAoyIWqb8HvkBVxFZvjDGdUSQTxBzgEBEZIiJxwCXA9EbzTAemeu8vBD5UVQVmAmNEJNFLHCcDyyIWaWwCMcHqiK3eGGM6o4g1MXl9CjfidvY+4ClVXSoivwTmqup04EngeRFZA2zHJRFUtVhEHsAlGQVmqOo7kYqV2ARiKsojtnpjjOmMItoHoaozcM1DoePuDHlfCVzUxLL/wJ3qGnn+BGKCxfvlo4wxprOwK6kBYntYE5MxxjRiCQLAn4AvYAnCGGNCWYIAq0EYY0wYliAA4pPxBXZFOwpjjOlQLEEAJPXBX1sOtVaLMMaYOpYgAJJ6u7+7CqMbhzHGdCCWIACS+rq/pQXRjcMYYzoQSxAAvQ9xfwtXRTcOY9rLon/CO7eCarQjaR1V+PDXkL8o2pF0HLXVUBudWwFZggDodTBB8cPXS6IdiTFtowp/OxUWvAQrZsAb18Ccv5G4K3f/xfCfafD30yEYdMOlBfC/R11sO/Phg19BTeXe11FRDB//Hp4/v/Wfv2UBbPh0z/GqsOQN2Lllz2lfPQ+vX9Oy9QeDbh2BNjyaprywIZbWevho+NPhe44vXA2fPggRfJZNR72b6/7li6U86UBS1uW4DSgS7Yi6vpI8SBuw/z6vpqIV81aCLw5iwhw/VZdDbI+Gabu2w6qZcMQle//dBGpBgxAb17q4G6vcCYtfhf5joWARZF0Fy9+GLx6DvHnuFSKuekfL1huoAQRK86HnoPDzBAMQrIWV/4HV78HE30BCWsP0Lx51f79eAv0PdzveDZ9AoBoKlri4P/kDnHIHnPx/sPzfEJ8CvQ9z32vvYQ078doql2Diktw84dRWuZjfuwPGXQtPnOzGZ7/VMI8qrPkAXrvSzXP2H2DbKrfe3Dkw/UY3X9ZV8L+/Qvbt8NpVMOkvMDALPn8YhkyA/kfAQ2Nhx0YY+x0YerL7jVSWwNFT3e+gohgyDt79s0Vg3rPw75tg1Pmw9E23rkPOgOyfufm2LICqEjj4VJeEdhVCct+G9ZRscn8XvAhDToaCxVC0Gj55ACq2Q00louOa28JtYgnCs73XkaRseg22LoPMUZH/wECNe8Ults/6nj0H+o6Cs37b9nWsy4HM0Q2d9k0J1MDGz6H3oZDaP8z0WnhpsvvHOuHmPacveBH+dQNc+yEMOLr5uKrKYONncOiZDeO+/BukDoDh39xz/toqeOM6GDnJ7WRmun/Ew/qdDklrYNS3IbFX+M8KBuHXmTD+Ovjm/Y3iKIXfDIQTfwSn3+3GfXAPzHsG5vzd7eSO/yGkD4aUfvDK5W5nu32925GWFcB1H8Gb18O3/tSQIFVd8ojxNXzWqpnw75vhnD83lLumAha8AO+GPL03Yxi8clmTX11sbZnbiVWXu2024lyXpHZugY/vdzuqw86Cv2RB8YaGBYd/C064BSQGVvwbYhNg02z3G6mz/hM46Hg4/zGoCTlNfNZ9cN5foWyrG37/TnYz69du57z6PTec0BMqd8BdO2CHtzOsLoU/HgZ9hsMlL8Lif8JR34XNX7o4DzgSnju3YZ1fPlH/VoI17jstXAVPnuHWDS6hbl8Hj4TZmb55vfvs5f92w38/DY6YAgtfcttuyASXHAAW/MO96pRthVn3NnxvR1/pdvZPnQkpmZDrJe2lb7q/+Qvd6+NGv6/LXoMXLnTvz3/CbZctXzVM/9cNe8YN8NFvGXzghcDp4afvA9HO1kbZhKysLJ07d26bl//ynecYP+eH7h/y6CvaL7Bg0P1AJcbtBBa/5nZOi15x/2B35MO6WRDjh36jIS7FHWkdfKrbyVSWuFfPA3dfb6AWvnzcxVqS1/Cjv3GuO2Jb/Z77Z/r23+CtH0C/MTDh1vrF6+8fn78QHp8Al70OL1zgdm43L/Q+owZiYvc8Mp77FLz9Izh0Ilz6Ciz9F3zwS/jep1C0Bh4/qWHeu72dU1WpK/+z57qjH4CLnnH/UPOfd00Qp9zuvqvywoZ+odoquNc7mrphtjuy2rW9obxHTXVJ6OFW3g3+iEvdTqyq1H0/y6fDST9xR5IPegcIKf3B53cJofehLgnU/ZPHp8LgE91OpTVNk6f+HD70diajzodNX0DpFrd9vvErtxM65Ax460ZY6z3+ZPBJLhHMe7p1ZQSq/WnE1ZTsfaYLnoTXr271uuvFxLqaRaT0G+OOmltoR9pIepZE7ubPHdH29LH0uvmjNi3rPWsnK+w0SxBOzqwPyF7yU7fzOvhUOO9RSMxwO/YYn2vXfesHbmd06JnQd4Q7Svn8IXeE9OMV0KMn1Fa6nf2Oja4m8v5d8Nmf3Diff/cjLYBzHnLVzzpHfRe+eg7GXOSaLf5xgRs/NBuKN8K5D7ujqj8Mc+MPn+ySTVN6pLuqL7ijVp8ftixg2/ol9PGVwdfeP1764IYjyPHXux3ZU2e6GtXY77jkEqh2bbybZrsjuphYuOyfe28vPu5GmP0Xl/iS+7gjuNbo0ctVo/eXb/wK3v/F/vu8fTFwPOR+Gd0Y4lOhamd0Y6hzws3w2Z+bny8m1jVzfXDP7uND/1ea8oMv4ZHx7v1lr7smqtL81sc6+QX3f15dDhtD+k2+9aA7+GpsQBbkhdm/Df8WfOtBcuYsJfuUU1ofB5YgWiQnJ4dsnQ0feU00p93l2h/7joCKHbB16e4LHHk55M6FbcvdcPpgt7HLtzXMc8lL8Ma1UF3W5rg6jMQM2FUU7SjaZsxFLtE3lUh79HLzfPn4vn3O5f9yO6h1s9xw4x3WSbe6ppDGO9QR57rkXLCXM3eS+rp2+42fw9I33LgrZgAKz5y9+7zH3OBqPY+Mc7XP6z5yTUQbP4N3fuzmOWIK+BNh7pNueMJtrins1DvcjvK58yB/ARx6Fpx+l2t6qdnlOkVT+jfsFO/a4WqYr1/rar5Xv+92ZutmuQMKVVebrS5zBxV7fGdvwvSbXG30gLGudlWaDzfOc8sFquG/d8HAca5ZCuDO7TDnSUgb6GqAOfe57++nG+HTB9x3njHM1WYPPM4d0HznDTjwWNd/FKyB2Hi4J93Vaq/50NVch54CK952zWaJGfCbQXD4xW4dPQe5vpDMUVC4xvWtZF3p4qkud0kn7ytXzl1F4O8Bb36v4YAwbRCUbIbv/8/Vhg6/uOE7CNTCf/7Pra/fGHcQ9szZrtXghFtcLf/sB2DbCnjsBPddnXEvvDQFzn8cBh69T0+UswTRAjk5OWSfdAL8qpn2946k7kfXlJGTYNlbrj3zzeva9hnJmVD2tXsferQ45mK3QwDXWXfeoy1rpkju59riAfxJcPYfXU0J4J6e7u+Qk2G9V10+5Q7XZl2nz3D3jxKq3xh3JJXQ0+2Ytq2Eyc+7s2oGjavvL/jsvbc4oe8ut1MBt7ObeJ9r6lF1O8+5T8HI81yZx1zkmncqd8D8f7iO1z4j4Jlvuqatxf90O4Cz7nft3Wf93rWd586BYSHtwXenub6dGz5rGPfl32DGra7decgEt57t6+DrZa5pcdB41/b99TIoXg8HneBqqHVx//duuH2L62yt3gUobPgMXrwIfviV6yzdtpJFH/+bwy9oaFoMq7TAfWZLLHjR7TA16H4PyX3ceFUoWus6mptSsNi1o3/zD5A+xJUnNn73eap3uR1u3Xrr4kvq6zrgi9bA2Cm7LxOodd97j3QoL6Lk8W+SNvlRd3AXm+B22uE6unfmu89vqj9qX09Yqa12tZRjb3DbMlDT9GeF+2zVPU+UWDvLdXI3Wo8liGa0S4LIzob/PQab/9fQ1hzqynfh6Ym7jzvxxzDiW+4Uw73pMxyS+rgjj8YOOtE14bx+jTuDYdIjrjkL3JkXR091O/qTp8Fzk1zz1RXvQPpBbkfx6YMN64pNcEdbw892O7FANcQlw68yIO1A1ymedRXz82s4cvhQtyPOnga/G9ywjiO/A6MvcJ1rJ/3YnbXyymXuzJlr/gtrP3TNcOXb3E4iPtkt99lDsP5jOO1OdyR4yu3uyP2DX8LE30KvIe6f5IvHYNzVe/7T1u00f761oU07Lsn1OWz4FEpyXZ/Lff1dU9voC3Y/o6gZLfonCgZ27ywOp65vZu0H7qhxwm1735GUfu2+99DyqrpO57acpKDqvh+fP/y0kFjs+czdQ6QSBKraJV5HH3207otZs2Y1DASDqr85UPWuVNUnTlFdGzKtYKkb/4fDVGtrGsavmKH69NmqL1ys+v5dqhU73Ouxk1QXv6ZaU6UaqFWtLFV97RrVpW+pVu5UXfmuG6+qGgg0vF/+jmrZtpYFX7pV9dcDVBe+qlpVFn6eqrLd4t2tvKqqxZtUaypdDI1VlKj+cYTq6vdbFk8HtUeZuwErc/ewL2XGPeEz7H7VTnMNRwR+tMS1JaYP3n1a3xFw6i9ck4Yv5Os77Cz3auz6j3cfjk+GC/7WMBx66mbokXC40zebktwHbm/mgqi4pL1Pb+rcd4CEVPhx9zorxBhj10E0LT4lfLulyG6nixpjTFdlt9owxhgTliUIY4wxYVmCMMYYE5YlCGOMMWFZgjDGGBOWJQhjjDFhWYIwxhgTliUIY4wxYXWZezGJyDZg4z6sojdQ2E7hdAbdrbxgZe4urMytc5Cq9gk3ocskiH0lInO1qRtWdUHdrbxgZe4urMztx5qYjDHGhGUJwhhjTFiWIBo80fwsXUp3Ky9YmbsLK3M7sT4IY4wxYVkNwhhjTFiWIIwxxoTV7ROEiEwUkZUiskZEpkU7nvYiIoNEZJaILBORpSJysze+l4i8LyKrvb/p3ngRkYe872GRiBwV3RK0jYj4RGS+iLztDQ8RkS+8cr0iInHe+HhveI03fXA0494XItJTRF4TkRUislxEjusG2/lH3u96iYi8JCIJXW1bi8hTIrJVRJaEjGv1dhWRqd78q0Vkamti6NYJQkR8wCPAWcBIYIqIjIxuVO2mFviJqo4EjgV+4JVtGvCBqh4CfOANg/sODvFe1wGP7v+Q28XNwPKQ4d8BD6rqMKAYuNobfzVQ7I1/0Juvs/oz8K6qDgeOwJW/y25nERkA3ARkqepowAdcQtfb1s8AExuNa9V2FZFewF3AMcB44K66pNIiTT2suju8gOOAmSHDPwN+Fu24IlTWt4BvACuB/t64/sBK7/3jwJSQ+evn6ywvYKD3T3Mq8DYguKtLYxtvb2AmcJz3PtabT6JdhjaUOQ1Y3zj2Lr6dBwCbgV7etnsbOLMrbmtgMLCkrdsVmAI8HjJ+t/mae3XrGgQNP7Q6ud64LsWrUh8JfAFkqmq+N6kAyPTed4Xv4k/A/wFBbzgD2KGqtd5waJnqy+tNL/Hm72yGANuAp72mtb+LSBJdeDurah7wB2ATkI/bdvPo+tsaWr9d92l7d/cE0eWJSDLwOnCLqu4MnabukKJLnOcsIt8CtqrqvGjHsp/FAkcBj6rqkUA5Dc0OQNfazgBeE8kkXHI8AEhiz6aYLm9/bNfuniDygEEhwwO9cV2CiPhxyeEFVX3DG/21iPT3pvcHtnrjO/t3cQJwrohsAF7GNTP9GegpIrHePKFlqi+vNz0NKNqfAbeTXCBXVb/whl/DJYyuup0BTgfWq+o2Va0B3sBt/66+raH123Wftnd3TxBzgEO8sx/icB1d06McU7sQEQGeBJar6gMhk6YDdWcyTMX1TdSN/653NsSxQElIVbbDU9WfqepAVR2M244fquplwCzgQm+2xuWt+x4u9ObvdEfZqloAbBaRw7xRpwHL6KLb2bMJOFZEEr3feV2Zu/S29rR2u84EzhCRdK/mdYY3rmWi3QkT7RfwTWAVsBa4I9rxtGO5TsRVPxcBC7zXN3Ftrx8Aq4H/Ar28+QV3RtdaYDHuDJGol6ONZc8G3vbeDwW+BNYA/wTivfEJ3vAab/rQaMe9D+UdC8z1tvW/gPSuvp2Be4AVwBLgeSC+q21r4CVcH0sNrqZ4dVu2K3CVV/Y1wJWticFutWGMMSas7t7EZIwxpgmWIIwxxoRlCcIYY0xYliCMMcaEZQnCGGNMWJYgjGkFEQmIyIKQV7vdAVhEBofeudOYaIttfhZjTIgKVR0b7SCM2R+sBmFMOxCRDSLyexFZLCJfisgwb/xgEfnQu0f/ByJyoDc+U0TeFJGF3ut4b1U+Efmb96yD90SkR9QKZbo9SxDGtE6PRk1Mk0OmlajqGOAvuDvLAjwMPKuqhwMvAA954x8CPlLVI3D3TlrqjT8EeERVRwE7gAsiXB5jmmRXUhvTCiJSpqrJYcZvAE5V1XXeTRILVDVDRApx9++v8cbnq2pvEdkGDFTVqpB1DAbeV/cwGETkp4BfVe+NfMmM2ZPVIIxpP9rE+9aoCnkfwPoJTRRZgjCm/UwO+Tvbe/857u6yAJcBn3jvPwBugPrnaKftryCNaSk7OjGmdXqIyIKQ4XdVte5U13QRWYSrBUzxxv0Q97S323BPfrvSG38z8ISIXI2rKdyAu3OnMR2G9UEY0w68PogsVS2MdizGtBdrYjLGGBOW1SCMMcaEZTUIY4wxYVmCMMYYE5YlCGOMMWFZgjDGGBOWJQhjjDFh/T88hRoPtwMPwwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hc2q5qu4rYmM"
      },
      "source": [
        "### LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOKNM0lhrYmM",
        "outputId": "c675acec-5790-419b-a86d-56f52f0b61c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epoch = 1000\n",
        "batch_size = 32\n",
        "\n",
        "# Reshape menjadi (jumlah sample, time steps, jumlah feature)\n",
        "# Time steps: jumlah lag, gunakan default 1\n",
        "# https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/\n",
        "feature_train_reshaped = np.reshape(feature_train, (feature_train.shape[0], 1, feature_train.shape[1]))\n",
        "feature_test_reshaped = np.reshape(feature_test, (feature_test.shape[0], 1, feature_test.shape[1]))\n",
        "\n",
        "lstm_model2 = Sequential()\n",
        "lstm_model2.add(LSTM(50, activation='relu', input_dim=feature_train.shape[1])) # 50 LSTM Block\n",
        "lstm_model2.add(Dense(1))\n",
        "lstm_model2.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "lstm_model_history2 = lstm_model2.fit(feature_train_reshaped, label_train, epochs=epoch, batch_size=batch_size, validation_data=(feature_test_reshaped, label_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 0.1121 - val_loss: 0.0691\n",
            "Epoch 2/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1090 - val_loss: 0.0675\n",
            "Epoch 3/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1066 - val_loss: 0.0662\n",
            "Epoch 4/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1046 - val_loss: 0.0651\n",
            "Epoch 5/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1029 - val_loss: 0.0641\n",
            "Epoch 6/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1011 - val_loss: 0.0633\n",
            "Epoch 7/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0995 - val_loss: 0.0625\n",
            "Epoch 8/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0981 - val_loss: 0.0617\n",
            "Epoch 9/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0965 - val_loss: 0.0609\n",
            "Epoch 10/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0950 - val_loss: 0.0601\n",
            "Epoch 11/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0937 - val_loss: 0.0594\n",
            "Epoch 12/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0922 - val_loss: 0.0588\n",
            "Epoch 13/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0908 - val_loss: 0.0582\n",
            "Epoch 14/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0897 - val_loss: 0.0577\n",
            "Epoch 15/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0884 - val_loss: 0.0572\n",
            "Epoch 16/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0875 - val_loss: 0.0568\n",
            "Epoch 17/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0865 - val_loss: 0.0566\n",
            "Epoch 18/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0858 - val_loss: 0.0564\n",
            "Epoch 19/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0853 - val_loss: 0.0563\n",
            "Epoch 20/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0846 - val_loss: 0.0561\n",
            "Epoch 21/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0841 - val_loss: 0.0561\n",
            "Epoch 22/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0836 - val_loss: 0.0560\n",
            "Epoch 23/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0835 - val_loss: 0.0562\n",
            "Epoch 24/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0830 - val_loss: 0.0560\n",
            "Epoch 25/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0827 - val_loss: 0.0558\n",
            "Epoch 26/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0826 - val_loss: 0.0557\n",
            "Epoch 27/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0823 - val_loss: 0.0556\n",
            "Epoch 28/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0822 - val_loss: 0.0557\n",
            "Epoch 29/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0820 - val_loss: 0.0557\n",
            "Epoch 30/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0819 - val_loss: 0.0556\n",
            "Epoch 31/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0817 - val_loss: 0.0555\n",
            "Epoch 32/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0816 - val_loss: 0.0554\n",
            "Epoch 33/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0815 - val_loss: 0.0552\n",
            "Epoch 34/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0814 - val_loss: 0.0551\n",
            "Epoch 35/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0813 - val_loss: 0.0549\n",
            "Epoch 36/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0813 - val_loss: 0.0550\n",
            "Epoch 37/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0812 - val_loss: 0.0551\n",
            "Epoch 38/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0811 - val_loss: 0.0551\n",
            "Epoch 39/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0811 - val_loss: 0.0551\n",
            "Epoch 40/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0809 - val_loss: 0.0548\n",
            "Epoch 41/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0810 - val_loss: 0.0547\n",
            "Epoch 42/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0809 - val_loss: 0.0548\n",
            "Epoch 43/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0810 - val_loss: 0.0546\n",
            "Epoch 44/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0808 - val_loss: 0.0546\n",
            "Epoch 45/1000\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0808 - val_loss: 0.0549\n",
            "Epoch 46/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0809 - val_loss: 0.0547\n",
            "Epoch 47/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 48/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0807 - val_loss: 0.0549\n",
            "Epoch 49/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0809 - val_loss: 0.0547\n",
            "Epoch 50/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0549\n",
            "Epoch 51/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 52/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 53/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 54/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0546\n",
            "Epoch 55/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 56/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 57/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0547\n",
            "Epoch 58/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0549\n",
            "Epoch 59/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0548\n",
            "Epoch 60/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0546\n",
            "Epoch 61/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0544\n",
            "Epoch 62/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0807 - val_loss: 0.0544\n",
            "Epoch 63/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0546\n",
            "Epoch 64/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0547\n",
            "Epoch 65/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0546\n",
            "Epoch 66/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0545\n",
            "Epoch 67/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0546\n",
            "Epoch 68/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 69/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 70/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0546\n",
            "Epoch 71/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0547\n",
            "Epoch 72/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 73/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0546\n",
            "Epoch 74/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0547\n",
            "Epoch 75/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0547\n",
            "Epoch 76/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 77/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0547\n",
            "Epoch 78/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 79/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 80/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 81/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0548\n",
            "Epoch 82/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 83/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0547\n",
            "Epoch 84/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0549\n",
            "Epoch 85/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0551\n",
            "Epoch 86/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0548\n",
            "Epoch 87/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0547\n",
            "Epoch 88/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 89/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 90/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 91/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 92/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 93/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 94/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 95/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 96/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0548\n",
            "Epoch 97/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 98/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 99/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0549\n",
            "Epoch 100/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 101/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 102/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 103/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 104/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0547\n",
            "Epoch 105/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0545\n",
            "Epoch 106/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0545\n",
            "Epoch 107/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0808 - val_loss: 0.0551\n",
            "Epoch 108/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0548\n",
            "Epoch 109/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0548\n",
            "Epoch 110/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0545\n",
            "Epoch 111/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0547\n",
            "Epoch 112/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 113/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0545\n",
            "Epoch 114/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0545\n",
            "Epoch 115/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 116/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 117/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 118/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 119/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 120/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 121/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 122/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 123/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 124/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0545\n",
            "Epoch 125/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 126/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0549\n",
            "Epoch 127/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 128/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 129/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0545\n",
            "Epoch 130/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 131/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 132/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0550\n",
            "Epoch 133/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0547\n",
            "Epoch 134/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 135/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0545\n",
            "Epoch 136/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0547\n",
            "Epoch 137/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0545\n",
            "Epoch 138/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 139/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0545\n",
            "Epoch 140/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0547\n",
            "Epoch 141/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 142/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 143/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 144/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 145/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0545\n",
            "Epoch 146/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0545\n",
            "Epoch 147/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0544\n",
            "Epoch 148/1000\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 149/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0545\n",
            "Epoch 150/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 151/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0550\n",
            "Epoch 152/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 153/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 154/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 155/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0545\n",
            "Epoch 156/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 157/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0548\n",
            "Epoch 158/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 159/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 160/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 161/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 162/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 163/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 164/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 165/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 166/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 167/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 168/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 169/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 170/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0548\n",
            "Epoch 171/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0545\n",
            "Epoch 172/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 173/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 174/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 175/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 176/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 177/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0549\n",
            "Epoch 178/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 179/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 180/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 181/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 182/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0545\n",
            "Epoch 183/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 184/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 185/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 186/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0807 - val_loss: 0.0544\n",
            "Epoch 187/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 188/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 189/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0552\n",
            "Epoch 190/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0547\n",
            "Epoch 191/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 192/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 193/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 194/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 195/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0551\n",
            "Epoch 196/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0550\n",
            "Epoch 197/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0551\n",
            "Epoch 198/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 199/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 200/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0544\n",
            "Epoch 201/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0543\n",
            "Epoch 202/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0545\n",
            "Epoch 203/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0545\n",
            "Epoch 204/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0547\n",
            "Epoch 205/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 206/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 207/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 208/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 209/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 210/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 211/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 212/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0545\n",
            "Epoch 213/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0548\n",
            "Epoch 214/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 215/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 216/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 217/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0547\n",
            "Epoch 218/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 219/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 220/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 221/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 222/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0548\n",
            "Epoch 223/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0544\n",
            "Epoch 224/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0545\n",
            "Epoch 225/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0545\n",
            "Epoch 226/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 227/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 228/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0550\n",
            "Epoch 229/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0547\n",
            "Epoch 230/1000\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 231/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 232/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 233/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 234/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 235/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 236/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0547\n",
            "Epoch 237/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 238/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0545\n",
            "Epoch 239/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0544\n",
            "Epoch 240/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 241/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 242/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 243/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 244/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0551\n",
            "Epoch 245/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 246/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 247/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 248/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0546\n",
            "Epoch 249/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 250/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0545\n",
            "Epoch 251/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 252/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 253/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 254/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0544\n",
            "Epoch 255/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0545\n",
            "Epoch 256/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 257/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 258/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 259/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0546\n",
            "Epoch 260/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 261/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 262/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 263/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 264/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 265/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 266/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 267/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 268/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 269/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 270/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 271/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0547\n",
            "Epoch 272/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0545\n",
            "Epoch 273/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0547\n",
            "Epoch 274/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 275/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0549\n",
            "Epoch 276/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 277/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 278/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 279/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0545\n",
            "Epoch 280/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0544\n",
            "Epoch 281/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0544\n",
            "Epoch 282/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 283/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0547\n",
            "Epoch 284/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 285/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 286/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 287/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 288/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 289/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 290/1000\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0804 - val_loss: 0.0545\n",
            "Epoch 291/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 292/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 293/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 294/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 295/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 296/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 297/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 298/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 299/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 300/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 301/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 302/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 303/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 304/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0545\n",
            "Epoch 305/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 306/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 307/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0544\n",
            "Epoch 308/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 309/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 310/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 311/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0547\n",
            "Epoch 312/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0551\n",
            "Epoch 313/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 314/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 315/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 316/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 317/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0548\n",
            "Epoch 318/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 319/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0807 - val_loss: 0.0544\n",
            "Epoch 320/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 321/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 322/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 323/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 324/1000\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 325/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 326/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0544\n",
            "Epoch 327/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0544\n",
            "Epoch 328/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 329/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 330/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 331/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 332/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 333/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 334/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 335/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 336/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 337/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0547\n",
            "Epoch 338/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 339/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 340/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0545\n",
            "Epoch 341/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0544\n",
            "Epoch 342/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0545\n",
            "Epoch 343/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0545\n",
            "Epoch 344/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 345/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 346/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 347/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 348/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 349/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0545\n",
            "Epoch 350/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0545\n",
            "Epoch 351/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 352/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 353/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 354/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 355/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 356/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 357/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 358/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 359/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 360/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 361/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0545\n",
            "Epoch 362/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 363/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 364/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 365/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 366/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 367/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 368/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 369/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 370/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 371/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0549\n",
            "Epoch 372/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 373/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0545\n",
            "Epoch 374/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 375/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 376/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 377/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 378/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 379/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 380/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 381/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 382/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 383/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0544\n",
            "Epoch 384/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0545\n",
            "Epoch 385/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0545\n",
            "Epoch 386/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 387/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 388/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 389/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 390/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 391/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 392/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 393/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 394/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 395/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 396/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 397/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 398/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 399/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 400/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 401/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 402/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 403/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 404/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 405/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 406/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 407/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 408/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 409/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 410/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0551\n",
            "Epoch 411/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 412/1000\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 413/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0547\n",
            "Epoch 414/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 415/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 416/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 417/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 418/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 419/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 420/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 421/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 422/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 423/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 424/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 425/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0545\n",
            "Epoch 426/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0544\n",
            "Epoch 427/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0548\n",
            "Epoch 428/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 429/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 430/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 431/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 432/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 433/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 434/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 435/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 436/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 437/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 438/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 439/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0548\n",
            "Epoch 440/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 441/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0551\n",
            "Epoch 442/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 443/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0548\n",
            "Epoch 444/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0545\n",
            "Epoch 445/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 446/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 447/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 448/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 449/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 450/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 451/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 452/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 453/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 454/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 455/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 456/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 457/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 458/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 459/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0551\n",
            "Epoch 460/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 461/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 462/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 463/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0545\n",
            "Epoch 464/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0544\n",
            "Epoch 465/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 466/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 467/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 468/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 469/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 470/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 471/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 472/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 473/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 474/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 475/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0547\n",
            "Epoch 476/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0550\n",
            "Epoch 477/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 478/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 479/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 480/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 481/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0546\n",
            "Epoch 482/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0550\n",
            "Epoch 483/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 484/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 485/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 486/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0545\n",
            "Epoch 487/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 488/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 489/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 490/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 491/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 492/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 493/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 494/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 495/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0546\n",
            "Epoch 496/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 497/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 498/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 499/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 500/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 501/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 502/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 503/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0545\n",
            "Epoch 504/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0547\n",
            "Epoch 505/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 506/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0545\n",
            "Epoch 507/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0544\n",
            "Epoch 508/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0545\n",
            "Epoch 509/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 510/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 511/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 512/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 513/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 514/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 515/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 516/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0545\n",
            "Epoch 517/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 518/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 519/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 520/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 521/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 522/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0544\n",
            "Epoch 523/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 524/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 525/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 526/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 527/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 528/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 529/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 530/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 531/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 532/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0551\n",
            "Epoch 533/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 534/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 535/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 536/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 537/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 538/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 539/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 540/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0545\n",
            "Epoch 541/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 542/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 543/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 544/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0545\n",
            "Epoch 545/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0544\n",
            "Epoch 546/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0545\n",
            "Epoch 547/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0548\n",
            "Epoch 548/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 549/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 550/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 551/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 552/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 553/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 554/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0550\n",
            "Epoch 555/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 556/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 557/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 558/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 559/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 560/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0546\n",
            "Epoch 561/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 562/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 563/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 564/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 565/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 566/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 567/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 568/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0551\n",
            "Epoch 569/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 570/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 571/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0545\n",
            "Epoch 572/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0549\n",
            "Epoch 573/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 574/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 575/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 576/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0551\n",
            "Epoch 577/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0551\n",
            "Epoch 578/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 579/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 580/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 581/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0546\n",
            "Epoch 582/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 583/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 584/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 585/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0552\n",
            "Epoch 586/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 587/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 588/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 589/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 590/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 591/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 592/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 593/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 594/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 595/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 596/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 597/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 598/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0545\n",
            "Epoch 599/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 600/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 601/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 602/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0551\n",
            "Epoch 603/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 604/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 605/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 606/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0551\n",
            "Epoch 607/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 608/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 609/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0551\n",
            "Epoch 610/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 611/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 612/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 613/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 614/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 615/1000\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 616/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 617/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 618/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 619/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0549\n",
            "Epoch 620/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 621/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 622/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 623/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 624/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 625/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0545\n",
            "Epoch 626/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0545\n",
            "Epoch 627/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 628/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 629/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 630/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 631/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 632/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 633/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 634/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 635/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 636/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 637/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 638/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 639/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 640/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 641/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 642/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 643/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 644/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 645/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 646/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 647/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 648/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 649/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 650/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 651/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 652/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 653/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0545\n",
            "Epoch 654/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 655/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 656/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0551\n",
            "Epoch 657/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 658/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0802 - val_loss: 0.0547\n",
            "Epoch 659/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 660/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 661/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 662/1000\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 663/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 664/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 665/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 666/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 667/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 668/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 669/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 670/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 671/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 672/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 673/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 674/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 675/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0549\n",
            "Epoch 676/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 677/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 678/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 679/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 680/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 681/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 682/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 683/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 684/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0551\n",
            "Epoch 685/1000\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0804 - val_loss: 0.0551\n",
            "Epoch 686/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0547\n",
            "Epoch 687/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0549\n",
            "Epoch 688/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 689/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 690/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 691/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 692/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 693/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 694/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 695/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 696/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 697/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 698/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 699/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 700/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 701/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0547\n",
            "Epoch 702/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0549\n",
            "Epoch 703/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 704/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 705/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 706/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 707/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 708/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 709/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 710/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 711/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 712/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 713/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 714/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 715/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0552\n",
            "Epoch 716/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 717/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 718/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 719/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 720/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 721/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0545\n",
            "Epoch 722/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 723/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 724/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 725/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 726/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 727/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0545\n",
            "Epoch 728/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0545\n",
            "Epoch 729/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0545\n",
            "Epoch 730/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0546\n",
            "Epoch 731/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 732/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 733/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 734/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 735/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 736/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0546\n",
            "Epoch 737/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 738/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 739/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 740/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 741/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 742/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 743/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 744/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 745/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 746/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 747/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 748/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 749/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 750/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 751/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 752/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 753/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 754/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 755/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 756/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 757/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 758/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0551\n",
            "Epoch 759/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0548\n",
            "Epoch 760/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 761/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 762/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 763/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 764/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 765/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 766/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0545\n",
            "Epoch 767/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0544\n",
            "Epoch 768/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 769/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 770/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 771/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 772/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0548\n",
            "Epoch 773/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 774/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 775/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 776/1000\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 777/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 778/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0551\n",
            "Epoch 779/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 780/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 781/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 782/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 783/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 784/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 785/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 786/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 787/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 788/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 789/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 790/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 791/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 792/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 793/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 794/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0545\n",
            "Epoch 795/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 796/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 797/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 798/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 799/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 800/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 801/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 802/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 803/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 804/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 805/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0551\n",
            "Epoch 806/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0553\n",
            "Epoch 807/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 808/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 809/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 810/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 811/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 812/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 813/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 814/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 815/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 816/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 817/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 818/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 819/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 820/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 821/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 822/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 823/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 824/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 825/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 826/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 827/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 828/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 829/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 830/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 831/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 832/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 833/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0551\n",
            "Epoch 834/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 835/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 836/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 837/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 838/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 839/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 840/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 841/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 842/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0552\n",
            "Epoch 843/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0551\n",
            "Epoch 844/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0551\n",
            "Epoch 845/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0553\n",
            "Epoch 846/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0551\n",
            "Epoch 847/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 848/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 849/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 850/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 851/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 852/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 853/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 854/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 855/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 856/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 857/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 858/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 859/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 860/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 861/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 862/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 863/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 864/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 865/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0551\n",
            "Epoch 866/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 867/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 868/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 869/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 870/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 871/1000\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 872/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 873/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 874/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0550\n",
            "Epoch 875/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 876/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 877/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 878/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 879/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 880/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 881/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 882/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 883/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 884/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 885/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 886/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 887/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 888/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 889/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 890/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 891/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 892/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 893/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 894/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 895/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 896/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 897/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 898/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 899/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 900/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 901/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0551\n",
            "Epoch 902/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0551\n",
            "Epoch 903/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0551\n",
            "Epoch 904/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0548\n",
            "Epoch 905/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 906/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 907/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 908/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 909/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 910/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 911/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0546\n",
            "Epoch 912/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 913/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 914/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 915/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 916/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 917/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 918/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 919/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 920/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 921/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 922/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 923/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 924/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 925/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 926/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 927/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 928/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 929/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0545\n",
            "Epoch 930/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 931/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 932/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0546\n",
            "Epoch 933/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 934/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 935/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 936/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 937/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 938/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 939/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 940/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 941/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0551\n",
            "Epoch 942/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 943/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0552\n",
            "Epoch 944/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 945/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 946/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 947/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 948/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 949/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 950/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 951/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 952/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 953/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 954/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 955/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 956/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 957/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 958/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 959/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 960/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 961/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 962/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 963/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 964/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 965/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 966/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0548\n",
            "Epoch 967/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0551\n",
            "Epoch 968/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0551\n",
            "Epoch 969/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0551\n",
            "Epoch 970/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 971/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 972/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0550\n",
            "Epoch 973/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0551\n",
            "Epoch 974/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 975/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 976/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0545\n",
            "Epoch 977/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 978/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 979/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0550\n",
            "Epoch 980/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 981/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 982/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 983/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 984/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0548\n",
            "Epoch 985/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0550\n",
            "Epoch 986/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 987/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0547\n",
            "Epoch 988/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 989/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0551\n",
            "Epoch 990/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0551\n",
            "Epoch 991/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0546\n",
            "Epoch 992/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 993/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0549\n",
            "Epoch 994/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 995/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 996/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0550\n",
            "Epoch 997/1000\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0547\n",
            "Epoch 998/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0548\n",
            "Epoch 999/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0549\n",
            "Epoch 1000/1000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0549\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJhYQ23TrYmP",
        "outputId": "bf27d067-f244-4650-d598-34073286f58c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "lstm_history_dataframe2 = pd.DataFrame(lstm_model_history2.history)\n",
        "lstm_history_dataframe2['epoch'] = lstm_model_history2.epoch\n",
        "lstm_history_dataframe2.sort_values(by='val_loss', ascending=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>0.080473</td>\n",
              "      <td>0.054276</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>280</th>\n",
              "      <td>0.080386</td>\n",
              "      <td>0.054358</td>\n",
              "      <td>280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>326</th>\n",
              "      <td>0.080425</td>\n",
              "      <td>0.054363</td>\n",
              "      <td>326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>279</th>\n",
              "      <td>0.080394</td>\n",
              "      <td>0.054373</td>\n",
              "      <td>279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>0.080440</td>\n",
              "      <td>0.054377</td>\n",
              "      <td>199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.102929</td>\n",
              "      <td>0.064142</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.104646</td>\n",
              "      <td>0.065102</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.106585</td>\n",
              "      <td>0.066178</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.108979</td>\n",
              "      <td>0.067454</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.112141</td>\n",
              "      <td>0.069068</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         loss  val_loss  epoch\n",
              "200  0.080473  0.054276    200\n",
              "280  0.080386  0.054358    280\n",
              "326  0.080425  0.054363    326\n",
              "279  0.080394  0.054373    279\n",
              "199  0.080440  0.054377    199\n",
              "..        ...       ...    ...\n",
              "4    0.102929  0.064142      4\n",
              "3    0.104646  0.065102      3\n",
              "2    0.106585  0.066178      2\n",
              "1    0.108979  0.067454      1\n",
              "0    0.112141  0.069068      0\n",
              "\n",
              "[1000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ckmNMsTrYmR",
        "outputId": "ce2d8d11-e214-4911-ace7-d9141d9acb09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "plot_loss(lstm_model_history2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pflXCJGKg-7"
      },
      "source": [
        "# Kesimpulan dataset birth\n",
        "\n",
        "Untuk hasil validation loss pada model-model diatas perbedaannya tidak terlalu signifikan pula. Akan tetapi validation loss terendah didapatkan dengan model Deeper pada epoch ke-122, dimana:\n",
        "\n",
        "Epoch = 122\n",
        "\n",
        "Loss =\t0.081794\n",
        "\n",
        "Val_loss = \t0.053497"
      ]
    }
  ]
}