{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignmet_7_Sonar_Yoel_RegenT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GE8V30hlBG8u",
        "colab_type": "text"
      },
      "source": [
        "**Dataset Sonar**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xsiy4lqbBA17",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "4270ed3e-20fd-41c7-f69b-8fac160c49a6"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGjhjhWJDTyO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "935661c4-1e41-4902-a14b-fce16158d7ff"
      },
      "source": [
        "#os.chdir('drive/My Drive/BCML')\n",
        "#os.listdir('.')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Untitled0.ipynb',\n",
              " 'iris.csv',\n",
              " 'heart.csv',\n",
              " 'pima-indians-diabetes.csv',\n",
              " 'sonar.csv']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzhPvgPbDazF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "5974c584-1cfc-4d5f-9b92-80180e4737b1"
      },
      "source": [
        "dataset = pd.read_csv('sonar.csv')\n",
        "dataset.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>V29</th>\n",
              "      <th>V30</th>\n",
              "      <th>V31</th>\n",
              "      <th>V32</th>\n",
              "      <th>V33</th>\n",
              "      <th>V34</th>\n",
              "      <th>V35</th>\n",
              "      <th>V36</th>\n",
              "      <th>V37</th>\n",
              "      <th>V38</th>\n",
              "      <th>V39</th>\n",
              "      <th>V40</th>\n",
              "      <th>V41</th>\n",
              "      <th>V42</th>\n",
              "      <th>V43</th>\n",
              "      <th>V44</th>\n",
              "      <th>V45</th>\n",
              "      <th>V46</th>\n",
              "      <th>V47</th>\n",
              "      <th>V48</th>\n",
              "      <th>V49</th>\n",
              "      <th>V50</th>\n",
              "      <th>V51</th>\n",
              "      <th>V52</th>\n",
              "      <th>V53</th>\n",
              "      <th>V54</th>\n",
              "      <th>V55</th>\n",
              "      <th>V56</th>\n",
              "      <th>V57</th>\n",
              "      <th>V58</th>\n",
              "      <th>V59</th>\n",
              "      <th>V60</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0200</td>\n",
              "      <td>0.0371</td>\n",
              "      <td>0.0428</td>\n",
              "      <td>0.0207</td>\n",
              "      <td>0.0954</td>\n",
              "      <td>0.0986</td>\n",
              "      <td>0.1539</td>\n",
              "      <td>0.1601</td>\n",
              "      <td>0.3109</td>\n",
              "      <td>0.2111</td>\n",
              "      <td>0.1609</td>\n",
              "      <td>0.1582</td>\n",
              "      <td>0.2238</td>\n",
              "      <td>0.0645</td>\n",
              "      <td>0.0660</td>\n",
              "      <td>0.2273</td>\n",
              "      <td>0.3100</td>\n",
              "      <td>0.2999</td>\n",
              "      <td>0.5078</td>\n",
              "      <td>0.4797</td>\n",
              "      <td>0.5783</td>\n",
              "      <td>0.5071</td>\n",
              "      <td>0.4328</td>\n",
              "      <td>0.5550</td>\n",
              "      <td>0.6711</td>\n",
              "      <td>0.6415</td>\n",
              "      <td>0.7104</td>\n",
              "      <td>0.8080</td>\n",
              "      <td>0.6791</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>0.1307</td>\n",
              "      <td>0.2604</td>\n",
              "      <td>0.5121</td>\n",
              "      <td>0.7547</td>\n",
              "      <td>0.8537</td>\n",
              "      <td>0.8507</td>\n",
              "      <td>0.6692</td>\n",
              "      <td>0.6097</td>\n",
              "      <td>0.4943</td>\n",
              "      <td>0.2744</td>\n",
              "      <td>0.0510</td>\n",
              "      <td>0.2834</td>\n",
              "      <td>0.2825</td>\n",
              "      <td>0.4256</td>\n",
              "      <td>0.2641</td>\n",
              "      <td>0.1386</td>\n",
              "      <td>0.1051</td>\n",
              "      <td>0.1343</td>\n",
              "      <td>0.0383</td>\n",
              "      <td>0.0324</td>\n",
              "      <td>0.0232</td>\n",
              "      <td>0.0027</td>\n",
              "      <td>0.0065</td>\n",
              "      <td>0.0159</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0167</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>0.0032</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0453</td>\n",
              "      <td>0.0523</td>\n",
              "      <td>0.0843</td>\n",
              "      <td>0.0689</td>\n",
              "      <td>0.1183</td>\n",
              "      <td>0.2583</td>\n",
              "      <td>0.2156</td>\n",
              "      <td>0.3481</td>\n",
              "      <td>0.3337</td>\n",
              "      <td>0.2872</td>\n",
              "      <td>0.4918</td>\n",
              "      <td>0.6552</td>\n",
              "      <td>0.6919</td>\n",
              "      <td>0.7797</td>\n",
              "      <td>0.7464</td>\n",
              "      <td>0.9444</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.8874</td>\n",
              "      <td>0.8024</td>\n",
              "      <td>0.7818</td>\n",
              "      <td>0.5212</td>\n",
              "      <td>0.4052</td>\n",
              "      <td>0.3957</td>\n",
              "      <td>0.3914</td>\n",
              "      <td>0.3250</td>\n",
              "      <td>0.3200</td>\n",
              "      <td>0.3271</td>\n",
              "      <td>0.2767</td>\n",
              "      <td>0.4423</td>\n",
              "      <td>0.2028</td>\n",
              "      <td>0.3788</td>\n",
              "      <td>0.2947</td>\n",
              "      <td>0.1984</td>\n",
              "      <td>0.2341</td>\n",
              "      <td>0.1306</td>\n",
              "      <td>0.4182</td>\n",
              "      <td>0.3835</td>\n",
              "      <td>0.1057</td>\n",
              "      <td>0.1840</td>\n",
              "      <td>0.1970</td>\n",
              "      <td>0.1674</td>\n",
              "      <td>0.0583</td>\n",
              "      <td>0.1401</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.0621</td>\n",
              "      <td>0.0203</td>\n",
              "      <td>0.0530</td>\n",
              "      <td>0.0742</td>\n",
              "      <td>0.0409</td>\n",
              "      <td>0.0061</td>\n",
              "      <td>0.0125</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0089</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>0.0191</td>\n",
              "      <td>0.0140</td>\n",
              "      <td>0.0049</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0262</td>\n",
              "      <td>0.0582</td>\n",
              "      <td>0.1099</td>\n",
              "      <td>0.1083</td>\n",
              "      <td>0.0974</td>\n",
              "      <td>0.2280</td>\n",
              "      <td>0.2431</td>\n",
              "      <td>0.3771</td>\n",
              "      <td>0.5598</td>\n",
              "      <td>0.6194</td>\n",
              "      <td>0.6333</td>\n",
              "      <td>0.7060</td>\n",
              "      <td>0.5544</td>\n",
              "      <td>0.5320</td>\n",
              "      <td>0.6479</td>\n",
              "      <td>0.6931</td>\n",
              "      <td>0.6759</td>\n",
              "      <td>0.7551</td>\n",
              "      <td>0.8929</td>\n",
              "      <td>0.8619</td>\n",
              "      <td>0.7974</td>\n",
              "      <td>0.6737</td>\n",
              "      <td>0.4293</td>\n",
              "      <td>0.3648</td>\n",
              "      <td>0.5331</td>\n",
              "      <td>0.2413</td>\n",
              "      <td>0.5070</td>\n",
              "      <td>0.8533</td>\n",
              "      <td>0.6036</td>\n",
              "      <td>0.8514</td>\n",
              "      <td>0.8512</td>\n",
              "      <td>0.5045</td>\n",
              "      <td>0.1862</td>\n",
              "      <td>0.2709</td>\n",
              "      <td>0.4232</td>\n",
              "      <td>0.3043</td>\n",
              "      <td>0.6116</td>\n",
              "      <td>0.6756</td>\n",
              "      <td>0.5375</td>\n",
              "      <td>0.4719</td>\n",
              "      <td>0.4647</td>\n",
              "      <td>0.2587</td>\n",
              "      <td>0.2129</td>\n",
              "      <td>0.2222</td>\n",
              "      <td>0.2111</td>\n",
              "      <td>0.0176</td>\n",
              "      <td>0.1348</td>\n",
              "      <td>0.0744</td>\n",
              "      <td>0.0130</td>\n",
              "      <td>0.0106</td>\n",
              "      <td>0.0033</td>\n",
              "      <td>0.0232</td>\n",
              "      <td>0.0166</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0244</td>\n",
              "      <td>0.0316</td>\n",
              "      <td>0.0164</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0078</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0171</td>\n",
              "      <td>0.0623</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0368</td>\n",
              "      <td>0.1098</td>\n",
              "      <td>0.1276</td>\n",
              "      <td>0.0598</td>\n",
              "      <td>0.1264</td>\n",
              "      <td>0.0881</td>\n",
              "      <td>0.1992</td>\n",
              "      <td>0.0184</td>\n",
              "      <td>0.2261</td>\n",
              "      <td>0.1729</td>\n",
              "      <td>0.2131</td>\n",
              "      <td>0.0693</td>\n",
              "      <td>0.2281</td>\n",
              "      <td>0.4060</td>\n",
              "      <td>0.3973</td>\n",
              "      <td>0.2741</td>\n",
              "      <td>0.3690</td>\n",
              "      <td>0.5556</td>\n",
              "      <td>0.4846</td>\n",
              "      <td>0.3140</td>\n",
              "      <td>0.5334</td>\n",
              "      <td>0.5256</td>\n",
              "      <td>0.2520</td>\n",
              "      <td>0.2090</td>\n",
              "      <td>0.3559</td>\n",
              "      <td>0.6260</td>\n",
              "      <td>0.7340</td>\n",
              "      <td>0.6120</td>\n",
              "      <td>0.3497</td>\n",
              "      <td>0.3953</td>\n",
              "      <td>0.3012</td>\n",
              "      <td>0.5408</td>\n",
              "      <td>0.8814</td>\n",
              "      <td>0.9857</td>\n",
              "      <td>0.9167</td>\n",
              "      <td>0.6121</td>\n",
              "      <td>0.5006</td>\n",
              "      <td>0.3210</td>\n",
              "      <td>0.3202</td>\n",
              "      <td>0.4295</td>\n",
              "      <td>0.3654</td>\n",
              "      <td>0.2655</td>\n",
              "      <td>0.1576</td>\n",
              "      <td>0.0681</td>\n",
              "      <td>0.0294</td>\n",
              "      <td>0.0241</td>\n",
              "      <td>0.0121</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0150</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0073</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>0.0040</td>\n",
              "      <td>0.0117</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0762</td>\n",
              "      <td>0.0666</td>\n",
              "      <td>0.0481</td>\n",
              "      <td>0.0394</td>\n",
              "      <td>0.0590</td>\n",
              "      <td>0.0649</td>\n",
              "      <td>0.1209</td>\n",
              "      <td>0.2467</td>\n",
              "      <td>0.3564</td>\n",
              "      <td>0.4459</td>\n",
              "      <td>0.4152</td>\n",
              "      <td>0.3952</td>\n",
              "      <td>0.4256</td>\n",
              "      <td>0.4135</td>\n",
              "      <td>0.4528</td>\n",
              "      <td>0.5326</td>\n",
              "      <td>0.7306</td>\n",
              "      <td>0.6193</td>\n",
              "      <td>0.2032</td>\n",
              "      <td>0.4636</td>\n",
              "      <td>0.4148</td>\n",
              "      <td>0.4292</td>\n",
              "      <td>0.5730</td>\n",
              "      <td>0.5399</td>\n",
              "      <td>0.3161</td>\n",
              "      <td>0.2285</td>\n",
              "      <td>0.6995</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.7262</td>\n",
              "      <td>0.4724</td>\n",
              "      <td>0.5103</td>\n",
              "      <td>0.5459</td>\n",
              "      <td>0.2881</td>\n",
              "      <td>0.0981</td>\n",
              "      <td>0.1951</td>\n",
              "      <td>0.4181</td>\n",
              "      <td>0.4604</td>\n",
              "      <td>0.3217</td>\n",
              "      <td>0.2828</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.1979</td>\n",
              "      <td>0.2444</td>\n",
              "      <td>0.1847</td>\n",
              "      <td>0.0841</td>\n",
              "      <td>0.0692</td>\n",
              "      <td>0.0528</td>\n",
              "      <td>0.0357</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0230</td>\n",
              "      <td>0.0046</td>\n",
              "      <td>0.0156</td>\n",
              "      <td>0.0031</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0105</td>\n",
              "      <td>0.0110</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0107</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       V1      V2      V3      V4  ...     V58     V59     V60  Class\n",
              "0  0.0200  0.0371  0.0428  0.0207  ...  0.0084  0.0090  0.0032      1\n",
              "1  0.0453  0.0523  0.0843  0.0689  ...  0.0049  0.0052  0.0044      1\n",
              "2  0.0262  0.0582  0.1099  0.1083  ...  0.0164  0.0095  0.0078      1\n",
              "3  0.0100  0.0171  0.0623  0.0205  ...  0.0044  0.0040  0.0117      1\n",
              "4  0.0762  0.0666  0.0481  0.0394  ...  0.0048  0.0107  0.0094      1\n",
              "\n",
              "[5 rows x 61 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THGjMsGTDiK1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a1f6bfb2-0881-41ba-83ea-9878ed8ef9ca"
      },
      "source": [
        "dataset.info()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 208 entries, 0 to 207\n",
            "Data columns (total 61 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   V1      208 non-null    float64\n",
            " 1   V2      208 non-null    float64\n",
            " 2   V3      208 non-null    float64\n",
            " 3   V4      208 non-null    float64\n",
            " 4   V5      208 non-null    float64\n",
            " 5   V6      208 non-null    float64\n",
            " 6   V7      208 non-null    float64\n",
            " 7   V8      208 non-null    float64\n",
            " 8   V9      208 non-null    float64\n",
            " 9   V10     208 non-null    float64\n",
            " 10  V11     208 non-null    float64\n",
            " 11  V12     208 non-null    float64\n",
            " 12  V13     208 non-null    float64\n",
            " 13  V14     208 non-null    float64\n",
            " 14  V15     208 non-null    float64\n",
            " 15  V16     208 non-null    float64\n",
            " 16  V17     208 non-null    float64\n",
            " 17  V18     208 non-null    float64\n",
            " 18  V19     208 non-null    float64\n",
            " 19  V20     208 non-null    float64\n",
            " 20  V21     208 non-null    float64\n",
            " 21  V22     208 non-null    float64\n",
            " 22  V23     208 non-null    float64\n",
            " 23  V24     208 non-null    float64\n",
            " 24  V25     208 non-null    float64\n",
            " 25  V26     208 non-null    float64\n",
            " 26  V27     208 non-null    float64\n",
            " 27  V28     208 non-null    float64\n",
            " 28  V29     208 non-null    float64\n",
            " 29  V30     208 non-null    float64\n",
            " 30  V31     208 non-null    float64\n",
            " 31  V32     208 non-null    float64\n",
            " 32  V33     208 non-null    float64\n",
            " 33  V34     208 non-null    float64\n",
            " 34  V35     208 non-null    float64\n",
            " 35  V36     208 non-null    float64\n",
            " 36  V37     208 non-null    float64\n",
            " 37  V38     208 non-null    float64\n",
            " 38  V39     208 non-null    float64\n",
            " 39  V40     208 non-null    float64\n",
            " 40  V41     208 non-null    float64\n",
            " 41  V42     208 non-null    float64\n",
            " 42  V43     208 non-null    float64\n",
            " 43  V44     208 non-null    float64\n",
            " 44  V45     208 non-null    float64\n",
            " 45  V46     208 non-null    float64\n",
            " 46  V47     208 non-null    float64\n",
            " 47  V48     208 non-null    float64\n",
            " 48  V49     208 non-null    float64\n",
            " 49  V50     208 non-null    float64\n",
            " 50  V51     208 non-null    float64\n",
            " 51  V52     208 non-null    float64\n",
            " 52  V53     208 non-null    float64\n",
            " 53  V54     208 non-null    float64\n",
            " 54  V55     208 non-null    float64\n",
            " 55  V56     208 non-null    float64\n",
            " 56  V57     208 non-null    float64\n",
            " 57  V58     208 non-null    float64\n",
            " 58  V59     208 non-null    float64\n",
            " 59  V60     208 non-null    float64\n",
            " 60  Class   208 non-null    int64  \n",
            "dtypes: float64(60), int64(1)\n",
            "memory usage: 99.2 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IJwhWu-DoB1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "a4a99b90-ba62-4b40-e616-c9b533051166"
      },
      "source": [
        "dataset.describe()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>V29</th>\n",
              "      <th>V30</th>\n",
              "      <th>V31</th>\n",
              "      <th>V32</th>\n",
              "      <th>V33</th>\n",
              "      <th>V34</th>\n",
              "      <th>V35</th>\n",
              "      <th>V36</th>\n",
              "      <th>V37</th>\n",
              "      <th>V38</th>\n",
              "      <th>V39</th>\n",
              "      <th>V40</th>\n",
              "      <th>V41</th>\n",
              "      <th>V42</th>\n",
              "      <th>V43</th>\n",
              "      <th>V44</th>\n",
              "      <th>V45</th>\n",
              "      <th>V46</th>\n",
              "      <th>V47</th>\n",
              "      <th>V48</th>\n",
              "      <th>V49</th>\n",
              "      <th>V50</th>\n",
              "      <th>V51</th>\n",
              "      <th>V52</th>\n",
              "      <th>V53</th>\n",
              "      <th>V54</th>\n",
              "      <th>V55</th>\n",
              "      <th>V56</th>\n",
              "      <th>V57</th>\n",
              "      <th>V58</th>\n",
              "      <th>V59</th>\n",
              "      <th>V60</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.029164</td>\n",
              "      <td>0.038437</td>\n",
              "      <td>0.043832</td>\n",
              "      <td>0.053892</td>\n",
              "      <td>0.075202</td>\n",
              "      <td>0.104570</td>\n",
              "      <td>0.121747</td>\n",
              "      <td>0.134799</td>\n",
              "      <td>0.178003</td>\n",
              "      <td>0.208259</td>\n",
              "      <td>0.236013</td>\n",
              "      <td>0.250221</td>\n",
              "      <td>0.273305</td>\n",
              "      <td>0.296568</td>\n",
              "      <td>0.320201</td>\n",
              "      <td>0.378487</td>\n",
              "      <td>0.415983</td>\n",
              "      <td>0.452318</td>\n",
              "      <td>0.504812</td>\n",
              "      <td>0.563047</td>\n",
              "      <td>0.609060</td>\n",
              "      <td>0.624275</td>\n",
              "      <td>0.646975</td>\n",
              "      <td>0.672654</td>\n",
              "      <td>0.675424</td>\n",
              "      <td>0.699866</td>\n",
              "      <td>0.702155</td>\n",
              "      <td>0.694024</td>\n",
              "      <td>0.642074</td>\n",
              "      <td>0.580928</td>\n",
              "      <td>0.504475</td>\n",
              "      <td>0.439040</td>\n",
              "      <td>0.417220</td>\n",
              "      <td>0.403233</td>\n",
              "      <td>0.392571</td>\n",
              "      <td>0.384848</td>\n",
              "      <td>0.363807</td>\n",
              "      <td>0.339657</td>\n",
              "      <td>0.325800</td>\n",
              "      <td>0.311207</td>\n",
              "      <td>0.289252</td>\n",
              "      <td>0.278293</td>\n",
              "      <td>0.246542</td>\n",
              "      <td>0.214075</td>\n",
              "      <td>0.197232</td>\n",
              "      <td>0.160631</td>\n",
              "      <td>0.122453</td>\n",
              "      <td>0.091424</td>\n",
              "      <td>0.051929</td>\n",
              "      <td>0.020424</td>\n",
              "      <td>0.016069</td>\n",
              "      <td>0.013420</td>\n",
              "      <td>0.010709</td>\n",
              "      <td>0.010941</td>\n",
              "      <td>0.009290</td>\n",
              "      <td>0.008222</td>\n",
              "      <td>0.007820</td>\n",
              "      <td>0.007949</td>\n",
              "      <td>0.007941</td>\n",
              "      <td>0.006507</td>\n",
              "      <td>0.466346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.022991</td>\n",
              "      <td>0.032960</td>\n",
              "      <td>0.038428</td>\n",
              "      <td>0.046528</td>\n",
              "      <td>0.055552</td>\n",
              "      <td>0.059105</td>\n",
              "      <td>0.061788</td>\n",
              "      <td>0.085152</td>\n",
              "      <td>0.118387</td>\n",
              "      <td>0.134416</td>\n",
              "      <td>0.132705</td>\n",
              "      <td>0.140072</td>\n",
              "      <td>0.140962</td>\n",
              "      <td>0.164474</td>\n",
              "      <td>0.205427</td>\n",
              "      <td>0.232650</td>\n",
              "      <td>0.263677</td>\n",
              "      <td>0.261529</td>\n",
              "      <td>0.257988</td>\n",
              "      <td>0.262653</td>\n",
              "      <td>0.257818</td>\n",
              "      <td>0.255883</td>\n",
              "      <td>0.250175</td>\n",
              "      <td>0.239116</td>\n",
              "      <td>0.244926</td>\n",
              "      <td>0.237228</td>\n",
              "      <td>0.245657</td>\n",
              "      <td>0.237189</td>\n",
              "      <td>0.240250</td>\n",
              "      <td>0.220749</td>\n",
              "      <td>0.213992</td>\n",
              "      <td>0.213237</td>\n",
              "      <td>0.206513</td>\n",
              "      <td>0.231242</td>\n",
              "      <td>0.259132</td>\n",
              "      <td>0.264121</td>\n",
              "      <td>0.239912</td>\n",
              "      <td>0.212973</td>\n",
              "      <td>0.199075</td>\n",
              "      <td>0.178662</td>\n",
              "      <td>0.171111</td>\n",
              "      <td>0.168728</td>\n",
              "      <td>0.138993</td>\n",
              "      <td>0.133291</td>\n",
              "      <td>0.151628</td>\n",
              "      <td>0.133938</td>\n",
              "      <td>0.086953</td>\n",
              "      <td>0.062417</td>\n",
              "      <td>0.035954</td>\n",
              "      <td>0.013665</td>\n",
              "      <td>0.012008</td>\n",
              "      <td>0.009634</td>\n",
              "      <td>0.007060</td>\n",
              "      <td>0.007301</td>\n",
              "      <td>0.007088</td>\n",
              "      <td>0.005736</td>\n",
              "      <td>0.005785</td>\n",
              "      <td>0.006470</td>\n",
              "      <td>0.006181</td>\n",
              "      <td>0.005031</td>\n",
              "      <td>0.500070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.001500</td>\n",
              "      <td>0.000600</td>\n",
              "      <td>0.001500</td>\n",
              "      <td>0.005800</td>\n",
              "      <td>0.006700</td>\n",
              "      <td>0.010200</td>\n",
              "      <td>0.003300</td>\n",
              "      <td>0.005500</td>\n",
              "      <td>0.007500</td>\n",
              "      <td>0.011300</td>\n",
              "      <td>0.028900</td>\n",
              "      <td>0.023600</td>\n",
              "      <td>0.018400</td>\n",
              "      <td>0.027300</td>\n",
              "      <td>0.003100</td>\n",
              "      <td>0.016200</td>\n",
              "      <td>0.034900</td>\n",
              "      <td>0.037500</td>\n",
              "      <td>0.049400</td>\n",
              "      <td>0.065600</td>\n",
              "      <td>0.051200</td>\n",
              "      <td>0.021900</td>\n",
              "      <td>0.056300</td>\n",
              "      <td>0.023900</td>\n",
              "      <td>0.024000</td>\n",
              "      <td>0.092100</td>\n",
              "      <td>0.048100</td>\n",
              "      <td>0.028400</td>\n",
              "      <td>0.014400</td>\n",
              "      <td>0.061300</td>\n",
              "      <td>0.048200</td>\n",
              "      <td>0.040400</td>\n",
              "      <td>0.047700</td>\n",
              "      <td>0.021200</td>\n",
              "      <td>0.022300</td>\n",
              "      <td>0.008000</td>\n",
              "      <td>0.035100</td>\n",
              "      <td>0.038300</td>\n",
              "      <td>0.037100</td>\n",
              "      <td>0.011700</td>\n",
              "      <td>0.036000</td>\n",
              "      <td>0.005600</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.000600</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.000600</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.013350</td>\n",
              "      <td>0.016450</td>\n",
              "      <td>0.018950</td>\n",
              "      <td>0.024375</td>\n",
              "      <td>0.038050</td>\n",
              "      <td>0.067025</td>\n",
              "      <td>0.080900</td>\n",
              "      <td>0.080425</td>\n",
              "      <td>0.097025</td>\n",
              "      <td>0.111275</td>\n",
              "      <td>0.129250</td>\n",
              "      <td>0.133475</td>\n",
              "      <td>0.166125</td>\n",
              "      <td>0.175175</td>\n",
              "      <td>0.164625</td>\n",
              "      <td>0.196300</td>\n",
              "      <td>0.205850</td>\n",
              "      <td>0.242075</td>\n",
              "      <td>0.299075</td>\n",
              "      <td>0.350625</td>\n",
              "      <td>0.399725</td>\n",
              "      <td>0.406925</td>\n",
              "      <td>0.450225</td>\n",
              "      <td>0.540725</td>\n",
              "      <td>0.525800</td>\n",
              "      <td>0.544175</td>\n",
              "      <td>0.531900</td>\n",
              "      <td>0.534775</td>\n",
              "      <td>0.463700</td>\n",
              "      <td>0.411400</td>\n",
              "      <td>0.345550</td>\n",
              "      <td>0.281400</td>\n",
              "      <td>0.257875</td>\n",
              "      <td>0.217575</td>\n",
              "      <td>0.179375</td>\n",
              "      <td>0.154350</td>\n",
              "      <td>0.160100</td>\n",
              "      <td>0.174275</td>\n",
              "      <td>0.173975</td>\n",
              "      <td>0.186450</td>\n",
              "      <td>0.163100</td>\n",
              "      <td>0.158900</td>\n",
              "      <td>0.155200</td>\n",
              "      <td>0.126875</td>\n",
              "      <td>0.094475</td>\n",
              "      <td>0.068550</td>\n",
              "      <td>0.064250</td>\n",
              "      <td>0.045125</td>\n",
              "      <td>0.026350</td>\n",
              "      <td>0.011550</td>\n",
              "      <td>0.008425</td>\n",
              "      <td>0.007275</td>\n",
              "      <td>0.005075</td>\n",
              "      <td>0.005375</td>\n",
              "      <td>0.004150</td>\n",
              "      <td>0.004400</td>\n",
              "      <td>0.003700</td>\n",
              "      <td>0.003600</td>\n",
              "      <td>0.003675</td>\n",
              "      <td>0.003100</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.022800</td>\n",
              "      <td>0.030800</td>\n",
              "      <td>0.034300</td>\n",
              "      <td>0.044050</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>0.092150</td>\n",
              "      <td>0.106950</td>\n",
              "      <td>0.112100</td>\n",
              "      <td>0.152250</td>\n",
              "      <td>0.182400</td>\n",
              "      <td>0.224800</td>\n",
              "      <td>0.249050</td>\n",
              "      <td>0.263950</td>\n",
              "      <td>0.281100</td>\n",
              "      <td>0.281700</td>\n",
              "      <td>0.304700</td>\n",
              "      <td>0.308400</td>\n",
              "      <td>0.368300</td>\n",
              "      <td>0.434950</td>\n",
              "      <td>0.542500</td>\n",
              "      <td>0.617700</td>\n",
              "      <td>0.664900</td>\n",
              "      <td>0.699700</td>\n",
              "      <td>0.698500</td>\n",
              "      <td>0.721100</td>\n",
              "      <td>0.754500</td>\n",
              "      <td>0.745600</td>\n",
              "      <td>0.731900</td>\n",
              "      <td>0.680800</td>\n",
              "      <td>0.607150</td>\n",
              "      <td>0.490350</td>\n",
              "      <td>0.429600</td>\n",
              "      <td>0.391200</td>\n",
              "      <td>0.351050</td>\n",
              "      <td>0.312750</td>\n",
              "      <td>0.321150</td>\n",
              "      <td>0.306300</td>\n",
              "      <td>0.312700</td>\n",
              "      <td>0.283500</td>\n",
              "      <td>0.278050</td>\n",
              "      <td>0.259500</td>\n",
              "      <td>0.245100</td>\n",
              "      <td>0.222550</td>\n",
              "      <td>0.177700</td>\n",
              "      <td>0.148000</td>\n",
              "      <td>0.121350</td>\n",
              "      <td>0.101650</td>\n",
              "      <td>0.078100</td>\n",
              "      <td>0.044700</td>\n",
              "      <td>0.017900</td>\n",
              "      <td>0.013900</td>\n",
              "      <td>0.011400</td>\n",
              "      <td>0.009550</td>\n",
              "      <td>0.009300</td>\n",
              "      <td>0.007500</td>\n",
              "      <td>0.006850</td>\n",
              "      <td>0.005950</td>\n",
              "      <td>0.005800</td>\n",
              "      <td>0.006400</td>\n",
              "      <td>0.005300</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.035550</td>\n",
              "      <td>0.047950</td>\n",
              "      <td>0.057950</td>\n",
              "      <td>0.064500</td>\n",
              "      <td>0.100275</td>\n",
              "      <td>0.134125</td>\n",
              "      <td>0.154000</td>\n",
              "      <td>0.169600</td>\n",
              "      <td>0.233425</td>\n",
              "      <td>0.268700</td>\n",
              "      <td>0.301650</td>\n",
              "      <td>0.331250</td>\n",
              "      <td>0.351250</td>\n",
              "      <td>0.386175</td>\n",
              "      <td>0.452925</td>\n",
              "      <td>0.535725</td>\n",
              "      <td>0.659425</td>\n",
              "      <td>0.679050</td>\n",
              "      <td>0.731400</td>\n",
              "      <td>0.809325</td>\n",
              "      <td>0.816975</td>\n",
              "      <td>0.831975</td>\n",
              "      <td>0.848575</td>\n",
              "      <td>0.872175</td>\n",
              "      <td>0.873725</td>\n",
              "      <td>0.893800</td>\n",
              "      <td>0.917100</td>\n",
              "      <td>0.900275</td>\n",
              "      <td>0.852125</td>\n",
              "      <td>0.735175</td>\n",
              "      <td>0.641950</td>\n",
              "      <td>0.580300</td>\n",
              "      <td>0.556125</td>\n",
              "      <td>0.596125</td>\n",
              "      <td>0.593350</td>\n",
              "      <td>0.556525</td>\n",
              "      <td>0.518900</td>\n",
              "      <td>0.440550</td>\n",
              "      <td>0.434900</td>\n",
              "      <td>0.424350</td>\n",
              "      <td>0.387525</td>\n",
              "      <td>0.384250</td>\n",
              "      <td>0.324525</td>\n",
              "      <td>0.271750</td>\n",
              "      <td>0.231550</td>\n",
              "      <td>0.200375</td>\n",
              "      <td>0.154425</td>\n",
              "      <td>0.120100</td>\n",
              "      <td>0.068525</td>\n",
              "      <td>0.025275</td>\n",
              "      <td>0.020825</td>\n",
              "      <td>0.016725</td>\n",
              "      <td>0.014900</td>\n",
              "      <td>0.014500</td>\n",
              "      <td>0.012100</td>\n",
              "      <td>0.010575</td>\n",
              "      <td>0.010425</td>\n",
              "      <td>0.010350</td>\n",
              "      <td>0.010325</td>\n",
              "      <td>0.008525</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.137100</td>\n",
              "      <td>0.233900</td>\n",
              "      <td>0.305900</td>\n",
              "      <td>0.426400</td>\n",
              "      <td>0.401000</td>\n",
              "      <td>0.382300</td>\n",
              "      <td>0.372900</td>\n",
              "      <td>0.459000</td>\n",
              "      <td>0.682800</td>\n",
              "      <td>0.710600</td>\n",
              "      <td>0.734200</td>\n",
              "      <td>0.706000</td>\n",
              "      <td>0.713100</td>\n",
              "      <td>0.997000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.998800</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.965700</td>\n",
              "      <td>0.930600</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.964700</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.949700</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.985700</td>\n",
              "      <td>0.929700</td>\n",
              "      <td>0.899500</td>\n",
              "      <td>0.824600</td>\n",
              "      <td>0.773300</td>\n",
              "      <td>0.776200</td>\n",
              "      <td>0.703400</td>\n",
              "      <td>0.729200</td>\n",
              "      <td>0.552200</td>\n",
              "      <td>0.333900</td>\n",
              "      <td>0.198100</td>\n",
              "      <td>0.082500</td>\n",
              "      <td>0.100400</td>\n",
              "      <td>0.070900</td>\n",
              "      <td>0.039000</td>\n",
              "      <td>0.035200</td>\n",
              "      <td>0.044700</td>\n",
              "      <td>0.039400</td>\n",
              "      <td>0.035500</td>\n",
              "      <td>0.044000</td>\n",
              "      <td>0.036400</td>\n",
              "      <td>0.043900</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               V1          V2          V3  ...         V59         V60       Class\n",
              "count  208.000000  208.000000  208.000000  ...  208.000000  208.000000  208.000000\n",
              "mean     0.029164    0.038437    0.043832  ...    0.007941    0.006507    0.466346\n",
              "std      0.022991    0.032960    0.038428  ...    0.006181    0.005031    0.500070\n",
              "min      0.001500    0.000600    0.001500  ...    0.000100    0.000600    0.000000\n",
              "25%      0.013350    0.016450    0.018950  ...    0.003675    0.003100    0.000000\n",
              "50%      0.022800    0.030800    0.034300  ...    0.006400    0.005300    0.000000\n",
              "75%      0.035550    0.047950    0.057950  ...    0.010325    0.008525    1.000000\n",
              "max      0.137100    0.233900    0.305900  ...    0.036400    0.043900    1.000000\n",
              "\n",
              "[8 rows x 61 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OU0jlcz_Dq6l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "56870db5-ab1d-4fb7-b456-eafd412b7f51"
      },
      "source": [
        "dataset['Class'].value_counts()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    111\n",
              "1     97\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gs-nU1M-DvUe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "1d2c6721-48d3-41d7-cde7-75372435ee4a"
      },
      "source": [
        "dataset.columns"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
              "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n",
              "       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31',\n",
              "       'V32', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V39', 'V40', 'V41',\n",
              "       'V42', 'V43', 'V44', 'V45', 'V46', 'V47', 'V48', 'V49', 'V50', 'V51',\n",
              "       'V52', 'V53', 'V54', 'V55', 'V56', 'V57', 'V58', 'V59', 'V60', 'Class'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQrGcxuoDxad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sb.pairplot(dataset, hue='Class', size=3)\n",
        "#plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNT81-O5VnGC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "38e63c13-7298-4f09-9912-0dc96db66474"
      },
      "source": [
        "V = ('V1', 'V10', 'V20', 'V30', 'V40', 'V50', 'V60')\n",
        "for i in V:\n",
        "  dataset.plot(kind=\"scatter\", x=(i), y=\"Class\")\n",
        "  plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAcpklEQVR4nO3de5Bc5Xnn8e/TF80I3RlNxEojIWUlvJawNDZTGMWGkEBAJi6xiYQsskSLF5vdrKESm6SMyyniJbVlI2GIHcjGJCYpqBgsOxVQGVyiysZFsJGtURAQycEMV41kxEiWBEK3meln/+ju4fT9jGZOt6T396mimD7n7fc873tO90+nT1/M3RERkXClWl2AiIi0loJARCRwCgIRkcApCEREAqcgEBEJXKbVBYzWzJkzff78+a0uQ0TktLJt27Z97t5Zbd1pFwTz58+nt7e31WWIiJxWzOz1Wuv00pCISOAUBCIigVMQiIgETkEgIhI4BYGISOASe9eQmd0PfBx4y93Pr7LegK8BVwFHgOvd/d+Sqmf/4eP0HzhK14yJdExuG1V7gB173ubto4NMnZhlyeypI8vAWTJ7Gh2T2+jb+w7bdx2ke+50Fs6aQt/ed3i6bx8zJ7ex/D93jGx3tLVE+50xacKo7hvd3qQJad49MTwypvJl0fqqjTe63f2Hj/PEjjd5Zd9hrlx8Dgs6J1fUVW2cjZa9OnCYR7bvIZs2Ljj3bP7LOVPYc+goYMye1l5S/zMv72Pf4ROcP3sqRwaHS9oUxzVpQpo9h46x+8ARjg8Nc/7saRwZzI2Mbfa09or+i/eJ7ttax0WtfZGfw0OAsWT21KpjrXb/kz1Oy/fjaPsZD422WWt9rTkp/l1tf5SPe987x3iu/xCXLJpJz4KOutvcf/g4z7y8n9f3v8vZkyYwZ8ZElsyeVrLtWnMWd17z29jH6/uPcG7HpJLH/2j6inu8jZUl9e2jZnYJcBh4oEYQXAXcTD4IPgx8zd0/3Kjfnp4eH+3bRx/dvpvP//PzZFMpBnM51q9aysruObHaHxsaZmjYic6SAWaQKyzMpo0PLzibp/v2j7Q5b9YkfrH33ZHb6ZRx95plOIyqltseeYEHtrwxcjtlMGlCJtZ9o2MBODaYoy1tDLtjZqRTNrLMUsb6VUtx4JaN2xnKlY43kzbaM2kGcznW9HTxwDNvVGxrStt7dVUbZ6Nl7xwfqjsWYKT+4RzUOnIzKRjK5ffL4PDoju/ifYuyaeOr1yxjZfeckuPi6OAQZu/NSXRfPLp9N3/6nedGtp1JwV1rukvGWu3+oz02qu1bSxlrLuhi47b+2P2Mh0aPsVrryx9r7s7EbGZkforHaFE2bVx74Vw29vaPjLvcxQs7ePBTF1XdpgOf2/gcw7nS4yJl+cdotf0Zd4zRdp/99naimyg+/qPHSKO+4h5vcZnZNnfvqbouya+hNrP5wPdqBME3gB+5+0OF2y8Cl7r7L+v1Odog2H/4OB+544clB0x7NsWPP//bNf/VUt5+vExIpzBzjg+9N+f1aunb+w6X3/1Uzf7q3RdGP5a2jOEOJ0b55FmtHzCOR55Rqy9LAaXzcSpqy6R47OaP8vF7nq45l8V9AfAbX/lhyTgBJqTBLFWxPLqN8rkYr+O00XEyVo0eY7XWf++m+nM6Ft9cdwGfeejZkr7zx7dxYnj0cxb3eWT/4eMs//IPqj6G2jIpfnJr/hhp1Fej/Xsy+7ReELTyGsEcYFfkdn9hWQUzu9HMes2sd2BgYFQb6T9wlGyqdJjZVIr+A0djtx8/Ttri17J918G6vdW7L4x+LGlLkX/FbmzSliKdssbLUlYxH6eidMrYvutg3bks7ov+A0crxglgVI6/fBujOTZGs28bHSdj1egxVmt9ozkdiyd27q3oOz+/8f7RUT5ncZ9H+g8crfsYKh4jjfpqtH/He5+e+o9CwN3vc/ced+/p7Kz6CemaumZMZDBXmqqDudzIa25x2o8fY9jj19I9d3rd3urdF0Y/lmHPMR5niMOeqzj1rros5xXzcSoazjndc6fXncvivuiaMbFinABO5fjLtzGaY2M0+7bRcTJWjR5jtdY3mtOxuGLxrIq+8/Mb7x865XMW93mka8bEuo+h4jHSqK9G+3e892krg2A3MDdyu6uwbFx1TG5j/aqltGdTTGnL0J5NsX7V0pqnVOXts2mrOHSM/GuKRdm0cfHCjpI275s1qeR2OmXcec1SNqxeFruWhbOmsG75vJJlKSPWfcvH0p7N7+q2tJFJ5WuOLmvPptiwehl3XrOMTNlRYYUxFrdbXlNRcf2G1cvYsLp0zqsvK52POIr113s4F+vPpkd/dlM+9mza2LB6KQtnTSk5LopzWL4vOia3sWH10pJtZ1Jw5zXdJeMvv3/5XIzmOC3fj+uWz4vdz3ho9Birtb58TrOFfRudn+LYirJpGxlf+bqiixd2cNnicyq2mT++l1Y9M0tZ9f0Zd4zRdndes4zyTaRT+eOoeIw06qu8Ta3jbby08hrB7wI38d7F4q+7+4WN+jyZi8Wgdw3pXUN611DS9K6h0nan2ruGWnKx2MweAi4FZgJ7gb8AsgDu/reFt4/eA6wg//bRT7p7w2f4kw0CEZGQ1QuCxD5H4O7XNljvwGeS2r6IiMRzWlwsFhGR5CgIREQCpyAQEQmcgkBEJHAKAhGRwCkIREQCpyAQEQmcgkBEJHAKAhGRwCkIREQCpyAQEQmcgkBEJHAKAhGRwCkIREQCpyAQEQmcgkBEJHAKAhGRwCkIREQCpyAQEQmcgkBEJHAKAhGRwCkIREQCpyAQEQmcgkBEJHAKAhGRwCkIREQCpyAQEQmcgkBEJHAKAhGRwCkIREQCpyAQEQlcokFgZivM7EUz6zOzW6usn2dmT5rZs2b2vJldlWQ9IiJSKbEgMLM0cC/wMWAxcK2ZLS5r9ufARnf/ILAW+Juk6hERkeqSPCO4EOhz91fc/QTwMHB1WRsHphb+ngbsSbAeERGpIskgmAPsitzuLyyL+hJwnZn1A48DN1fryMxuNLNeM+sdGBhIolYRkWC1+mLxtcA/unsXcBXwoJlV1OTu97l7j7v3dHZ2Nr1IEZEzWZJBsBuYG7ndVVgWdQOwEcDdnwHagZkJ1iQiImWSDIKtwCIzW2BmE8hfDN5U1uYN4DIAM3s/+SDQaz8iIk2UWBC4+xBwE7AZ+Dn5dwftMLPbzWxlodktwKfN7DngIeB6d/ekahIRkUqZJDt398fJXwSOLrst8vdO4CNJ1iAiIvW1+mKxiIi0mIJARCRwCgIRkcApCEREAqcgEBEJnIJARCRwCgIRkcApCEREAqcgEBEJnIJARCRwCgIRkcApCEREAqcgEBEJnIJARCRwCgIRkcApCEREAqcgEBEJnIJARCRwCgIRkcApCEREAqcgEBEJnIJARCRwCgIRkcApCEREAqcgEBEJnIJARCRwCgIRkcApCEREAqcgEBEJnIJARCRwiQaBma0wsxfNrM/Mbq3RZo2Z7TSzHWb2rSTrERGRSpmkOjazNHAv8DtAP7DVzDa5+85Im0XAF4CPuPsBM/u1pOoREZHqkjwjuBDoc/dX3P0E8DBwdVmbTwP3uvsBAHd/K8F6RESkiiSDYA6wK3K7v7As6jzgPDP7sZltMbMV1ToysxvNrNfMegcGBhIqV0QkTK2+WJwBFgGXAtcCf2dm08sbuft97t7j7j2dnZ1NLlFE5MyWZBDsBuZGbncVlkX1A5vcfdDdXwV+QT4YRESkSZIMgq3AIjNbYGYTgLXAprI2j5A/G8DMZpJ/qeiVBGsSEZEyiQWBuw8BNwGbgZ8DG919h5ndbmYrC802A/vNbCfwJPBn7r4/qZpERKSSuXuraxiVnp4e7+3tbXUZIiKnFTPb5u491da1+mKxiIi0mIJARCRwCgIRkcApCEREAhcrCMzsj81squV908z+zcyuSLo4ERFJXtwzgv/h7m8DVwAzgD8EvpJYVSIi0jRxg8AK/78KeNDdd0SWiYjIaSxuEGwzsyfIB8FmM5sC5JIrS0REmiXu7xHcAHQDr7j7ETM7G/hkcmWJiEizxD0jWA686O4Hzew64M+BQ8mVJSIizRI3CP4fcMTMlgG3AC8DDyRWlYiINE3cIBjy/JcSXQ3c4+73AlOSK0tERJol7jWCd8zsC8B1wCVmlgKyyZUlIiLNEveM4BPAceAGd3+T/I/MbEisKhERaZpYZwSFJ/+7IrffQNcIRETOCHG/YuIiM9tqZofN7ISZDZuZ3jUkInIGiPvS0D3kf1z+JWAi8Cngb5IqSkREmif2t4+6ex+Qdvdhd/8HYEVyZYmISLPEfdfQkcIP0G83s/XAL9FXWIuInBHiPpn/IZAm/2P07wJzgVVJFSUiIs0T911Drxf+PAr8n+TKERGRZqsbBGb2AuC11rv70nGvSEREmqrRGcHvA7OAXWXL5wJvJlKRiIg0VaNrBHcDh9z99eh/5L959O7kyxMRkaQ1CoJZ7v5C+cLCsvmJVCQiIk3VKAim11k3cTwLERGR1mgUBL1m9unyhWb2KWBbMiWJiEgzNbpY/CfAv5jZf+O9J/4eYALwe0kWJiIizVE3CNx9L/AbZvZbwPmFxY+5+w8Tr0xERJoi7gfKngSeTLgWERFpAX1fkIhI4BINAjNbYWYvmlmfmd1ap90qM3Mz60myHhERqZRYEJhZGrgX+BiwGLjWzBZXaTcF+GPgp0nVIiIitSV5RnAh0Ofur7j7CeBh4Ooq7f4SuAM4lmAtIiJSQ5JBMIfS7yjqLywbYWYfAua6+2P1OjKzG82s18x6BwYGxr9SEZGAtexisZmlgLuAWxq1dff73L3H3Xs6OzuTL05EJCBJBsFu8t9SWtRVWFY0hfxnE35kZq8BFwGbdMFYRKS5kgyCrcAiM1tQ+JnLtcCm4kp3P+TuM919vrvPB7YAK929N8GaRESkTGJB4O5D5H/acjPwc2Cju+8ws9vNbGVS2xURkdGJ++P1J8XdHwceL1t2W422lyZZi4iIVKdPFouIBE5BICISOAWBiEjgFAQiIoFTEIiIBE5BICISOAWBiEjgFAQiIoFTEIiIBE5BICISOAWBiEjgFAQiIoFTEIiIBE5BICISOAWBiEjgFAQiIoFTEIiIBE5BICISOAWBiEjgFAQiIoFTEIiIBE5BICISOAWBiEjgFAQiIoFTEIiIBE5BICISOAWBiEjgFAQiIoFTEIiIBE5BICISuESDwMxWmNmLZtZnZrdWWf85M9tpZs+b2Q/M7Nwk6xERkUqJBYGZpYF7gY8Bi4FrzWxxWbNngR53Xwp8F1ifVD0iIlJdkmcEFwJ97v6Ku58AHgaujjZw9yfd/Ujh5hagK8F6RESkiiSDYA6wK3K7v7CslhuA71dbYWY3mlmvmfUODAyMY4kiInJKXCw2s+uAHmBDtfXufp+797h7T2dnZ3OLExE5w2US7Hs3MDdyu6uwrISZXQ58EfhNdz+eYD0iIlJFkmcEW4FFZrbAzCYAa4FN0QZm9kHgG8BKd38rwVpERKSGxILA3YeAm4DNwM+Bje6+w8xuN7OVhWYbgMnAd8xsu5ltqtGdiIgkJMmXhnD3x4HHy5bdFvn78iS3LyIijZ0SF4tFRKR1FAQiIoFTEIiIBE5BICISOAWBiEjgFAQiIoFTEIiIBE5BICISOAWBiEjgFAQiIoFTEIiIBE5BICISOAWBiEjgFAQiIoFTEIiIBE5BICISOAWBiEjgFAQiIoFTEIiIBE5BICISOAWBiEjgFAQiIoFTEIiIBE5BICISOAWBiEjgFAQiIoFTEIiIBE5BICISOAWBiEjgFAQiIoFTEIiIBC6TZOdmtgL4GpAG/t7dv1K2vg14ALgA2A98wt1fS7ImgP2Hj9N/4ChdMybSMbmt5rLR9FHt9o49bwPOktnTSvqMrps9bSJ7Dh2r2m409ccdQ9xxFttNmpDm3RPDTJqQZs+ho4CxZPbUijG/OnCYp17ax7Kuacyc0k7XjIkcePcE23cdpHvudBbOmlKz7zjjqHWf4ly+fXSQqROzLJk9FaDKvjhUUnvcua1WS9/ed0rGVW2uijWW1xJ3vwI1a+7b+w6bd/wSMK5ccg4zJk2oO59x9vGeQ8d4++iJwhxOK2z/vWO0vN/onM6e1s6PXnyLF3YfYuWy2XTPm1FRT7V56H11P0+9tI9LFs2kZ0FHRU1bX/sVO/a8zZLZU7liyTkj9/vBzjd5Yuderlg8i8sWn1N1TINDw7y2/wgzzspy4Mgg8zvOIptJl9RSHPfuA0c4PpTjowtnsnDWlKr794kdb1atpdg22n/cx3/0mK21v6K1FPdz3P07Gubu49rhSMdmaeAXwO8A/cBW4Fp33xlp87+Bpe7+v8xsLfB77v6Jev329PR4b2/vSdf16PbdfP6fnyebSjGYy7F+1VIcKpat7J4Tu481F3SxcVv/e7d7uvjWT99gKJdvn00bX71mGSu75/Do9t3csnH7yLqoaLvR1F/st9EY4rSJtgM4NpgjbTAcOUwyKfiDD89jY29+zO8cHyq5vwFmkIvcZ93yedx+9Qcq+m5LG5ayuuMo7h/POceHnfZs/kR2zQVdfOtnb5TMZcry/03MZkb2zUNbdzFYGEAmBXet6a477lr7df2qpfS+9ise2PLGyH0uXtjB1tcPVMxVezbFcM5x95Fa6h1X0W0fGxpmOOcj8xet+bZHXijZfnHM2ZSVzE3cY7hYd1Q6ZeRyTvSZIbqfHPjT7zw3MqfVtKXfq2doOIeZ0Z5Jj8zDxt5dPN23v2QeV/fMLdnP5b6+tpt7nnyJX+x9d2TZ+2ZNYvNnLy0Z03DOq9aWKbz+YWakU1Yx7mJ/L0b6v3hhB/8aqTNaS/mxkDbIZlKjfvzXOibL93U6ZZyVTcd6jqrGzLa5e0/VdQkGwXLgS+5+ZeH2FwDc/cuRNpsLbZ4xswzwJtDpdYoaSxDsP3ycj9zxw5IDoC2TApzjQ+9tsj2b4sef/+2qqVutjzjaMikeu/mj/O5f/2vJtqq1+8mt8bfdnk3xvZs+ysfvebpieXQMte5bPs6THV8c3/2fF3Hd/T+r2netcVTbP2PVljF+cutlox53WybF8WoJHlOt4yreto1/uuHDrP7GljFtK+726tUBNqZ5mJBOcWK48v7ZFNQryYBqR8E3111A97wZiR231aSB4VG0b/T4Lz8m+/a+w+V3P1Wzv3r7t5Z6QZDkNYI5wK7I7f7Csqpt3H0IOAR0lHdkZjeaWa+Z9Q4MDJx0Qf0HjpJNlQ45nTLSVrosm0rRf+Bo7D7iSKeM7bsOVmyrWrvRbDubSrF918Gqy6P91Lpv+bZOdnxxPPXSvpp91xpHtf0zVmlr7riLah1XcbadthRPvbRvzNuKu716ddhJ3TOqRqhb/Z5r/VPgiZ17m7L/4tRSS6PHf/kxuX3Xwbr91du/J+O0uFjs7ve5e4+793R2dp50P10zJjKYK/0Xw3DOGfbSZYO53MhriXH6iGM453TPnV6xrWrtRrPtwVyO7rnTqy6P9lPrvuXbOtnxxXHJopk1+641jmr7Z6yGvbnjLqp1XMXZ9rDnuGTRzDFvK+726tUx9nOzGk/4DV6dqBUTVyye1ZT9F6eWWho9/suPye650+v2V2//nowkg2A3MDdyu6uwrGqbwktD08hfNE5Ex+Q21q9aSns2xZS2DO3ZFBtWL2XD6mUly9avWlrzlKtaH+uWz6u4nYnMbDZtbFi9lIWzprBh9bKSdVHFdqPZ9vpV+X6rLY/2U+u+5duKtiu+3pwuO+ozKUrGXM7Iv24dtW75PHoWdFT03Za2uuOI7p+2QiHF+5fPM4XtZlKU7ItsZACZFGxYvazuuGvt1w2rl7Ju+byS+128sKPqXLVnU2TTVlJLreOqfNvZtJXMX7HmngUdFdsvjrl8buIew8W6o9Ipq3iiK+6nDauXsWH10pI5rSZaTyaVP7aL83DnNUu5eGHpif/FCzv46prukv1c7mtru3nfrEkly943axKXLT6nZEy1asukGKml2riL/ZXXVc3da7sr9kXaOKnHf7VjcuGsKZX9pyzWc9TJSPIaQYb8xeLLyD/hbwX+wN13RNp8BvhA5GLx77v7mnr9jvViMehdQ3rXkN41VD6netfQmf+uoZZcLC5s+Crgr8hfW7nf3f+vmd0O9Lr7JjNrBx4EPgj8Cljr7q/U63M8gkBEJDT1giDRzxG4++PA42XLbov8fQy4JskaRESkvtPiYrGIiCRHQSAiEjgFgYhI4BQEIiKBS/RdQ0kwswHg9VbX0SQzgfgfJz0zaQ40B0Wah7HNwbnuXvUTuaddEITEzHprvd0rFJoDzUGR5iG5OdBLQyIigVMQiIgETkFwaruv1QWcAjQHmoMizUNCc6BrBCIigdMZgYhI4BQEIiKBUxCcAsxshZm9aGZ9ZnZrlfWfM7OdZva8mf3AzM5tRZ1JajQHkXarzMzN7Ix7G2GcOTCzNYVjYYeZfavZNSYtxmNhnpk9aWbPFh4PV7WiziSZ2f1m9paZ/XuN9WZmXy/M0fNm9qExb9Td9V8L/yP/Fd0vA78OTACeAxaXtfkt4KzC338EfLvVdTd7DgrtpgBPAVuAnlbX3YLjYBHwLDCjcPvXWl13C+bgPuCPCn8vBl5rdd0JzMMlwIeAf6+x/irg++R/A+oi4Kdj3abOCFrvQqDP3V9x9xPAw8DV0Qbu/qS7Hync3EL+197OJA3noOAvgTuAY80srknizMGngXvd/QCAu7/V5BqTFmcOHJha+HsasKeJ9TWFuz9F/vdZarkaeMDztgDTzew/jWWbCoLWmwPsitzuLyyr5Qby/xo4kzScg8Lp71x3f6yZhTVRnOPgPOA8M/uxmW0xsxVNq6454szBl4DrzKyf/G+d3Nyc0k4po33OaCjRH6aR8WVm1wE9wG+2upZmMrMUcBdwfYtLabUM+ZeHLiV/VviUmX3A3Q+2tKrmuhb4R3f/qpktBx40s/Pda/wqvMSiM4LW2w3MjdzuKiwrYWaXA18EVrr78SbV1iyN5mAKcD7wIzN7jfzropvOsAvGcY6DfmCTuw+6+6vkfxN8UZPqa4Y4c3ADsBHA3Z8B2sl/EVtIYj1njIaCoPW2AovMbIGZTQDWApuiDczsg8A3yIfAmfa6MDSYA3c/5O4z3X2+u88nf51kpbufST9e3fA4AB4hfzaAmc0k/1JR3d/4Ps3EmYM3gMsAzOz95INgoKlVtt4mYF3h3UMXAYfc/Zdj6VAvDbWYuw+Z2U3AZvLvmrjf3XeY2e1Ar7tvAjYAk4HvmBnAG+6+smVFj7OYc3BGizkHm4ErzGwnMAz8mbvvb13V4yvmHNwC/J2ZfZb8hePrvfBWmjOFmT1EPvBnFq6F/AWQBXD3vyV/beQqoA84AnxyzNs8w+ZQRERGSS8NiYgETkEgIhI4BYGISOAUBCIigVMQiIgETkEgEkPhGy+vLFv2J2b2fTN7pvBtoM+b2Sci6xeY2U8L3xL57cJ740VOOQoCkXgeIv8Bp6i1wJeBde6+BFgB/JWZTS+svwO4290XAgfIfypW5JSjzxGIxGBmZwP/AXS5+wkzm0/+K7HPjX6gycyeA1aT/7DPAHBO4YNSy4EvufuVFZ2LtJjOCERicPdfAT8DPlZYtBbYWBYCF5L/Hv2XgQ7goLsPFVaP+RsiRZKiIBCJL/ry0NrCbQAK3wf/IPBJfROmnG4UBCLxPQpcVvhthLPcfRuAmU0FHgO+WPihEID95H8wpPh9XmP+hkiRpCgIRGJy98PAk8D9FM4GCu8E+hfyvxj13UhbL7RdXVj038kHicgpRxeLRUbBzP4r+Sf+97v7fxR+LOgfgB2RZte7+3Yz+3XyP7d4NvnfGr7uDPwtCTkDKAhERAKnl4ZERAKnIBARCZyCQEQkcAoCEZHAKQhERAKnIBARCZyCQEQkcP8f6z4ctPhroTYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAXHElEQVR4nO3df5Dc9X3f8ed7706/kJDE6axYvywY5NiABXavcrBj18WxDaQDdsA2tJg6IaaehEyc2h2g9lCHTlMbmrjuQBLTxG1xpybEqY0mpsWNTaYTj6GcjGwiYYjMD+skA4oQAiEh6e7e/WP35OW00u3p7runu8/zMXOj/X4/n/1+3/u51b5u9/Pd7zcyE0lSuWrTXYAkaXoZBJJUOINAkgpnEEhS4QwCSSpc93QXMFHLli3LtWvXTncZkjSjbNq06e8zs69V24wLgrVr1zIwMDDdZUjSjBIRTx+rzY+GJKlwBoEkFc4gkKTCGQSSVDiDQJIKV9lRQxHxZeCfAM9l5jkt2gP4InAxsB/4aGZ+v6p6xtq97yBbdr7IiwcOse+VIXa/fIih4RF27TvE2StOZXh4hL985BlWLJ7Hmt4FvHxomGULetj6zD6WzOump6eLc1Ys4oUDQwwNj3BwaJg53V30dAVL5vfwtztf4sy+U+hfexovHxrmlDldfPOHO3ngyedZ17eQM16zkNVL57N9zwGWLZzDjuf387+3PsuGtafxwf7V/OiZl9j6070EsGrpAlYuXcCCnhoPPvk8u/cdBKB34Rzed/ZrOXP5osbj2cuLBw4Dwanzuzl7xWIAtux8EUjOXrGY3oVzAdj27Ets3v4CSxf0sGf/Ydb2LmD/4RFePHCIU+f3HOm7e99BBvccYNXS+fQunHvkfuetXsKZyxe1HNfR/sCr7juZ39WxttOq7Xj9JR0tqjr7aES8E9gH3HmMILgY+C3qQfBW4IuZ+dbxttvf35+TPXz0ns07+OTdmxkamdRm2tZdo9J9/eKZvTz45PMcHn7177KrFoyMJKNre7qC3//guQw89Tx3PvCT426zpyu4csNq7h4YpKdW4/DICP2vW8rfbNt9pM/V56/h5kvfdGT5ns07uP4vfkhPrcaBw0NEBPO6uzg8MsItl63nkvNWTvixNW9z7HZatSUcs79UsojYlJn9LduqPA11RKwF/vIYQfAl4K8z86uN5ceAd2XmT4+3zckGwe59B3nb577NwaEyT789p6vGoeGpS6W/+p13HnlH8vbPf4dXDrfe9ryeGt+9/oIJ/YXeapuj2wGOapvbXQPyVb/bE9mvNBsdLwimc45gJbC9aXmwse4oEXFtRAxExMCuXbsmtdPBPQfoipKnRqY2ADdvfwGoj2tP7djj2lOrMbjnwIS23Wqbo9tp1dZVi6N+tyeyX6k0M+IVMTPvyMz+zOzv62v5Dem2rVo6n+Hs0GdCJ6WY0q2dt3oJUB/XwyPHHtfDIyNH5g3a1Wqbo9tp1TY8kkf9bk9kv1JppjMIdgCrm5ZXNdZVqnfhXG69/Fy6O/jIq97XO87spafr6Bf4rlq86mW/pyv4Dx9cz9Xnrxl3mz1dwdXnr2FeT41Fc7uZ11PjHWf2vqrP1eevOTJh3LtwLrdctv5I/+5afRuj973lsvUT/nhm7Dabt9Oq7dbL13Pr5ee27C/p2KZzjuCXgev42WTxf8rMDeNtcyomi8GjhjxqSCrLtEwWR8RXgXcBy4BngX8D9ABk5h83Dh+9DbiQ+uGjv5qZ477CT1UQSFJJjhcElX2PIDOvHKc9gd+sav+SpPbMiMliSVJ1DAJJKpxBIEmFMwgkqXAGgSQVziCQpMIZBJJUOINAkgpnEEhS4QwCSSqcQSBJhTMIJKlwBoEkFc4gkKTCGQSSVDiDQJIKZxBIUuEMAkkqnEEgSYUzCCSpcAaBJBXOIJCkwhkEklQ4g0CSCmcQSFLhDAJJKpxBIEmFMwgkqXAGgSQVziCQpMIZBJJUuEqDICIujIjHImJbRNzQon1NRNwfEQ9HxA8j4uIq65EkHa2yIIiILuB24CLgLODKiDhrTLfPAHdn5puBK4A/rKoeSVJrVb4j2ABsy8wnMvMQcBdw6Zg+CZzauL0Y2FlhPZKkFqoMgpXA9qblwca6Zp8FroqIQeBe4LdabSgiro2IgYgY2LVrVxW1SlKxpnuy+Ergv2bmKuBi4CsRcVRNmXlHZvZnZn9fX1/Hi5Sk2azKINgBrG5aXtVY1+wa4G6AzPweMA9YVmFNkqQxqgyCh4B1EXF6RMyhPhm8cUyfnwDvBoiIN1IPAj/7kaQOqiwIMnMIuA64D3iU+tFBWyLi5oi4pNHtk8DHIuIHwFeBj2ZmVlWTJOlo3VVuPDPvpT4J3LzupqbbW4G3V1mDJOn4pnuyWJI0zQwCSSqcQSBJhTMIJKlwBoEkFc4gkKTCGQSSVDiDQJIKZxBIUuEMAkkqnEEgSYUzCCSpcAaBJBXOIJCkwhkEklQ4g0CSCmcQSFLhDAJJKpxBIEmFMwgkqXAGgSQVziCQpMIZBJJUOINAkgpnEEhS4QwCSSqcQSBJhTMIJKlwBoEkFc4gkKTCVRoEEXFhRDwWEdsi4oZj9PlQRGyNiC0R8T+qrEeSdLTuqjYcEV3A7cB7gEHgoYjYmJlbm/qsA24E3p6ZeyLiNVXVI0lqrcp3BBuAbZn5RGYeAu4CLh3T52PA7Zm5ByAzn6uwHklSC1UGwUpge9PyYGNds9cDr4+I70bEAxFxYasNRcS1ETEQEQO7du2qqFxJKtN0TxZ3A+uAdwFXAv85IpaM7ZSZd2Rmf2b29/X1dbhESZrdqgyCHcDqpuVVjXXNBoGNmXk4M58EHqceDJKkDqkyCB4C1kXE6RExB7gC2DimzzeovxsgIpZR/6joiQprkiSNUVkQZOYQcB1wH/AocHdmbomImyPikka3+4DdEbEVuB/4V5m5u6qaJElHi8yc7hompL+/PwcGBqa7DEmaUSJiU2b2t2qb7sliSdI0MwgkqXAGgSQVziCQpMK1FQQR8dsRcWrU/WlEfD8i3lt1cZKk6rX7juDXMvNF4L3AUuAjwOcqq0qS1DHtBkE0/r0Y+EpmbmlaJ0mawdoNgk0R8S3qQXBfRCwCRqorS5LUKe1ej+Aa4DzgiczcHxGnAb9aXVmSpE5p9x3B+cBjmflCRFwFfAbYW11ZkqROaTcI/gjYHxHnAp8EfgzcWVlVkqSOaTcIhrJ+UqJLgdsy83ZgUXVlSZI6pd05gpci4kbgKuCdEVEDeqorS5LUKe2+I/gwcBC4JjOfoX6RmVsrq0qS1DFtvSNovPj/QdPyT3COQJJmhXZPMfELEfFQROyLiEMRMRwRHjUkSbNAux8N3Ub94vJ/B8wHfh34w6qKkiR1TttnH83MbUBXZg5n5n8BLqyuLElSp7R71ND+xgXoN0fELcBP8RTWkjQrtPti/hGgi/rF6F8GVgOXVVWUJKlz2j1q6OnGzQPA71ZXjiSp044bBBHxCJDHas/M9VNekSSpo8Z7R/ArwHJg+5j1q4FnKqlIktRR480RfAHYm5lPN/9QP/PoF6ovT5JUtfGCYHlmPjJ2ZWPd2koqkiR11HhBsOQ4bfOnshBJ0vQYLwgGIuJjY1dGxK8Dm6opSZLUSeNNFn8C+HpE/DN+9sLfD8wBPlBlYZKkzjhuEGTms8DbIuIfA+c0Vn8zM79TeWWSpI5o9wtl9wP3V1yLJGkaeL4gSSpcpUEQERdGxGMRsS0ibjhOv8siIiOiv8p6JElHqywIIqILuB24CDgLuDIizmrRbxHw28CDVdUiSTq2Kt8RbAC2ZeYTmXkIuAu4tEW/fwt8HnilwlokScdQZRCs5NXnKBpsrDsiIt4CrM7Mbx5vQxFxbUQMRMTArl27pr5SSSrYtE0WR0QN+APgk+P1zcw7MrM/M/v7+vqqL06SClJlEOygfpbSUasa60Ytov7dhL+OiKeAXwA2OmEsSZ1VZRA8BKyLiNMbl7m8Atg42piZezNzWWauzcy1wAPAJZk5UGFNkqQxKguCzByifmnL+4BHgbszc0tE3BwRl1S1X0nSxLR78foTkpn3AveOWXfTMfq+q8paJEmt+c1iSSqcQSBJhTMIJKlwBoEkFc4gkKTCGQSSVDiDQJIKZxBIUuEMAkkqnEEgSYUzCCSpcAaBJBXOIJCkwhkEklQ4g0CSCmcQSFLhDAJJKpxBIEmFMwgkqXAGgSQVziCQpMIZBJJUOINAkgpnEEhS4QwCSSqcQSBJhTMIJKlwBoEkFc4gkKTCGQSSVLhKgyAiLoyIxyJiW0Tc0KL9X0bE1oj4YUR8OyJeV2U9kqSjVRYEEdEF3A5cBJwFXBkRZ43p9jDQn5nrga8Bt1RVjySptSrfEWwAtmXmE5l5CLgLuLS5Q2ben5n7G4sPAKsqrEeS1EKVQbAS2N60PNhYdyzXAP+rVUNEXBsRAxExsGvXriksUZJ0UkwWR8RVQD9wa6v2zLwjM/szs7+vr6+zxUnSLNdd4bZ3AKubllc11r1KRPwS8GngH2XmwQrrkSS1UOU7goeAdRFxekTMAa4ANjZ3iIg3A18CLsnM5yqsRZJ0DJUFQWYOAdcB9wGPAndn5paIuDkiLml0uxVYCPx5RGyOiI3H2JwkqSJVfjREZt4L3Dtm3U1Nt3+pyv1LksZ3UkwWS5Kmj0EgSYUzCCSpcAaBJBXOIJCkwhkEklQ4g0CSCmcQSFLhDAJJKpxBIEmFMwgkqXAGgSQVziCQpMIZBJJUOINAkgpnEEhS4QwCSSqcQSBJhTMIJKlwBoEkFc4gkKTCGQSSVDiDQJIKZxBIUuEMAkkqnEEgSYUzCCSpcAaBJBXOIJCkwhkEklQ4g0CSCtdd5cYj4kLgi0AX8CeZ+bkx7XOBO4F/AOwGPpyZT1VRy+59B9my80UgOXvFYgAG9xzglDldDDz1PH+780VOmdPFCLBsQQ8PPrWH7hqcs3IxXbUawyMjPPfSQRbM6eaxZ1/i5YNDvGH5Qn6y5xXWnraAM16zkNVL5/OjZ15i/6Eh3vjaxbzh5xaxc+8r7Nyzn+179rPjhQPsfukQp87vohY1+hbNZd3yRaxcOp+zVyymd+Fcdu87yLe2PMOmp59n+anz+MCbV3Hm8kVse/YlNm9/gfNWL2HpKXPYsnMvEJy94lR6F85l4MndfGPzDhbP7zlyn29vfYZvbX2W9561nPPWLGXLzhd5/JkXeWr3fl7Xu4Cf/7lFrxqLVUvnH6lhdGxePjR8ZP2o0VrW9i6gp7uLU+Z0sXPvASBYsXhey/uM/g6a99Oq7fDQME/t3s95q5dw5vJFU/r7H2/fU9k2kT5SO6p8LkVmTukGj2w4ogt4HHgPMAg8BFyZmVub+vwGsD4zPx4RVwAfyMwPH2+7/f39OTAwMKFa7tm8g0/evZmhkfpyVy0Ikq4IDg5X8/gnqqcruHLDau783k+Oanv98lN4/NmXjywHMFp1dw3O6Ht1O8DieV3sfWV43P2OjsX8nm4Oj4zwof5V3D0wSI4kB4eTeT31N423XLaeS85byU3feIQ7H/hZjbWAkTFDOPY+UP8dXP8XP6SnVuPwyEjLtqHhkSO/I4Crz1/DzZe+adzHMJ529j2Vbe3sV5qIqXguRcSmzOxv2VZhEJwPfDYz39dYvhEgM/99U5/7Gn2+FxHdwDNAXx6nqIkGwe59B3nb577NwaGT4wV/pprXU+O//9oGLv/SAxO6z3evvwCAt3/+O7xyeKSttmZ/9TvvnNQ7g937Dk5o35NtG/1L7Xj79Z2BJmKqnkvHC4Iq5whWAtublgcb61r2ycwhYC/QO3ZDEXFtRAxExMCuXbsmVMTgngN0hVMhk9VTq/F//+7vJ3yfwT0HGNxzgJ5are22Zpu3v3BC9Y6a6L4n29bOfqWJ6MRzaUa8QmbmHZnZn5n9fX19E7rvqqXzGc7Wf22qfYdHRnjnumUTvs+qpfNZtXQ+h0dG2m5rdt7qJSdU76iJ7nuybe3sV5qITjyXqgyCHcDqpuVVjXUt+zQ+GlpMfdJ4yvQunMutl59Ld9Mj7aoF3TWY2xVTuatJ6ekKrj5/Tcu2n19+yquWm6vurh3dDvU5gnaMjsWiud3M66lx9flrmNdTOzI283pqzOupcctl6+k/vfeoGmsthrD5Pr0L59K7cC63XLaeeT21I/tp1dY95tl49flrJj1h3O6+p6qtnf1KE9GJ51KVcwTd1CeL3039Bf8h4J9m5pamPr8JvKlpsvhXMvNDx9vuiUwWg0cNedSQRw1pZpvsc2laJosbO74Y+I/UDx/9cmb+u4i4GRjIzI0RMQ/4CvBm4Hngisx84njbPNEgkKSSHS8IKv0eQWbeC9w7Zt1NTbdfAT5YZQ2SpOObEZPFkqTqGASSVDiDQJIKZxBIUuEqPWqoChGxC3i6ze7LgIl9HbYMjsuxOTatOS6tzaRxeV1mtvxG7owLgomIiIFjHS5VMsfl2Byb1hyX1mbLuPjRkCQVziCQpMLN9iC4Y7oLOEk5Lsfm2LTmuLQ2K8ZlVs8RSJLGN9vfEUiSxmEQSFLhZmwQRMSFEfFYRGyLiBtatM+NiD9rtD8YEWub2m5srH8sIt7XybqrdqLjEhG9EXF/ROyLiNs6XXfVJjEu74mITRHxSOPfCzpde9UmMTYbImJz4+cHEfGBTtdepcm8xjTa1zT+P32qUzWfsMyccT/UT2v9Y+AMYA7wA+CsMX1+A/jjxu0rgD9r3D6r0X8ucHpjO13T/ZhOgnE5BfhF4OPAbdP9WE6icXkzsKJx+xxgx3Q/npNobBYA3Y3brwWeG12e6T+TGZem9q8Bfw58arofz3g/M/UdwQZgW2Y+kZmHgLuAS8f0uRT4b43bXwPeHRHRWH9XZh7MzCeBbY3tzQYnPC6Z+XJm/g3wSufK7ZjJjMvDmbmzsX4LMD8iZtMVZiYzNvuzfq1xgHnAbDryZDKvMUTE+4EnqT9nTnozNQiOXPS+YbCxrmWfxpN1L9Db5n1nqsmMy2w2VeNyGfD9zDxYUZ3TYVJjExFvjYgtwCPAx5uCYaY74XGJiIXA9cDvdqDOKTFTg0DqqIg4G/g88C+mu5aTSWY+mJlnA/8QuLFx1cHSfRb4Qmbum+5C2jVTg+DIRe8bVjXWtezTuH7yYmB3m/edqSYzLrPZpMYlIlYBXweuzswfV15tZ03JcyYzHwX2UZ9HmQ0mMy5vBW6JiKeATwD/OiKuq7rgyZipQfAQsC4iTo+IOdQnajaO6bMR+OeN25cD38n6DM5G4IrGjP/pwDrg/3Wo7qpNZlxmsxMel4hYAnwTuCEzv9uxijtnMmNzeuMFkIh4HfAG4KnOlF25Ex6XzHxHZq7NzLXUr9n+e5l5ch+JN92z1Sf6A1wMPE59Zv/TjXU3A5c0bs+jPmO/jfoL/RlN9/10436PARdN92M5icblKeB56n/ZDTLmKImZ/HOi4wJ8BngZ2Nz085rpfjwnydh8hPpk6Gbg+8D7p/uxnAzjMmYbn2UGHDXkKSYkqXAz9aMhSdIUMQgkqXAGgSQVziCQpMIZBJJUOINAakPjzKzvG7PuExHxR42zTH4rIh6NiK1NZ+c8vXFWym2Ns1TOmY7apfEYBFJ7vkr9S0XNrmisvxO4NTPfSP1kZc812j9P/VQDZwJ7gGs6VKs0IQaB1J6vAb88+ld946/+FdRPKdCdmf8HIDP3Zeb+xlkoL2jcD+pnqXx/p4uW2mEQSG3IzOepf3v0osaqK4C7qZ+i5IWI+J8R8XBE3BoRXdTPzvlC/uxsnLPpLLeaZQwCqX3NHw+NfizUDbwD+BT1M3CeAXx0OoqTTpRBILXvHuoXH3kLsCAzN1H/S39z1i9gMgR8A3gL9Y+MloyelI3ZdZZbzTIGgdSmrJ9f/n7gy9TfDUD9LJVLIqKvsXwBsDXrJ/G6n/pZKaF+lsp7Oliu1DZPOidNQOMShF8H3piZP2qsew/w+0AAm4BrM/NQRJxB/RKHpwEPA1fl7Lq6mWYJg0CSCudHQ5JUOINAkgpnEEhS4QwCSSqcQSBJhTMIJKlwBoEkFe7/A/eL9ZuyRJybAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpshNsEdD3z0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature = dataset.drop(['Class'], axis=1)\n",
        "label = dataset['Class']"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vENG5llOXzA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Scaling data\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "scaler = PowerTransformer(method='yeo-johnson', standardize=True)\n",
        "#scaler = preprocessing.StandardScaler()\n",
        "\n",
        "feature_scaled = scaler.fit_transform(feature.values)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fEzGdI7OZo_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "feature_train, feature_test, label_train, label_test = train_test_split(feature_scaled, label, test_size=0.10, random_state=29)"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtBvIJR8XnT2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Menyeimbangkan data\n",
        "\n",
        "#from imblearn.over_sampling import SMOTE\n",
        "#smt = SMOTE()\n",
        "#feature_train, label_train = smt.fit_sample(feature_train, label_train)\n",
        "#np.bincount(label_train)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcu104I_Obg3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "d3e78d3a-65e7-4878-f1c5-28ff9e64ae7f"
      },
      "source": [
        "# Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "\n",
        "log_reg = LogisticRegression(tol=0.25)\n",
        "log_reg.fit(feature_train, label_train)\n",
        "\n",
        "predictions = log_reg.predict(feature_train)\n",
        "\n",
        "print('Accuracy of logistic regression classifier on train set: {:.2f}'.format(log_reg.score(feature_train, label_train))) # .score() -> Accuracy\n",
        "print(f1_score(label_train, predictions, average='macro'))\n",
        "print(precision_score(label_train, predictions, average='macro'))\n",
        "print(recall_score(label_train, predictions, average='macro'))\n",
        "predictions = log_reg.predict(feature_test)\n",
        "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(log_reg.score(feature_test, label_test))) # .score() -> Accuracy\n",
        "print(f1_score(label_test, predictions, average='macro'))\n",
        "print(precision_score(label_test, predictions, average='macro'))\n",
        "print(recall_score(label_test, predictions, average='macro'))"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of logistic regression classifier on train set: 0.92\n",
            "0.9195560526542201\n",
            "0.9198232323232323\n",
            "0.9193418940609952\n",
            "Accuracy of logistic regression classifier on test set: 0.76\n",
            "0.7529411764705882\n",
            "0.75\n",
            "0.7596153846153846\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCERLcLcOd4f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656
        },
        "outputId": "c1f0d776-e069-40ce-d801-e496d6c4b696"
      },
      "source": [
        "# Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "for i in range(50, 150 ,25):\n",
        "  rf_model = RandomForestClassifier(n_estimators=(i), random_state=(20), bootstrap=True, max_features = \"sqrt\")\n",
        "  rf_model.fit(feature_train, label_train)\n",
        "  predictions = rf_model.predict(feature_train)\n",
        "  print('Accuracy of Random Forest with Estimators = ' +str(i)+ ' on train set: {:.2f}'.format(rf_model.score(feature_train, label_train)))\n",
        "  print(f1_score(label_train, predictions, average=\"macro\"))\n",
        "  print(precision_score(label_train, predictions, average=\"macro\"))\n",
        "  print(recall_score(label_train, predictions, average=\"macro\"))\n",
        "  predictions = rf_model.predict(feature_test)\n",
        "  print('Accuracy of Random Forest with Estimators = ' +str(i)+ ' on test set: {:.2f}'.format(rf_model.score(feature_test, label_test)))\n",
        "  print(f1_score(label_test, predictions, average=\"macro\"))\n",
        "  print(precision_score(label_test, predictions, average=\"macro\"))\n",
        "  print(recall_score(label_test, predictions, average=\"macro\"))\n",
        "  print(\"\")"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Random Forest with Estimators = 50 on train set: 1.00\n",
            "1.0\n",
            "1.0\n",
            "1.0\n",
            "Accuracy of Random Forest with Estimators = 50 on test set: 0.81\n",
            "0.7980769230769231\n",
            "0.7980769230769231\n",
            "0.7980769230769231\n",
            "\n",
            "Accuracy of Random Forest with Estimators = 75 on train set: 1.00\n",
            "1.0\n",
            "1.0\n",
            "1.0\n",
            "Accuracy of Random Forest with Estimators = 75 on test set: 0.76\n",
            "0.7529411764705882\n",
            "0.75\n",
            "0.7596153846153846\n",
            "\n",
            "Accuracy of Random Forest with Estimators = 100 on train set: 1.00\n",
            "1.0\n",
            "1.0\n",
            "1.0\n",
            "Accuracy of Random Forest with Estimators = 100 on test set: 0.81\n",
            "0.7980769230769231\n",
            "0.7980769230769231\n",
            "0.7980769230769231\n",
            "\n",
            "Accuracy of Random Forest with Estimators = 125 on train set: 1.00\n",
            "1.0\n",
            "1.0\n",
            "1.0\n",
            "Accuracy of Random Forest with Estimators = 125 on test set: 0.76\n",
            "0.7529411764705882\n",
            "0.75\n",
            "0.7596153846153846\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oL6awQytY_9a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "64f55f88-e2b0-4f17-b868-b0c098120732"
      },
      "source": [
        "# SVC\n",
        "from sklearn.svm import SVC\n",
        "kern = ('poly','linear', 'rbf')\n",
        "for i in kern:\n",
        "  classifier_poly = SVC(kernel = (i))\n",
        "  classifier_poly.fit(feature_train, label_train)\n",
        "  predictions = classifier_poly.predict(feature_train)\n",
        "  print('Accuracy of SVC ' +str(i)+ ' classifier on train set: {:.2f}'.format(classifier_poly.score(feature_train, label_train)))\n",
        "  print(f1_score(label_train, predictions, average=\"macro\"))\n",
        "  print(precision_score(label_train, predictions, average=\"macro\"))\n",
        "  print(recall_score(label_train, predictions, average=\"macro\"))\n",
        "  predictions = classifier_poly.predict(feature_test)\n",
        "  print('Accuracy of SVC ' +str(i)+ ' classifier on test set: {:.2f}'.format(classifier_poly.score(feature_test, label_test)))\n",
        "  print(f1_score(label_test, predictions, average=\"macro\"))\n",
        "  print(precision_score(label_test, predictions, average=\"macro\"))\n",
        "  print(recall_score(label_test, predictions, average=\"macro\"))\n",
        "  print(\"\")"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of SVC poly classifier on train set: 1.00\n",
            "1.0\n",
            "1.0\n",
            "1.0\n",
            "Accuracy of SVC poly classifier on test set: 0.90\n",
            "0.8990384615384616\n",
            "0.8990384615384616\n",
            "0.8990384615384616\n",
            "\n",
            "Accuracy of SVC linear classifier on train set: 0.95\n",
            "0.9464490263459335\n",
            "0.9461996336996337\n",
            "0.9469158449896813\n",
            "Accuracy of SVC linear classifier on test set: 0.76\n",
            "0.7529411764705882\n",
            "0.75\n",
            "0.7596153846153846\n",
            "\n",
            "Accuracy of SVC rbf classifier on train set: 0.99\n",
            "0.994642601346512\n",
            "0.9944444444444445\n",
            "0.9948979591836735\n",
            "Accuracy of SVC rbf classifier on test set: 0.86\n",
            "0.851764705882353\n",
            "0.8472222222222222\n",
            "0.8605769230769231\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1qFarXXZC8B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "17bb7006-247d-47b0-da3e-ab6830154109"
      },
      "source": [
        "# LinearSVC\n",
        "from sklearn import svm\n",
        "classifier_linear2 = svm.LinearSVC()\n",
        "classifier_linear2.fit(feature_train, label_train)\n",
        "\n",
        "predictions = classifier_linear2.predict(feature_train)\n",
        "print('Accuracy of SVC (Linear) classifier on train set: {:.2f}'.format(classifier_linear2.score(feature_train, label_train)))\n",
        "print(f1_score(label_train, predictions, average=\"macro\"))\n",
        "print(precision_score(label_train, predictions, average=\"macro\"))\n",
        "print(recall_score(label_train, predictions, average=\"macro\"))\n",
        "predictions = classifier_linear2.predict(feature_test)\n",
        "print('Accuracy of SVC (Linear) classifier on test set: {:.2f}'.format(classifier_linear2.score(feature_test, label_test)))\n",
        "print(f1_score(label_test, predictions, average=\"macro\"))\n",
        "print(precision_score(label_test, predictions, average=\"macro\"))\n",
        "print(recall_score(label_test, predictions, average=\"macro\"))"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of SVC (Linear) classifier on train set: 0.95\n",
            "0.9517336315925321\n",
            "0.952020202020202\n",
            "0.9515019490942445\n",
            "Accuracy of SVC (Linear) classifier on test set: 0.81\n",
            "0.8055555555555555\n",
            "0.8045454545454545\n",
            "0.8221153846153846\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1EBWZosZFN5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d1ac6bbd-6fec-4d59-f4af-199a340713e0"
      },
      "source": [
        "# KNN\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "for i in range(1, 20, 2):\n",
        "  knn = KNeighborsClassifier(n_neighbors=(i), metric='canberra') #Default k = 5\n",
        "  knn.fit(feature_train, label_train)\n",
        "  \n",
        "  predictions = knn.predict(feature_train)\n",
        "  print('Accuracy KNN classifier with k = ' +str(i)+' on train set: {:.2f}'.format(knn.score(feature_train, label_train)))\n",
        "  print(f1_score(label_train, predictions, average=\"macro\"))\n",
        "  print(precision_score(label_train, predictions, average=\"macro\"))\n",
        "  print(recall_score(label_train, predictions, average=\"macro\"))\n",
        "  predictions = knn.predict(feature_test)\n",
        "  print('Accuracy KNN classifier with k = ' +str(i)+' on test set: {:.2f}'.format(knn.score(feature_test, label_test)))\n",
        "  print(f1_score(label_test, predictions, average=\"macro\"))\n",
        "  print(precision_score(label_test, predictions, average=\"macro\"))\n",
        "  print(recall_score(label_test, predictions, average=\"macro\"))\n",
        "  print(\"\")"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy KNN classifier with k = 1 on train set: 1.00\n",
            "1.0\n",
            "1.0\n",
            "1.0\n",
            "Accuracy KNN classifier with k = 1 on test set: 1.00\n",
            "1.0\n",
            "1.0\n",
            "1.0\n",
            "\n",
            "Accuracy KNN classifier with k = 3 on train set: 0.93\n",
            "0.9243527508090615\n",
            "0.9317862165963431\n",
            "0.9223801880302682\n",
            "Accuracy KNN classifier with k = 3 on test set: 0.86\n",
            "0.851764705882353\n",
            "0.8472222222222222\n",
            "0.8605769230769231\n",
            "\n",
            "Accuracy KNN classifier with k = 5 on train set: 0.90\n",
            "0.8974455188338866\n",
            "0.9033294392523364\n",
            "0.895838110525109\n",
            "Accuracy KNN classifier with k = 5 on test set: 0.86\n",
            "0.851764705882353\n",
            "0.8472222222222222\n",
            "0.8605769230769231\n",
            "\n",
            "Accuracy KNN classifier with k = 7 on train set: 0.89\n",
            "0.8870675524113536\n",
            "0.8892741562644475\n",
            "0.8861499656042192\n",
            "Accuracy KNN classifier with k = 7 on test set: 0.76\n",
            "0.7407407407407407\n",
            "0.75\n",
            "0.7355769230769231\n",
            "\n",
            "Accuracy KNN classifier with k = 9 on train set: 0.85\n",
            "0.8490196078431372\n",
            "0.8533659445609132\n",
            "0.8478559963311167\n",
            "Accuracy KNN classifier with k = 9 on test set: 0.81\n",
            "0.7980769230769231\n",
            "0.7980769230769231\n",
            "0.7980769230769231\n",
            "\n",
            "Accuracy KNN classifier with k = 11 on train set: 0.84\n",
            "0.8431253435158669\n",
            "0.8505645730416372\n",
            "0.8417220820912634\n",
            "Accuracy KNN classifier with k = 11 on test set: 0.86\n",
            "0.8444444444444444\n",
            "0.8571428571428571\n",
            "0.8365384615384616\n",
            "\n",
            "Accuracy KNN classifier with k = 13 on train set: 0.81\n",
            "0.8039832285115305\n",
            "0.8174717615957703\n",
            "0.8029121761063975\n",
            "Accuracy KNN classifier with k = 13 on test set: 0.86\n",
            "0.8444444444444444\n",
            "0.8571428571428571\n",
            "0.8365384615384616\n",
            "\n",
            "Accuracy KNN classifier with k = 15 on train set: 0.80\n",
            "0.7988253423661792\n",
            "0.8106314278880651\n",
            "0.797810135290071\n",
            "Accuracy KNN classifier with k = 15 on test set: 0.86\n",
            "0.8444444444444444\n",
            "0.8571428571428571\n",
            "0.8365384615384616\n",
            "\n",
            "Accuracy KNN classifier with k = 17 on train set: 0.78\n",
            "0.7757203451806348\n",
            "0.7932234432234433\n",
            "0.7753382251777114\n",
            "Accuracy KNN classifier with k = 17 on test set: 0.86\n",
            "0.8444444444444444\n",
            "0.8571428571428571\n",
            "0.8365384615384616\n",
            "\n",
            "Accuracy KNN classifier with k = 19 on train set: 0.78\n",
            "0.7749567055094073\n",
            "0.796218487394958\n",
            "0.7748222884659481\n",
            "Accuracy KNN classifier with k = 19 on test set: 0.86\n",
            "0.8444444444444444\n",
            "0.8571428571428571\n",
            "0.8365384615384616\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmti1Zp-ZJv7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d87ed252-0f44-4b88-f3e6-be6c5313b650"
      },
      "source": [
        "from sklearn.neighbors import RadiusNeighborsClassifier\n",
        "\n",
        "for i in np.arange(40.0, 50.0, 1):\n",
        "  rn = RadiusNeighborsClassifier(radius=(i), metric='canberra') #Default k = 5\n",
        "  rn.fit(feature_train, label_train)\n",
        "  predictions = rn.predict(feature_train)\n",
        "  print('Accuracy RN classifier with radius = ' +str(i)+' on train set: {:.2f}'.format(rn.score(feature_train, label_train)))\n",
        "  print(f1_score(label_train, predictions, average=\"macro\"))\n",
        "  print(precision_score(label_train, predictions, average=\"macro\"))\n",
        "  print(recall_score(label_train, predictions, average=\"macro\"))\n",
        "  predictions = rn.predict(feature_test)\n",
        "  print('Accuracy RN classifier with radius = ' +str(i)+' on test set: {:.2f}'.format(rn.score(feature_test, label_test)))\n",
        "  print(f1_score(label_test, predictions, average=\"macro\"))\n",
        "  print(precision_score(label_test, predictions, average=\"macro\"))\n",
        "  print(recall_score(label_test, predictions, average=\"macro\"))\n",
        "  print(\"\")"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy RN classifier with radius = 40.0 on train set: 0.75\n",
            "0.7410811607011342\n",
            "0.7644628099173554\n",
            "0.7421462967209356\n",
            "Accuracy RN classifier with radius = 40.0 on test set: 0.76\n",
            "0.7529411764705882\n",
            "0.75\n",
            "0.7596153846153846\n",
            "\n",
            "Accuracy RN classifier with radius = 41.0 on train set: 0.76\n",
            "0.7589076418190341\n",
            "0.7774502579218865\n",
            "0.7590002293052052\n",
            "Accuracy RN classifier with radius = 41.0 on test set: 0.76\n",
            "0.7529411764705882\n",
            "0.75\n",
            "0.7596153846153846\n",
            "\n",
            "Accuracy RN classifier with radius = 42.0 on train set: 0.76\n",
            "0.7580569277816984\n",
            "0.780410447761194\n",
            "0.7584842925934419\n",
            "Accuracy RN classifier with radius = 42.0 on test set: 0.76\n",
            "0.7529411764705882\n",
            "0.75\n",
            "0.7596153846153846\n",
            "\n",
            "Accuracy RN classifier with radius = 43.0 on train set: 0.78\n",
            "0.7764266759980171\n",
            "0.7905797101449276\n",
            "0.7758541618894749\n",
            "Accuracy RN classifier with radius = 43.0 on test set: 0.71\n",
            "0.6971153846153846\n",
            "0.6971153846153846\n",
            "0.6971153846153846\n",
            "\n",
            "Accuracy RN classifier with radius = 44.0 on train set: 0.79\n",
            "0.7822035872350339\n",
            "0.7950012016342225\n",
            "0.7814721394175648\n",
            "Accuracy RN classifier with radius = 44.0 on test set: 0.67\n",
            "0.6636155606407322\n",
            "0.6727272727272727\n",
            "0.6826923076923077\n",
            "\n",
            "Accuracy RN classifier with radius = 45.0 on train set: 0.76\n",
            "0.7589076418190341\n",
            "0.7774502579218865\n",
            "0.7590002293052052\n",
            "Accuracy RN classifier with radius = 45.0 on test set: 0.71\n",
            "0.7083333333333333\n",
            "0.7090909090909091\n",
            "0.7211538461538461\n",
            "\n",
            "Accuracy RN classifier with radius = 46.0 on train set: 0.74\n",
            "0.7300633377522463\n",
            "0.752754820936639\n",
            "0.7314262783765191\n",
            "Accuracy RN classifier with radius = 46.0 on test set: 0.67\n",
            "0.6636155606407322\n",
            "0.6727272727272727\n",
            "0.6826923076923077\n",
            "\n",
            "Accuracy RN classifier with radius = 47.0 on train set: 0.73\n",
            "0.7167760520298161\n",
            "0.7472258064516129\n",
            "0.719674386608576\n",
            "Accuracy RN classifier with radius = 47.0 on test set: 0.76\n",
            "0.7529411764705882\n",
            "0.75\n",
            "0.7596153846153846\n",
            "\n",
            "Accuracy RN classifier with radius = 48.0 on train set: 0.69\n",
            "0.670774647887324\n",
            "0.7208532807659814\n",
            "0.6798326072001835\n",
            "Accuracy RN classifier with radius = 48.0 on test set: 0.67\n",
            "0.6370370370370371\n",
            "0.6428571428571428\n",
            "0.6346153846153846\n",
            "\n",
            "Accuracy RN classifier with radius = 49.0 on train set: 0.67\n",
            "0.6335100401606424\n",
            "0.7557027225901398\n",
            "0.6593671176335703\n",
            "Accuracy RN classifier with radius = 49.0 on test set: 0.71\n",
            "0.6785714285714286\n",
            "0.7\n",
            "0.6730769230769231\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqXLPycjaIcI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "5ea29462-7d6e-442e-8578-1a6ed0007d6c"
      },
      "source": [
        "# SGD\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "sgdc = SGDClassifier()\n",
        "\n",
        "sgdc.fit(feature_train, label_train)\n",
        "\n",
        "predictions = sgdc.predict(feature_train)\n",
        "print('Accuracy of SGD classifier on train set: {:.2f}'.format(sgdc.score(feature_train, label_train)))\n",
        "print(f1_score(label_train, predictions, average=\"macro\"))\n",
        "print(precision_score(label_train, predictions, average=\"macro\"))\n",
        "print(recall_score(label_train, predictions, average=\"macro\"))\n",
        "predictions = sgdc.predict(feature_test)\n",
        "print('Accuracy of SGD classifier on test set: {:.2f}'.format(sgdc.score(feature_test, label_test)))\n",
        "print(f1_score(label_test, predictions, average=\"macro\"))\n",
        "print(precision_score(label_test, predictions, average=\"macro\"))\n",
        "print(recall_score(label_test, predictions, average=\"macro\"))"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of SGD classifier on train set: 0.86\n",
            "0.8602873563218391\n",
            "0.861764705882353\n",
            "0.8596078880990599\n",
            "Accuracy of SGD classifier on test set: 0.76\n",
            "0.7529411764705882\n",
            "0.75\n",
            "0.7596153846153846\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-W3NT2vbaKS5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "bb5725a7-9943-4b75-bf1a-e8f8ca8190ce"
      },
      "source": [
        "# Decision Tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "tree = DecisionTreeClassifier()\n",
        "\n",
        "tree.fit(feature_train, label_train)\n",
        "\n",
        "predictions = tree.predict(feature_train)\n",
        "print('Accuracy of Decision Tree classifier on train set: {:.2f}'.format(tree.score(feature_train, label_train)))\n",
        "print(f1_score(label_train, predictions, average=\"macro\"))\n",
        "print(precision_score(label_train, predictions, average=\"macro\"))\n",
        "print(recall_score(label_train, predictions, average=\"macro\"))\n",
        "predictions = tree.predict(feature_test)\n",
        "print('Accuracy of Decision Tree classifier on test set: {:.2f}'.format(tree.score(feature_test, label_test)))\n",
        "print(f1_score(label_test, predictions, average=\"macro\"))\n",
        "print(precision_score(label_test, predictions, average=\"macro\"))\n",
        "print(recall_score(label_test, predictions, average=\"macro\"))"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Decision Tree classifier on train set: 1.00\n",
            "1.0\n",
            "1.0\n",
            "1.0\n",
            "Accuracy of Decision Tree classifier on test set: 0.81\n",
            "0.8090909090909091\n",
            "0.8333333333333333\n",
            "0.8461538461538461\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rq5LMUu1aMWQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "faf8f879-7353-4613-86e0-ec8869ee26f7"
      },
      "source": [
        "# Gaussian Naive Bayes\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "bay = GaussianNB()\n",
        "\n",
        "bay.fit(feature_train, label_train)\n",
        "\n",
        "predictions = bay.predict(feature_train)\n",
        "print('Accuracy of Gaussian Naive Bayes classifier on train set: {:.2f}'.format(bay.score(feature_train, label_train)))\n",
        "print(f1_score(label_train, predictions, average=\"macro\"))\n",
        "print(precision_score(label_train, predictions, average=\"macro\"))\n",
        "print(recall_score(label_train, predictions, average=\"macro\"))\n",
        "predictions = bay.predict(feature_test)\n",
        "print('Accuracy of Gaussian Naive Bayes classifier on test set: {:.2f}'.format(bay.score(feature_test, label_test)))\n",
        "print(f1_score(label_test, predictions, average=\"macro\"))\n",
        "print(precision_score(label_test, predictions, average=\"macro\"))\n",
        "print(recall_score(label_test, predictions, average=\"macro\"))"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Gaussian Naive Bayes classifier on train set: 0.79\n",
            "0.7905814788226848\n",
            "0.7913884411696983\n",
            "0.7901857372162349\n",
            "Accuracy of Gaussian Naive Bayes classifier on test set: 0.67\n",
            "0.6636155606407322\n",
            "0.6727272727272727\n",
            "0.6826923076923077\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sMUEna4aPFB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "dc5346d5-65fa-4065-d289-b5445be2e3e0"
      },
      "source": [
        "# AdaBoost\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "ada = AdaBoostClassifier()\n",
        "\n",
        "ada.fit(feature_train, label_train)\n",
        "\n",
        "predictions = ada.predict(feature_train)\n",
        "print('Accuracy of SVC AdaBoost classifier on train set: {:.2f}'.format(ada.score(feature_train, label_train)))\n",
        "print(f1_score(label_train, predictions, average=\"macro\"))\n",
        "print(precision_score(label_train, predictions, average=\"macro\"))\n",
        "print(recall_score(label_train, predictions, average=\"macro\"))\n",
        "predictions = ada.predict(feature_test)\n",
        "print('Accuracy of AdaBoost classifier on test set: {:.2f}'.format(ada.score(feature_test, label_test)))\n",
        "print(f1_score(label_test, predictions, average=\"macro\"))\n",
        "print(precision_score(label_test, predictions, average=\"macro\"))\n",
        "print(recall_score(label_test, predictions, average=\"macro\"))"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of SVC AdaBoost classifier on train set: 1.00\n",
            "1.0\n",
            "1.0\n",
            "1.0\n",
            "Accuracy of AdaBoost classifier on test set: 0.86\n",
            "0.851764705882353\n",
            "0.8472222222222222\n",
            "0.8605769230769231\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQMCVvb8aQpB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "c71f3ede-fc50-441d-aa0e-858aff6b1e18"
      },
      "source": [
        "# Gaussian Process\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "gau = GaussianProcessClassifier()\n",
        "gau.fit(feature_train, label_train)\n",
        "\n",
        "predictions = gau.predict(feature_train)\n",
        "print('Accuracy of Gaussian Process classifier on train set: {:.2f}'.format(gau.score(feature_train, label_train)))\n",
        "print(f1_score(label_train, predictions, average=\"macro\"))\n",
        "print(precision_score(label_train, predictions, average=\"macro\"))\n",
        "print(recall_score(label_train, predictions, average=\"macro\"))\n",
        "predictions = gau.predict(feature_test)\n",
        "print('Accuracy of Gaussian Process classifier on test set: {:.2f}'.format(gau.score(feature_test, label_test)))\n",
        "print(f1_score(label_test, predictions, average=\"macro\"))\n",
        "print(precision_score(label_test, predictions, average=\"macro\"))\n",
        "print(recall_score(label_test, predictions, average=\"macro\"))"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Gaussian Process classifier on train set: 1.00\n",
            "1.0\n",
            "1.0\n",
            "1.0\n",
            "Accuracy of Gaussian Process classifier on test set: 0.95\n",
            "0.9505882352941177\n",
            "0.9444444444444444\n",
            "0.9615384615384616\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9imjTUZLamtZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "dd76eb10-cb73-45be-c345-a58e36752f86"
      },
      "source": [
        "# QDA\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "quad = QuadraticDiscriminantAnalysis()\n",
        "\n",
        "quad.fit(feature_train, label_train)\n",
        "\n",
        "predictions = quad.predict(feature_train)\n",
        "print('Accuracy of QDA classifier on train set: {:.2f}'.format(quad.score(feature_train, label_train)))\n",
        "print(f1_score(label_train, predictions, average=\"macro\"))\n",
        "print(precision_score(label_train, predictions, average=\"macro\"))\n",
        "print(recall_score(label_train, predictions, average=\"macro\"))\n",
        "predictions = quad.predict(feature_test)\n",
        "print('Accuracy of QDA classifier on test set: {:.2f}'.format(quad.score(feature_test, label_test)))\n",
        "print(f1_score(label_test, predictions, average=\"macro\"))\n",
        "print(precision_score(label_test, predictions, average=\"macro\"))\n",
        "print(recall_score(label_test, predictions, average=\"macro\"))"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of QDA classifier on train set: 1.00\n",
            "1.0\n",
            "1.0\n",
            "1.0\n",
            "Accuracy of QDA classifier on test set: 0.90\n",
            "0.9027777777777778\n",
            "0.9\n",
            "0.9230769230769231\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMdtFsAxao_5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "6579c908-48af-42ad-ae42-3a2c14f8b1e8"
      },
      "source": [
        "# Multi-Layer Perceptron\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "mul = MLPClassifier(learning_rate_init=0.10, hidden_layer_sizes=120, random_state=60)\n",
        "\n",
        "mul.fit(feature_train, label_train)\n",
        "\n",
        "predictions = mul.predict(feature_train)\n",
        "print('Accuracy of MLP classifier on train set: {:.2f}'.format(mul.score(feature_train, label_train)))\n",
        "print(f1_score(label_train, predictions, average=\"macro\"))\n",
        "print(precision_score(label_train, predictions, average=\"macro\"))\n",
        "print(recall_score(label_train, predictions, average=\"macro\"))\n",
        "predictions = mul.predict(feature_test)\n",
        "print('Accuracy of MLP classifier on test set: {:.2f}'.format(mul.score(feature_test, label_test)))\n",
        "print(f1_score(label_test, predictions, average=\"macro\"))\n",
        "print(precision_score(label_test, predictions, average=\"macro\"))\n",
        "print(recall_score(label_test, predictions, average=\"macro\"))"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of MLP classifier on train set: 1.00\n",
            "1.0\n",
            "1.0\n",
            "1.0\n",
            "Accuracy of MLP classifier on test set: 0.86\n",
            "0.851764705882353\n",
            "0.8472222222222222\n",
            "0.8605769230769231\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0T4OgBijwLk9",
        "colab_type": "text"
      },
      "source": [
        "**Kesimpulan**\n",
        "Pada dataset Sonar ini, KNN Classifier menghasilkan akurasi tertinggi yaitu 1.0 dengan k=1 dan metric = \"canberra\". \n",
        "\n",
        "Scaling data dengan menggunakan Power Transformer method Yeo-Johnson, dan pembagian data training : test = 90% : 10% dan random_state=29."
      ]
    }
  ]
}